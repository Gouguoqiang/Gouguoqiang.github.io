{"meta":{"title":"ggq","subtitle":"","description":"","author":"ggq","url":"https://gouguoqiang.github.io","root":"/"},"pages":[{"title":"about","date":"2022-10-10T02:10:55.000Z","updated":"2022-10-10T02:11:45.270Z","comments":true,"path":"about/index.html","permalink":"https://gouguoqiang.github.io/about/index.html","excerpt":"","text":""},{"title":"archives","date":"2022-10-10T01:30:43.000Z","updated":"2022-10-10T01:31:11.074Z","comments":true,"path":"archives/index.html","permalink":"https://gouguoqiang.github.io/archives/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-10-10T05:33:05.000Z","updated":"2022-10-10T05:33:05.796Z","comments":true,"path":"tags/index.html","permalink":"https://gouguoqiang.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"beibao","slug":"beibao","date":"2022-10-17T09:55:43.000Z","updated":"2022-10-17T10:15:31.621Z","comments":true,"path":"2022/10/17/beibao/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/17/beibao/","excerpt":"","text":"模板 优化空间后 除了 完全背包可从前往后 ,其他都是从后往前 123for 物品 for 体积 for 决策 01背包12//不选第i个物品和 选一个最后一个物品dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w[i]] + v[i]); 板子题1234567输入 3 7071 10069 11 2 // 给定背包大小 m,给定 物品个数 n,w[i] v[i] 求背包能装物品的最大值 123456789101112131415import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int m = in.nextInt(); int[] dp = new int[m+10]; for (int i =0; i &lt; n; i++) &#123; int w = in.nextInt(); int v = in.nextInt(); for (int j = m; j &gt;= w; j--) dp[j] = Math.max(dp[j],dp[j-w]+v); &#125; System.out.println(dp[m]); &#125;&#125; 装箱问题123456789101112输入 24 // 箱子容量 6 // 物品个数 8 // 物品体积 3 12 7 9 7 // 求任取若干 使箱子剩余空间最小 //思路 体积也看成价值 二维费用的背包问题有 NN 件物品和一个容量是 VV 的背包，背包能承受的最大重量是 MM。 每件物品只能用一次。体积是 vivi，重量是 mimi，价值是 wiwi。 求解将哪些物品装入背包，可使物品总体积不超过背包容量，总重量不超过背包可承受的最大重量，且价值总和最大。输出最大价值。 输入格式第一行三个整数，N,V,MN,V,M，用空格隔开，分别表示物品件数、背包容积和背包可承受的最大重量。 接下来有 NN 行，每行三个整数 vi,mi,wi, vi,mi,wi，用空格隔开，分别表示第 i 件物品的体积、重量和价值。 输出格式输出一个整数，表示最大价值。 数据范围0&lt;N≤10000&lt;N≤10000&lt;V,M≤1000&lt;V,M≤1000&lt;vi,mi≤1000&lt;vi,mi≤1000&lt;wi≤10000&lt;wi≤1000 输入样例123454 5 61 2 32 4 43 4 54 5 6 输出样例：18 代码:1f[i][j][k] = Math.max(dp[i-1][j][k],dp[i][j-w1][k-w2] + v) 1234567891011121314151617181920import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int W1 = in.nextInt(); int W2 = in.nextInt(); for (int i = 0; i &lt; n; i++) &#123; int w1 = in.nextInt(); int w2 = in.nextInt(); int v = nextInt(); for (int j = W1; j &gt;= 0; j--) &#123; for (int k = W2; k&gt;= 0; k--) &#123; dp[j][k] = Math.max(dp[i][k],dp[j-w1][k-w2]+v); &#125; &#125; &#125; System.out.println(dp[W1][W2]); &#125;&#125; 数字组合 给定 N 个正整数 A1,A2,…,AN ,从中选出若干个数，使它们的和为 M，求有多少种选择方案。 输入格式第一行包含两个整数 N 和 M。 第二行包含 N 个整数，表示 A1,A2,…,AN。 输出格式包含一个整数，表示可选方案数。 数据范围1≤N≤1001≤N≤100,1≤M≤100001≤M≤10000,1≤Ai≤10001≤Ai≤1000,答案保证在 int 范围内。 输入样例：124 41 1 2 2 输出样例：13 代码1import 完全背包123456//不选第i个物品和,选一个,选两个,选n个直到不能选dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w]+v,dp[i-1][j-2w]+2v...dp[i-1][j-nw] + nv);dp[i][j-w] = Math.max( dp[i-1][j-w] ,dp[i-1][j-2w]+v ...dp[i-1][j-nw] + (n-1)v);//最终dp[i][j] = Math.max(dp[i-1][j],dp[i][j-w[i]] + v[i]); 零钱兑换I给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。 计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。 你可以认为每种硬币的数量是无限的。 示例 1： 输入：coins &#x3D; [1, 2, 5], amount &#x3D; 11输出：3解释：11 &#x3D; 5 + 5 + 1示例 2： 输入：coins &#x3D; [2], amount &#x3D; 3输出：-1示例 3： 输入：coins &#x3D; [1], amount &#x3D; 0输出：0 提示： 1 &lt;&#x3D; coins.length &lt;&#x3D; 121 &lt;&#x3D; coins[i] &lt;&#x3D; 231 - 10 &lt;&#x3D; amount &lt;&#x3D; 104 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/coin-change著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 123456789101112131415161718192021class Solution &#123; public final int INF = Integer.MAX_VALUE / 2; public int coinChange(int[] coins, int amount) &#123; // dp[i] // 刚好装满的最少个数(价值为1) int m = amount; int n = coins.length; int[]dp = new int[amount+10]; Arrays.fill(dp,INF); dp[0] = 0; for (int i = 0; i &lt; n; i++) &#123; for (int j = coins[i]; j &lt;= m; j++) &#123; dp[j] = Math.min(dp[j],dp[j-coins[i]]+1); &#125; &#125; return dp[amount] == INF ? -1 : dp[amount]; &#125;&#125; 零钱兑换II买书&#x2F;货币系统&#x2F;零钱兑换II货币系统II多重背包 r &#x3D; j % v; 物品有限s[i]个 12345678910//不选第i个物品,选一个第i个物品,选两个,选到不能选(体积之内 || 个数之内)dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w]+v,dp[i-1][j-2w]+2v...dp[i-1][j-nw] + nv);dp[i][j-w] = Math.max( dp[i-1][j-w] ,dp[i-1][j-2w]+v ...dp[i-1][j-nw] + (n-1)v,dp[i][j-(n+1)w] + v); //在多重背包里会多一项不能直接替换 (在j-w的体积基础上选s[i](n个),所以要-(n+1)w)//最简单的 for(int j = 1; j &lt;= V; j++)&#123; for(int k = 0; k &lt;= s &amp;&amp; j &gt;= k * v; k++)&#123; dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - k * v] + k * w); &#125; &#125; 多重背包I有 N 种物品和一个容量是 V 的背包。 第 i 种物品最多有 si 件，每件体积是 vi，价值是 wi。 求解将哪些物品装入背包，可使物品体积总和不超过背包容量，且价值总和最大。输出最大价值。 输入格式第一行两个整数，N，V用空格隔开，分别表示物品种数和背包容积。 接下来有 NN行，每行三个整数 vi,wi,si，用空格隔开，分别表示第 i种物品的体积、价值和数量。 输出格式输出一个整数，表示最大价值。 数据范围0&lt;N,V≤1000&lt;N,V≤1000&lt;vi,wi,si≤1000&lt;vi,wi,si≤100 输入样例123454 5 // n m1 2 3 //体积、价值和数量2 4 13 4 34 5 2 输出样例：110 代码:12345678910111213import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner.nextInt(); int n = in.nextInt(); int m = in.nextInt(); int[] w = new int[n+10]; int[] v = new int[n+10]; int[] s = new int[n+10]; for (int i = 0; i &lt; n; i++) &#125;&#125; 混合背包板子题最优选法 背包问题求方案数 有 N件物品和一个容量是 V的背包。每件物品只能使用一次。 第 i 件物品的体积是 v_i，价值是 w_i。 求解将哪些物品装入背包，可使这些物品的总体积不超过背包容量，且总价值最大。 输出 最优选法的方案数。注意答案可能很大，请输出答案模 10^9 + 7 的结果。 输入格式第一行两个整数，N，V，用空格隔开，分别表示物品数量和背包容积。 接下来有 N 行，每行两个整数 v_i, w_i，用空格隔开，分别表示第 i 件物品的体积和价值。 输出格式输出一个整数，表示 方案数 模 10^9 + 7 的结果。 数据范围$0 \\lt N, V \\le 1000$$0\\lt v_i, w_i \\le 1000$ 输入样例123454 51 22 43 44 6 输出样例：12 代码1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.*;class Main&#123; static final int mod = (int)1e9 + 7; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int m = in.nextInt(); //恰好装满的最大价值 int[] f = new int[m+10]; Arrays.fill(f,-1010); // 最优解的方案数 int[] g = new int[m+10]; f[0] = 0; g[0] = 1; for (int i = 0; i &lt; n; i++) &#123; int w = in.nextInt(); int v = in.nextInt(); for (int j = m; j &gt;= w; j--) &#123; int maxv = Math.max(f[j],f[j-w] + v); int cnt = 0; if (maxv == f[j]) cnt += g[j]; if (maxv == f[j-w] + v) cnt += g[j-w]; g[j] = cnt % mod; f[j] = maxv; &#125; &#125; int res = 0; for (int i = 1; i &lt;= m; i++) &#123; res = Math.max(res,f[i]); &#125; int cnt = 0; for (int i = 1; i &lt;= m; i++) &#123; if (res == f[i]) cnt = (cnt + g[i]) % mod; &#125; System.out.println(cnt == 0 ? 1 : cnt); &#125; &#125;","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"https://gouguoqiang.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"beibao","slug":"beibao/beibao","date":"2022-10-17T09:55:43.000Z","updated":"2022-10-17T10:20:46.141Z","comments":true,"path":"2022/10/17/beibao/beibao/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/17/beibao/beibao/","excerpt":"","text":"模板 优化空间后 除了 完全背包可从前往后 ,其他都是从后往前 123for 物品 for 体积 for 决策 01背包12//不选第i个物品和 选一个最后一个物品dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w[i]] + v[i]); 板子题1234567输入 3 7071 10069 11 2 // 给定背包大小 m,给定 物品个数 n,w[i] v[i] 求背包能装物品的最大值 123456789101112131415import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int m = in.nextInt(); int[] dp = new int[m+10]; for (int i =0; i &lt; n; i++) &#123; int w = in.nextInt(); int v = in.nextInt(); for (int j = m; j &gt;= w; j--) dp[j] = Math.max(dp[j],dp[j-w]+v); &#125; System.out.println(dp[m]); &#125;&#125; 装箱问题123456789101112输入 24 // 箱子容量 6 // 物品个数 8 // 物品体积 3 12 7 9 7 // 求任取若干 使箱子剩余空间最小 //思路 体积也看成价值 二维费用的背包问题有 NN 件物品和一个容量是 VV 的背包，背包能承受的最大重量是 MM。 每件物品只能用一次。体积是 vivi，重量是 mimi，价值是 wiwi。 求解将哪些物品装入背包，可使物品总体积不超过背包容量，总重量不超过背包可承受的最大重量，且价值总和最大。输出最大价值。 输入格式第一行三个整数，N,V,MN,V,M，用空格隔开，分别表示物品件数、背包容积和背包可承受的最大重量。 接下来有 NN 行，每行三个整数 vi,mi,wi, vi,mi,wi，用空格隔开，分别表示第 i 件物品的体积、重量和价值。 输出格式输出一个整数，表示最大价值。 数据范围0&lt;N≤10000&lt;N≤10000&lt;V,M≤1000&lt;V,M≤1000&lt;vi,mi≤1000&lt;vi,mi≤1000&lt;wi≤10000&lt;wi≤1000 输入样例123454 5 61 2 32 4 43 4 54 5 6 输出样例：18 代码:1f[i][j][k] = Math.max(dp[i-1][j][k],dp[i][j-w1][k-w2] + v) 1234567891011121314151617181920import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int W1 = in.nextInt(); int W2 = in.nextInt(); for (int i = 0; i &lt; n; i++) &#123; int w1 = in.nextInt(); int w2 = in.nextInt(); int v = nextInt(); for (int j = W1; j &gt;= 0; j--) &#123; for (int k = W2; k&gt;= 0; k--) &#123; dp[j][k] = Math.max(dp[i][k],dp[j-w1][k-w2]+v); &#125; &#125; &#125; System.out.println(dp[W1][W2]); &#125;&#125; 数字组合 给定 N 个正整数 A1,A2,…,AN ,从中选出若干个数，使它们的和为 M，求有多少种选择方案。 输入格式第一行包含两个整数 N 和 M。 第二行包含 N 个整数，表示 A1,A2,…,AN。 输出格式包含一个整数，表示可选方案数。 数据范围1≤N≤1001≤N≤100,1≤M≤100001≤M≤10000,1≤Ai≤10001≤Ai≤1000,答案保证在 int 范围内。 输入样例：124 41 1 2 2 输出样例：13 代码1import 完全背包123456//不选第i个物品和,选一个,选两个,选n个直到不能选dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w]+v,dp[i-1][j-2w]+2v...dp[i-1][j-nw] + nv);dp[i][j-w] = Math.max( dp[i-1][j-w] ,dp[i-1][j-2w]+v ...dp[i-1][j-nw] + (n-1)v);//最终dp[i][j] = Math.max(dp[i-1][j],dp[i][j-w[i]] + v[i]); 零钱兑换I给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。 计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。 你可以认为每种硬币的数量是无限的。 示例 1： 输入：coins &#x3D; [1, 2, 5], amount &#x3D; 11输出：3解释：11 &#x3D; 5 + 5 + 1示例 2： 输入：coins &#x3D; [2], amount &#x3D; 3输出：-1示例 3： 输入：coins &#x3D; [1], amount &#x3D; 0输出：0 提示： 1 &lt;&#x3D; coins.length &lt;&#x3D; 121 &lt;&#x3D; coins[i] &lt;&#x3D; 231 - 10 &lt;&#x3D; amount &lt;&#x3D; 104 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/coin-change著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 123456789101112131415161718192021class Solution &#123; public final int INF = Integer.MAX_VALUE / 2; public int coinChange(int[] coins, int amount) &#123; // dp[i] // 刚好装满的最少个数(价值为1) int m = amount; int n = coins.length; int[]dp = new int[amount+10]; Arrays.fill(dp,INF); dp[0] = 0; for (int i = 0; i &lt; n; i++) &#123; for (int j = coins[i]; j &lt;= m; j++) &#123; dp[j] = Math.min(dp[j],dp[j-coins[i]]+1); &#125; &#125; return dp[amount] == INF ? -1 : dp[amount]; &#125;&#125; 零钱兑换II买书&#x2F;货币系统&#x2F;零钱兑换II货币系统II多重背包 r &#x3D; j % v; 物品有限s[i]个 12345678910//不选第i个物品,选一个第i个物品,选两个,选到不能选(体积之内 || 个数之内)dp[i][j] = Math.max(dp[i-1][j],dp[i-1][j-w]+v,dp[i-1][j-2w]+2v...dp[i-1][j-nw] + nv);dp[i][j-w] = Math.max( dp[i-1][j-w] ,dp[i-1][j-2w]+v ...dp[i-1][j-nw] + (n-1)v,dp[i][j-(n+1)w] + v); //在多重背包里会多一项不能直接替换 (在j-w的体积基础上选s[i](n个),所以要-(n+1)w)//最简单的 for(int j = 1; j &lt;= V; j++)&#123; for(int k = 0; k &lt;= s &amp;&amp; j &gt;= k * v; k++)&#123; dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - k * v] + k * w); &#125; &#125; 多重背包I有 N 种物品和一个容量是 V 的背包。 第 i 种物品最多有 si 件，每件体积是 vi，价值是 wi。 求解将哪些物品装入背包，可使物品体积总和不超过背包容量，且价值总和最大。输出最大价值。 输入格式第一行两个整数，N，V用空格隔开，分别表示物品种数和背包容积。 接下来有 NN行，每行三个整数 vi,wi,si，用空格隔开，分别表示第 i种物品的体积、价值和数量。 输出格式输出一个整数，表示最大价值。 数据范围0&lt;N,V≤1000&lt;N,V≤1000&lt;vi,wi,si≤1000&lt;vi,wi,si≤100 输入样例123454 5 // n m1 2 3 //体积、价值和数量2 4 13 4 34 5 2 输出样例：110 代码:12345678910111213import java.util.*;class Main&#123; public static void main(String[] args) &#123; Scanner in = new Scanner.nextInt(); int n = in.nextInt(); int m = in.nextInt(); int[] w = new int[n+10]; int[] v = new int[n+10]; int[] s = new int[n+10]; for (int i = 0; i &lt; n; i++) &#125;&#125; 混合背包板子题最优选法 背包问题求方案数 有 N件物品和一个容量是 V的背包。每件物品只能使用一次。 第 i 件物品的体积是 v_i，价值是 w_i。 求解将哪些物品装入背包，可使这些物品的总体积不超过背包容量，且总价值最大。 输出 最优选法的方案数。注意答案可能很大，请输出答案模 10^9 + 7 的结果。 输入格式第一行两个整数，N，V，用空格隔开，分别表示物品数量和背包容积。 接下来有 N 行，每行两个整数 v_i, w_i，用空格隔开，分别表示第 i 件物品的体积和价值。 输出格式输出一个整数，表示 方案数 模 10^9 + 7 的结果。 数据范围$0 \\lt N, V \\le 1000$$0\\lt v_i, w_i \\le 1000$ 输入样例123454 51 22 43 44 6 输出样例：12 代码1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.*;class Main&#123; static final int mod = (int)1e9 + 7; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int m = in.nextInt(); //恰好装满的最大价值 int[] f = new int[m+10]; Arrays.fill(f,-1010); // 最优解的方案数 int[] g = new int[m+10]; f[0] = 0; g[0] = 1; for (int i = 0; i &lt; n; i++) &#123; int w = in.nextInt(); int v = in.nextInt(); for (int j = m; j &gt;= w; j--) &#123; int maxv = Math.max(f[j],f[j-w] + v); int cnt = 0; if (maxv == f[j]) cnt += g[j]; if (maxv == f[j-w] + v) cnt += g[j-w]; g[j] = cnt % mod; f[j] = maxv; &#125; &#125; int res = 0; for (int i = 1; i &lt;= m; i++) &#123; res = Math.max(res,f[i]); &#125; int cnt = 0; for (int i = 1; i &lt;= m; i++) &#123; if (res == f[i]) cnt = (cnt + g[i]) % mod; &#125; System.out.println(cnt == 0 ? 1 : cnt); &#125; &#125;","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"https://gouguoqiang.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"排序算法","slug":"算法","date":"2022-10-17T08:09:45.000Z","updated":"2022-10-17T09:47:32.316Z","comments":true,"path":"2022/10/17/算法/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/17/%E7%AE%97%E6%B3%95/","excerpt":"","text":"排序快速排序第K个数均分纸牌有N堆纸牌，编号分别为 1,2,…,N 每堆上有若干张，但纸牌总数必为 N 的倍数。 可以在任一堆上取若干张纸牌，然后移动。 移牌规则为：在编号为 1 的堆上取的纸牌，只能移到编号为 2 的堆上；在编号为 N 的堆上取的纸牌，只能移到编号为 N−1 的堆上；其他堆上取的纸牌，可以移到相邻左边或右边的堆上。 现在要求找出一种移动方法，用最少的移动次数使每堆上纸牌数都一样多。 例如 N&#x3D;4，4 堆纸牌数分别为：(9,8,17,6) 移动 3 次可达到目的： 从第三堆取四张牌放入第四堆，各堆纸牌数量变为:(9,8,13,10) 从第三堆取三张牌放入第二堆，各堆纸牌数量变为:(9,11,10,10) 从第二堆取一张牌放入第一堆，各堆纸牌数量变为:(10,10,10,10) 输入格式第一行包含整数 N。 第二行包含 N 个整数，A1,A2,…,AN 表示各堆的纸牌数量。 输出格式输出使得所有堆的纸牌数量都相等所需的最少移动次数。 数据范围1≤N≤1001≤N≤100,1≤Ai≤100001≤Ai≤10000 输入样例：1249 8 17 6 输出样例：13 思路:模拟多进少补 处理每一个数 多进少补 代码:123456789int t = 0; for (int i = 1; i &lt;= n; i++) t += arr[i]; t /= n; for (int i = 1; i &lt;= n; i++) arr[i] -= t; int tnt = 0, ans = 0; for (int i = 1; i &lt;= n; i++) &#123; tnt += arr[i]; ans++; if(tnt == 0) ans--; &#125; 七夕祭七夕节因牛郎织女的传说而被扣上了「情人节」的帽子。 于是 TYVJ 今年举办了一次线下七夕祭。 Vani 同学今年成功邀请到了 cl 同学陪他来共度七夕，于是他们决定去 TYVJ 七夕祭游玩。 TYVJ 七夕祭和 11 区的夏祭的形式很像。 矩形的祭典会场由 N 排 M 列共计 N×M 个摊点组成。 虽然摊点种类繁多，不过 cl 只对其中的一部分摊点感兴趣，比如章鱼烧、苹果糖、棉花糖、射的屋……什么的。 Vani 预先联系了七夕祭的负责人 zhq，希望能够通过恰当地布置会场，使得各行中 cl 感兴趣的摊点个数一样多，并且各列中 cl 感兴趣的摊点数也一样多。 不过 zhq 告诉 Vani，摊点已经随意布置完毕了，如果想满足 cl 的要求，唯一的调整方式就是交换两个相邻的摊点。 两个摊点相邻，当且仅当他们处在同一行或者同一列的相邻位置上。 由于 zhq 率领的 TYVJ 开发小组成功地扭曲了空间，每一行或每一列的第一个位置和最后一个位置也算作相邻。 现在 Vani 想知道他的两个要求最多能满足多少个。 在此前提下，至少需要交换多少次摊点。 输入格式第一行包含三个整数 N 和 M 和 T，T 表示 cl 对多少个摊点感兴趣。 接下来 T 行，每行两个整数 x,y，表示 cl 对处在第 x行第 y 列的摊点感兴趣。 输出格式首先输出一个字符串。 如果能满足 Vani 的全部两个要求，输出 both； 如果通过调整只能使得各行中 cl 感兴趣的摊点数一样多，输出 row； 如果只能使各列中 cl 感兴趣的摊点数一样多，输出 column； 如果均不能满足，输出 impossible。 如果输出的字符串不是 impossible， 接下来输出最小交换次数，与字符串之间用一个空格隔开。 数据范围1≤N,M≤1000000≤T≤min(N∗M,100000),1≤x≤N,1≤y≤M 输入样例：123452 3 41 32 12 22 3 输出样例：1row 1 思路: 1 2 3 4 5 只交换相邻两个人的牌 需要交换多少次每个人都一样 设平均值为m &#x3D;3, 去一个通俗的就可以带入所有的 需要借: 1: m-1 2: 2-(m-1) &#x3D; 3-m, m - (3-m) &#x3D; 2m -3 3: 3 - (2m-3) &#x3D; 6 - 2m, m - (6-2m) &#x3D; 3m - 6 4: 4-(3m-6) &#x3D; 10 -3m, 4m - 10; 5: 5m - 15; 观察常数为前缀和, 如果不取首尾只能相邻 那就是前缀和的 每项绝对值相加 但是现在可以选取一个点做为分割点 转化为前缀和货仓选址问题(设置一个仓库位置 到其他所有点的总和距离最短,求中位数(要先排序)) 最少交换次数 排成一个环 取每个数减去中位数的新数组的前缀和 求出都减去平均值数组的前缀和做为新数组, 对新数组做为(“货仓选址”); 代码:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.util.*;public class Main&#123; static int N = 100005; static long[] row = new long[N], col = new long[N]; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); int m = in.nextInt(); int T = in.nextInt(); // 统计每行每列 for (int i = 1; i &lt;= T; i ++) &#123; int x = in.nextInt(); int y = in.nextInt(); row[x] ++; col[y] ++; &#125; for (int i = 1; i &lt;= n; i++) &#123; row[0] += row[i]; &#125; for (int i = 1; i &lt;= m; i++) &#123; col[0] += col[i]; &#125; if (T % n == 0 &amp;&amp; T % m == 0) &#123; long ans = get(row,n)+get(col,m); System.out.println(&quot;both&quot; + &quot; &quot; + ans); &#125; else if (T % n == 0) &#123; System.out.println(&quot;row&quot; + &quot; &quot; + get(row,n)); &#125; else if (T % m == 0) &#123; System.out.println(&quot;column&quot; + &quot; &quot; + get(col,m)); &#125; else &#123; System.out.println(&quot;impossible&quot;); &#125; &#125; public static long get(long[] a, int n) &#123; long avg = a[0] / n; long[] s = new long[N]; for (int i = 1; i &lt;= n; i++) &#123; a[i] -= avg; s[i] = s[i-1] + a[i]; &#125; long ans = 0; Arrays.sort(s,1,n); long mid = s[(1 + n) / 2]; for (int i = 1; i &lt;= n; i++) &#123; ans += Math.abs(s[i] - mid); &#125; return ans; &#125;&#125; 归并排序归并排序给定你一个长度为 n 的整数数列。 请你使用归并排序对这个数列按照从小到大进行排序。 并将排好序的数列按顺序输出。 输入格式输入共两行，第一行包含整数 n。 第二行包含 n 个整数（所有整数均在 1∼109范围内），表示整个数列。 输出格式输出共一行，包含 n 个整数，表示排好序的数列。 数据范围1≤n≤100000 输入样例：1253 1 2 4 5 输出样例：11 2 3 4 5 思路归并排序思路: 创建一个新数组 每次排好两边,再将两边合并 代码1234567891011121314151617181920212223242526272829303132import java.util.*;public class Main&#123; static int N = 100005; static int[] tmp = new int[N], q = new int[N]; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n = in.nextInt(); for (int i = 1; i &lt;= n; i++) &#123; q[i] = in.nextInt(); &#125; mergeSort(q,1,n); for (int i = 1; i &lt;= n; i++) &#123; System.out.println(q[i]); &#125; &#125; public static void mergeSort(int[] q, int l, int r) &#123; if (l &gt;= r) return ; int mid = (l + r) / 2; mergeSort(q,l,mid); mergeSort(q,mid+1,r); int k = 0, i = l, j = mid + 1; while (i &lt;= mid &amp;&amp; j &lt;= r) &#123; if (q[i] &lt;= q[j]) tmp[k++] = q[i++]; else tmp[k++] = q[j++]; &#125; while (i &lt;= mid) tmp[k++] = q[i++]; while (j &lt;= r) tmp[k++] = q[j++]; for (i = l, j = 0; i &lt;= r; i++,j++) q[i] = tmp[j]; &#125;&#125; 逆序对数量给定一个长度为 n 的整数数列，请你计算数列中的逆序对的数量。 逆序对的定义如下：对于数列的第 i 个和第 j 个元素，如果满足 i&lt;j 且 a[i]&gt;a[j]，则其为一个逆序对；否则不是。 输入格式第一行包含整数 n，表示数列的长度。 第二行包含 n 个整数，表示整个数列。 输出格式输出一个整数，表示逆序对的个数。 数据范围1≤n≤100000，数列中的元素的取值范围 [1,109][1,109]。 输入样例：1262 3 4 5 6 1 输出样例：15 思路:分析左右两半部分，如果左半部分 q[i] 大于右半部分的 q[j]，那么从 i 到 mid 都可以和 j 组成逆序对，逆序对个数 res +&#x3D; mid - i + 1 代码:12345678910111213141516171819202122232425262728293031323334class Main&#123; static int N = 100010; static long res = 0; static int[] q = new int[N]; static int[] tmp = new int[N]; public static void main(String[] args) throws IOException&#123; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int n = Integer.parseInt(br.readLine()); String[] s = br.readLine().split(&quot; &quot;); for(int i = 0; i &lt; n; i++)&#123; q[i] = Integer.parseInt(s[i]); &#125; mergeSort(0, n - 1); System.out.println(res); &#125; public static void mergeSort(int l, int r)&#123; if(l &gt;= r) return; int mid = l + r &gt;&gt; 1; mergeSort(l, mid); mergeSort(mid + 1, r); int k = 0, i = l, j = mid + 1; while(i &lt;= mid &amp;&amp; j &lt;= r)&#123; if(q[i] &lt;= q[j]) tmp[k++] = q[i++]; else &#123; res += mid - i + 1; tmp[k++] = q[j++]; &#125; &#125; while(i &lt;= mid) tmp[k++] = q[i++]; while(j &lt;= r) tmp[k++] = q[j++]; for(i = l, j = 0; i &lt;= r; i++, j++) q[i] = tmp[j]; &#125;&#125; 选择排序从头到尾找最小的跟第一个未排序交换 n方 插入排序在已排好序的中插入应该插的地方 12345678910111213int[] arr = &#123;1,3,5,6,2,1,23,5,6&#125;int n = arr.length;for (int i = 1; i &lt; n; i++) &#123; int t = arr[i]; int j = i - 1; for (; j &gt;= 0; j--) &#123; if (arr[j] &lt;= t) break; arr[j+1] = arr[j]; &#125; arr[j+1] = t; &#125; 希尔排序插入排序的优化 堆排序从最后一个根节点开始后层序遍历 上浮 为一个大顶堆 之后在交换第一个与最后一个为排序的","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"https://gouguoqiang.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"redis","slug":"all/5redis","date":"2022-10-09T03:36:23.000Z","updated":"2022-10-09T13:56:59.482Z","comments":true,"path":"2022/10/09/all/5redis/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/09/all/5redis/","excerpt":"","text":"redis日常基础使用 一些配置 与说明 (守护进程)daemonize yes 启动: 123456#可能需要进入redis目录redis-server /usr/local/redis/redis.confredis-cliauth (可以不写用户)密码keys* 关闭 1redis-cli shutdown 使用RedisDesktopManager连接远程服务器redis 修改 .conf ​ bind 0.0.0.0 允许所有主机 127.~ 只允许本机 ​ protectmode yes 只允许本机 no 允许所有主机 ​ requierpass 密码 服务器防火墙开放 6379端口就ok 第三章 redis多线程VS单线程Redis工作线程是单线程的,整个Redis来说，是多线程的；主要是指Redis的网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求时包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。这也是Redis对外提供键值存储服务的主要流程。 但Redis的其他功能，比如持久化、异步删除、集群数据同步等等，其实是由额外的线程执行的。Redis工作线程是单线程的，但是，整个Redis来说，是多线程的； 单线程快的原因1 避免上下文切换：因为是单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生 2 即使使用单线程模型也并发的处理多客户端的请求，主要使用的是多路复用和非阻塞 IO； 3 对于 Redis 系统来说，主要的性能瓶颈是内存或者网络带宽而并非 CPU。 单线程的弊病正常情况下使用 del 指令可以很快的删除数据，而当被删除的 key 是一个非常大的对象时，例如时包含了成千上万个元素的 hash 集合时，那么 del 指令就会造成 Redis 主线程卡顿。 这就是redis3.x单线程时代最经典的故障，大key删除的头疼问题， 由于redis是单线程的，del bigKey …..等待很久这个线程才会释放，类似加了一个synchronized锁，你可以想象高并发下，程序堵成什么样子？ 在Redis 4.0就引入了多个线程来实现数据的异步惰性删除等功能，但是其处理读写请求的仍然只有一个线程，所以仍然算是狭义上的单线程 Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理8W到10W的QPS， 这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。 默认单线程在Redis6.0中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在redis.conf中完成两个设置 1.设置io-thread-do-reads配置项为yes，表示启动多线程。 2。设置线程个数。关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。 第五章 经典五种数据类型(都是针对value)介绍及落地应用1. String1.1 常用指令12345678910111213141516171819202122set key valueget key同时设置/获取多个键值 MGET key [key ....]MSET key value [key value ....]数值增减INCR key增加指定的整数 INCRBY key increment递减数值 DECR key减少指定的整数DECRBY key decrement获取字符串长度STRLEN key分布式锁setnx key valueset key value [EX seconds] [PX milliseconds] [NX|XX] 1.2 应用场景比如抖音无限点赞某个视频或者商品，点一下加一次 2. HashMap&lt;String,Map&lt;Object,Object&gt;&gt; 2.1常用指令1234567891011121314一次设置一个字段值HSET key field value一次获取一个字段值HGET key field一次设置多个字段值HMSET key field value [field value ...]一次获取多个字段值HMGET key field [field ....]获取所有字段值hgetall key获取某个key内的全部数量hlen删除一个keyhdel 2.2应用场景​ Map&lt;String,Map&lt;Object,Object&gt;&gt; ​ hset key field value ​ JD早期购物车 中小场可用 ​ 新增商品 → hset shopcar:uid1024 334488 1 ​ 新增商品 → hset shopcar:uid1024 334477 1 ​ 增加商品数量 → hincrby shopcar:uid1024 334477 1 ​ 商品总数 → hlen shopcar:uid1024 ​ 全部选择 → hgetall shopcar:uid1024 3. List一个双端链表的结构，容量是2的32次方减1个元素，大概40多亿，主要功能有push&#x2F;pop等，一般用在栈、队列、消息队列等场景。 3.1 常用指令12345678向列表左边添加元素LPUSH key value [value ...]向列表右边添加元素RPUSH key value [value ....]查看列表LRANGE key start stop获取列表中元素的个数LLEN key 3.2 应用场景微信订阅号消息,关注了作者,如果作者发布了文章 就会向关注的list添加 ​ 1 订阅了的公众号和CSDN发布了文章分别是 11 和 22 ​ 2 ggq关注了他们两个，只要他们发布了新文章，就会安装进ggq的List lpush likearticle:ggqid 11 22 ​ 3 查看ggq自己的号订阅的全部文章，类似分页，下面0~10就是一次显示10条 ​ lrange likearticle:ggqid 0 9 ​ 商品评论 ​ 商品ID key 和 value评论信息 ​ 按时间顺序 4. Set4.1 常用指令1234567891011121314151617181920添加元素SADD key member [member ...]删除元素SREM key member [member ...]遍历集合中的所有元素SMEMBERS key判断元素是否在集合中SISMEMBER key member获取集合中的元素总数SCARD key从集合中随机弹出一个元素，元素不删除SRANDMEMBER key [数字]从集合中随机弹出一个元素，出一个删一个SPOP key [数字]集合运算SDIFF key [key ...] # 属于A但不属于B的元素构成的集合SINTER key [key ...] # 属于A同时也属于B的共同拥有的元素构成的集合SUNION key [key ...] # 属于A或者属于B的元素合并后的集合 4.2 应用场景抽奖 1 用户ID，立即参与按钮 sadd key 用户ID 2 显示已经有多少人参与了，上图23208人参加 SCARD key 3 抽奖(从set中任意选取N个中奖人) SRANDMEMBER key 2 随机抽奖2个人，元素不删除 SPOP key 3 随机抽奖3个人，元素会删除 ​ 集合运算 共同好友,共同关注 ​ 可能认识的人 5. sortedSet(Zset)向有序集合中加入一个元素和该元素的分数 5.1123456789101112131415161718192021ZADD key score member [score member ...]按照元素分数从小到大的顺序返回索引从start到stop之间的所有元素ZRANGE key start stop [WITHSCORES]获取元素的分数ZSCORE key member删除元素ZREM key member [member ...]获取指定分数范围的元素ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]增加某个元素的分数ZINCRBY key increment member获取集合中元素的数量ZCARD key获得指定分数范围内的元素个数ZCOUNT key min max按照排名范围删除元素ZREMRANGEBYRANK key start stop获取元素的排名ZRANK key member # 从小到大ZREVRANK key member # 从大到小 5.2 应用场景​ 商品排行 ​ 抖音热搜 incrby ​ 展示多少条 zrange min max 5.3 案例实战第六章 redis新类型bitmap&#x2F;hyperloglgo&#x2F;GEO存的进+取得快+多统计 亿级系统中常见的四种统计统计的类型 聚合统计 统计多个集合元素的聚合结果，就是前面讲解过的交差并等集合统计 交并差集和聚合函数的应用 排序统计 抖音视频最新评论留言的场景，请你设计一个展现列表。 考察你的数据结构和设计思路 设计案例和回答思路 每个商品评价对应一个List集合，这个List包含了对这个商品的所有评论，而且会按照评论时间保存这些评论， 每来一个新评论就用LPUSH命令把它插入List的队头。但是，如果在演示第二页前，又产生了一个新评论， 第2页的评论不一样了。原因： List是通过元素在List中的位置来排序的，当有一个新元素插入时，原先的元素在List中的位置都后移了一位， 原来在第1位的元素现在排在了第2位，当LRANGE读取时，就会读到旧元素。 在⾯对需要展示最新列表、排行榜等场景时， 如果数据更新频繁或者需要分页显示，建议使⽤ZSet 二值统计 集合元素的取值就只有0和1两种。 在钉钉上班签到打卡的场景中，我们只用记录有签到(1)或没签到(0) bitmap 基数统计 指统计⼀个集合中不重复的元素个数 见hyperloglog 1. BitMap1.1 常用指令1.2应用场景​ 按字节(8位)扩容 ​ setbit key offset value 偏移位从0开始算 value 只能是01 ​ 由0和1状态表现的二进制位的bit数组 ​ 用于状态统计 ​ 2. HyperLogLog2.1 常用指令2.2应用场景3. GEO3.1 常用指令3.2应用场景第七 章 布隆过滤器​ 由一个初值都为零的bit数组和多个哈希函数构成， ​ 用来快速判断某个数据是否存在 ​ 判断结果没有的一定没有,有的大概率有 只添加不删除 ​ 多重hash linux安装布隆过滤器的两种方式 采用docker安装RedisBloom，推荐 Redis 在 4.0 之后有了插件功能（Module），可以使用外部的扩展功能， 可以使用 RedisBloom 作为 Redis 布隆过滤器插件。 docker run -p 6379:6379 –name&#x3D;redis6379bloom -d redislabs&#x2F;rebloom docker exec -it redis6379bloom &#x2F;bin&#x2F;bash redis-cli 常用指令123456bf.reserve key error_rate的值 initial_size 的值 默认的error_rate是 0.01，默认的initial_size是 100。bf.add key 值bf.exists key 值bf.madd 一次添加多个元素bf.mexists 一次查询多个元素是否存在 Redis高级学习目标目标1：能够说出redis中的数据删除策与略淘汰策略 目标2：能够说出主从复制的概念，工作流程以及场景问题及解决方案 目标3：能够说出哨兵的作用以及工作原理，以及如何启用哨兵 目标4：能够说出集群的架构设计，完成集群的搭建 目标5：能够说出缓存预热，雪崩，击穿，穿透的概念，能说出redis的相关监控指标 1.数据删除与淘汰策略1.1 过期数据1.1.1 Redis中的数据特征Redis是一种内存级数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态 TTL返回的值有三种情况：正数，-1，-2 正数：代表该数据在内存中还能存活的时间 -1：永久有效的数据 2 ：已经过期的数据 或被删除的数据 或 未定义的数据 删除策略就是针对已过期数据的处理策略，已过期的数据是真的就立即删除了吗？其实也不是，我们会有多种删除策略，是分情况的，在不同的场景下使用不同的删除方式会有不同效果，这也正是我们要将的数据的删除策略的问题 1.1.2 时效性数据的存储结构在Redis中，如何给数据设置它的失效周期呢？数据的时效在redis中如何存储呢？看下图： 过期数据是一块独立的存储空间，Hash结构，field是内存地址，value是过期时间，保存了所有key的过期描述，在最终进行过期处理的时候，对该空间的数据进行检测， 当时间到期之后通过field找到内存该地址处的数据，然后进行相关操作。 1.2 数据删除策略1.2.1 数据删除策略的目标在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或 内存泄露 针对过期数据要进行删除的时候都有哪些删除策略呢？ 1.定时删除 2.惰性删除 3.定期删除 1.2.2 定时删除创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作 优点：节约内存，到时就删除，快速释放掉不必要的内存占用 缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量 总结：用处理器性能换取存储空间（拿时间换空间） 1.2.3 惰性删除数据到达过期时间，不做处理。等下次访问该数据时，我们需要判断 如果未过期，返回数据 发现已过期，删除，返回不存在 优点：节约CPU性能，发现必须删除的时候才删除 缺点：内存压力很大，出现长期占用内存的数据 总结：用存储空间换取处理器性能（拿时间换空间） 1.2.4 定期删除定时删除和惰性删除这两种方案都是走的极端，那有没有折中方案？ 我们来讲redis的定期删除方案： Redis启动服务器初始化时，读取配置server.hz的值，默认为10 即每100ms一次 每秒钟执行server.hz次serverCron()——–&gt;databasesCron()———&gt;activeExpireCycle() **activeExpireCycle()*对每个expires[]逐一进行检测，每次执行耗时：250ms&#x2F;server.hz 对某个expires[*]检测时，随机挑选W个key检测 1234567如果key超时，删除key如果一轮中删除的key的数量&gt;W*25%，循环该过程如果一轮中删除的key的数量≤W*25%，检查下一个expires[*]，0-15循环W取值=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值 参数current_db用于记录activeExpireCycle() 进入哪个expires[*] 执行 如果activeExpireCycle()执行时间到期，下次从current_db继续向下执行 总的来说：定期删除就是周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度 特点1：CPU性能占用设置有峰值，检测频度可自定义设置 特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理 总结：周期性抽查存储空间（随机抽查，重点抽查） 1.2.5 删除策略对比1：定时删除： 123节约内存，无占用,不分时段占用CPU资源，频度高,拿时间换空间 2：惰性删除： 123内存占用严重延时执行，CPU利用率高拿空间换时间 3：定期删除： 123内存定期随机清理每秒花费固定的CPU资源维护内存随机抽查，重点抽查 1.3 数据淘汰策略（逐出算法）1.3.1 淘汰策略概述什么叫数据淘汰策略？什么样的应用场景需要用到数据淘汰策略？ 当新数据进入redis时，如果内存不足怎么办？在执行每一个命令前，会调用**freeMemoryIfNeeded()**检测内存是否充足。如果内存不满足新 加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。 注意：逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕， 如不能达到内存清理的要求，将出现错误信息如下 1(error) OOM command not allowed when used memory &gt;&#x27;maxmemory&#x27; 1.3.2 策略配置影响数据淘汰的相关配置如下： 1：最大可使用内存，即占用物理内存的比例，默认值为0，表示不限制。生产环境中根据需求设定，通常设置在50%以上 1maxmemory ?mb 2：每次选取待删除数据的个数，采用随机获取数据的方式作为待检测删除数据 1maxmemory-samples count 3：对数据进行删除的选择策略 1maxmemory-policy policy 那数据删除的策略policy到底有几种呢？一共是3类8种 第一类：检测易失数据（可能会过期的数据集server.db[i].expires ） 1234volatile-lru：挑选最近最少使用的数据淘汰volatile-lfu：挑选最近使用次数最少的数据淘汰volatile-ttl：挑选将要过期的数据淘汰volatile-random：任意选择数据淘汰 第二类：检测全库数据（所有数据集server.db[i].dict ） 123allkeys-lru：挑选最近最少使用的数据淘汰allkeLyRs-lfu：：挑选最近使用次数最少的数据淘汰allkeys-random：任意选择数据淘汰，相当于随机 第三类：放弃数据驱逐 1no-enviction（驱逐）：禁止驱逐数据(redis4.0中默认策略)，会引发OOM(Out Of Memory) 注意：这些策略是配置到哪个属性上？怎么配置？如下所示 1maxmemory-policy volatile-lru 数据淘汰策略配置依据 使用INFO命令输出监控信息，查询缓存 hit 和 miss 的次数，根据业务需求调优Redis配置 2.主从复制2.1 主从复制简介2.1.1 高可用首先我们要理解互联网应用因为其独有的特性我们演化出的三高架构 高并发 应用要提供某一业务要能支持很多客户端同时访问的能力，我们称为并发，高并发意思就很明确了 高性能 性能带给我们最直观的感受就是：速度快，时间短 高可用 可用性：一年中应用服务正常运行的时间占全年时间的百分比，如下图：表示了应用服务在全年宕机的时间 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;1.Redis高级【海量资源尽在 】&#x2F;1.Redis高级&#x2F;讲义-md版本&#x2F;img&#x2F;5.png 我们把这些时间加在一起就是全年应用服务不可用的时间，然后我们可以得到应用服务全年可用的时间 4小时27分15秒+11分36秒+2分16秒&#x3D;4小时41分7秒&#x3D;16867秒 1年&#x3D;3652460*60&#x3D;31536000秒 可用性&#x3D;（31536000-16867）&#x2F;31536000*100%&#x3D;99.9465151% 业界可用性目标**5个9，即99.999%**，即服务器年宕机时长低于315秒，约5.25分钟 2.1.2 主从复制概念知道了三高的概念之后，我们想：你的“Redis”是否高可用？那我们要来分析单机redis的风险与问题 问题1.机器故障 现象：硬盘故障、系统崩溃 本质：数据丢失，很可能对业务造成灾难性打击 结论：基本上会放弃使用redis. 问题2.容量瓶颈 现象：内存不足，从16G升级到64G，从64G升级到128G，无限升级内存 本质：穷，硬件条件跟不上 结论：放弃使用redis 结论： 为了避免单点Redis服务器故障，准备多台服务器，互相连通。将数据复制多个副本保存在不同的服务器上，连接在一起，并保证数据是同步的。即使有其中一台服务器宕机，其他服务器依然可以继续提供服务，实现Redis的高可用，同时实现数据冗余备份。 多台服务器连接方案： 提供数据方：master 主服务器，主节点，主库主客户端 接收数据方：slave 从服务器，从节点，从库 从客户端 需要解决的问题： 数据同步（master的数据复制到slave中） 这里我们可以来解释主从复制的概念： 概念：主从复制即将master中的数据即时、有效的复制到slave中 特征：一个master可以拥有多个slave，一个slave只对应一个master 职责：master和slave各自的职责不一样 master: 12345写数据执行写操作时，将出现变化的数据自动同步到slave读数据（可忽略） slave: 123读数据写数据（禁止） 2.1.3 主从复制的作用 读写分离：master写、slave读，提高服务器的读写负载能力 负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数 量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量 故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复 数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式 高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案 2.2 主从复制工作流程主从复制过程大体可以分为3个阶段 建立连接阶段（即准备阶段） 数据同步阶段 命令传播阶段（反复同步） 而命令的传播其实有4种，分别如下： 2.2.1 主从复制的工作流程（三个阶段）2.2.1.1 阶段一：建立连接建立slave到master的连接，使master能够识别slave，并保存slave端口号 流程如下： 步骤1：设置master的地址和端口，保存master信息 步骤2：建立socket连接 步骤3：发送ping命令（定时器任务） 步骤4：身份验证 步骤5：发送slave端口信息 至此，主从连接成功！ 当前状态： slave：保存master的地址与端口 master：保存slave的端口 总体：之间创建了连接的socket master和slave互联 接下来就要通过某种方式将master和slave连接到一起 方式一：客户端发送命令 1slaveof masterip masterport 方式二：启动服务器参数 1redis-server --slaveof masterip masterport 方式三：服务器配置（主流方式） 1slaveof masterip masterport slave系统信息 12master_link_down_since_secondsmasterhost &amp; masterport master系统信息 1uslave_listening_port(多个) 主从断开连接 断开slave与master的连接，slave断开连接后，不会删除已有数据，只是不再接受master发送的数据 1slaveof no one 授权访问 master客户端发送命令设置密码 1requirepass password master配置文件设置密码 12config set requirepass passwordconfig get requirepass slave客户端发送命令设置密码 1auth password slave配置文件设置密码 1masterauth password slave启动服务器设置密码 1redis-server –a password 2.2.1.2 阶段二：数据同步 在slave初次连接master后，复制master中的所有数据到slave 将slave的数据库状态更新成master当前的数据库状态 同步过程如下： 步骤1：请求同步数据 步骤2：创建RDB同步数据 步骤3：恢复RDB同步数据 步骤4：请求部分同步数据 步骤5：恢复部分同步数据 至此，数据同步工作完成！ 当前状态： slave：具有master端全部数据，包含RDB过程接收的数据 master：保存slave当前数据同步的位置 总体：之间完成了数据克隆 数据同步阶段master说明 1：如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行 2：复制缓冲区大小设定不合理，会导致数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。 1repl-backlog-size ?mb master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执 行bgsave命令和创建复制缓冲区 数据同步阶段slave说明 为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务 1slave-serve-stale-data yes|no 数据同步阶段，master发送给slave信息可以理解master是slave的一个客户端，主动向slave发送命令 多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰 slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间的节点既是master，也是 slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟 较大，数据一致性变差，应谨慎选择 2.2.1.3 阶段三：命令传播 当master数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态，同步的动作称为命令传播 master将接收到的数据变更命令发送给slave，slave接收命令后执行命令 命令传播阶段的部分复制 命令传播阶段出现了断网现象： 网络闪断闪连：忽略 短时间网络中断：部分复制 长时间网络中断：全量复制 这里我们主要来看部分复制，部分复制的三个核心要素 服务器的运行 id（run id） 主服务器的复制积压缓冲区 主从服务器的复制偏移量 服务器运行ID（runid） 12345678910概念：服务器运行ID是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行id组成：运行id由40位字符组成，是一个随机的十六进制字符例如：fdc9ff13b9bbaab28db42b3d50f852bb5e3fcdce作用：运行id被用于在服务器间进行传输，识别身份如果想两次操作均对同一台服务器进行，必须每次操作携带对应的运行id，用于对方识别实现方式：运行id在每台服务器启动时自动生成的，master在首次连接slave时，会将自己的运行ID发送给slave，slave保存此ID，通过info Server命令，可以查看节点的runid 复制缓冲区 123456概念：复制缓冲区，又名复制积压缓冲区，是一个先进先出（FIFO）的队列，用于存储服务器执行过的命令，每次传播命令，master都会将传播的命令记录下来，并存储在复制缓冲区 复制缓冲区默认数据存储空间大小是1M 当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列作用：用于保存master收到的所有指令（仅影响数据变更的指令，例如set，select）数据来源：当master接收到主客户端的指令时，除了将指令执行，会将该指令存储到缓冲区中 复制缓冲区内部工作原理： 组成 偏移量 概念：一个数字，描述复制缓冲区中的指令字节位置 分类： master复制偏移量：记录发送给所有slave的指令字节对应的位置（多个） slave复制偏移量：记录slave接收master发送过来的指令字节对应的位置（一个） 作用：同步信息，比对master与slave的差异，当slave断线后，恢复数据使用 数据来源： master端：发送一次记录一次 slave端：接收一次记录一次 字节值 工作原理 通过offset区分不同的slave当前数据传播的差异 master记录已发送的信息对应的offset slave记录已接收的信息对应的offset 2.2.2 流程更新(全量复制&#x2F;部分复制)我们再次的总结一下主从复制的三个阶段的工作流程： 2.2.3 心跳机制什么是心跳机制？ 进入命令传播阶段候，master与slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线 master心跳： 内部指令：PING 周期：由repl-ping-slave-period决定，默认10秒 作用：判断slave是否在线 查询：INFO replication 获取slave最后一次连接时间间隔，lag项维持在0或1视为正常 slave心跳任务 内部指令：REPLCONF ACK {offset} 周期：1秒 作用1：汇报slave自己的复制偏移量，获取最新的数据变更指令 作用2：判断master是否在线 心跳阶段注意事项： 当slave多数掉线，或延迟过高时，master为保障数据稳定性，将拒绝所有信息同步 12min-slaves-to-write 2min-slaves-max-lag 8 slave数量少于2个，或者所有slave的延迟都大于等于8秒时，强制关闭master写功能，停止数据同步 slave数量由slave发送REPLCONF ACK命令做确认 slave延迟由slave发送REPLCONF ACK命令做确认 至此：我们可以总结出完整的主从复制流程： 2.3 主从复制常见问题2.3.1 频繁的全量复制 伴随着系统的运行，master的数据量会越来越大，一旦master重启，runid将发生变化，会导致全部slave的全量复制操作 内部优化调整方案： 1：master内部创建master_replid变量，使用runid相同的策略生成，长度41位，并发送给所有slave 2：在master关闭时执行命令shutdown save，进行RDB持久化,将runid与offset保存到RDB文件中 123repl-id repl-offset通过redis-check-rdb命令可以查看该信息 3：master重启后加载RDB文件，恢复数据，重启后，将RDB文件中保存的repl-id与repl-offset加载到内存中 123master_repl_id=repl master_repl_offset =repl-offset通过info命令可以查看该信息 作用：本机保存上次runid，重启后恢复该值，使所有slave认为还是之前的master 第二种出现频繁全量复制的问题现象：网络环境不佳，出现网络中断，slave不提供服务 问题原因：复制缓冲区过小，断网后slave的offset越界，触发全量复制 最终结果：slave反复进行全量复制 解决方案：修改复制缓冲区大小 1repl-backlog-size ?mb 建议设置如下： 1.测算从master到slave的重连平均时长second 2.获取master平均每秒产生写命令数据总量write_size_per_second 3.最优复制缓冲区空间 &#x3D; 2 * second * write_size_per_second 2.3.2 频繁的网络中断 问题现象：master的CPU占用过高 或 slave频繁断开连接 问题原因 12345slave每1秒发送REPLCONFACK命令到master当slave接到了慢查询时（keys * ，hgetall等），会大量占用CPU性能master每1秒调用复制定时函数replicationCron()，比对slave发现长时间没有进行响应 最终结果：master各种资源（输出缓冲区、带宽、连接等）被严重占用 解决方案：通过设置合理的超时时间，确认是否释放slave 1repl-timeout seconds 该参数定义了超时时间的阈值（默认60秒），超过该值，释放slave 问题现象：slave与master连接断开 问题原因 12345master发送ping指令频度较低master设定超时时间较短ping指令在网络中存在丢包 解决方案：提高ping指令发送的频度 1repl-ping-slave-period seconds 超时时间repl-time的时间至少是ping指令频度的5到10倍，否则slave很容易判定超时 2.3.3 数据不一致问题现象：多个slave获取相同数据不同步 问题原因：网络信息不同步，数据发送有延迟 解决方案 123优化主从间的网络环境，通常放置在同一个机房部署，如使用阿里云等云服务器时要注意此现象监控主从节点延迟（通过offset）判断，如果slave延迟过大，暂时屏蔽程序对该slave的数据访问 1slave-serve-stale-data yes|no 开启后仅响应info、slaveof等少数命令（慎用，除非对数据一致性要求很高） 3.哨兵模式3.1 哨兵简介3.1.1 哨兵概念首先我们来看一个业务场景：如果redis的master宕机了，此时应该怎么办？ 那此时我们可能需要从一堆的slave中重新选举出一个新的master，那这个操作过程是什么样的呢？这里面会有什么问题出现呢？ 要实现这些功能，我们就需要redis的哨兵，那哨兵是什么呢？ 哨兵 哨兵(sentinel) 是一个分布式系统，用于对主从结构中的每台服务器进行监控，当出现故障时通过投票机制选择新的master并将所有slave连接到新的master。 3.1.2 哨兵作用哨兵的作用： 监控：监控master和slave 不断的检查master和slave是否正常运行 master存活检测、master与slave运行情况检测 通知（提醒）：当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知 自动故障转移：断开master与slave连接，选取一个slave作为master，将其他slave连接新的master，并告知客户端新的服务器地址 注意：哨兵也是一台redis服务器，只是不提供数据相关服务，通常哨兵的数量配置为单数 3.2 启用哨兵配置哨兵 配置一拖二的主从结构（利用之前的方式启动即可） 配置三个哨兵（配置相同，端口不同），参看sentinel.conf 1：设置哨兵监听的主服务器信息， sentinel_number表示参与投票的哨兵数量 1sentinel monitor master_name master_host master_port sentinel_number 2：设置判定服务器宕机时长，该设置控制是否进行主从切换 1sentinel down-after-milliseconds master_name million_seconds 3：设置故障切换的最大超时时 1sentinel failover-timeout master_name million_seconds 4：设置主从切换后，同时进行数据同步的slave数量，数值越大，要求网络资源越高，数值越小，同步时间越长 1sentinel parallel-syncs master_name sync_slave_number 启动哨兵 1redis-sentinel filename 3.3 哨兵工作原理哨兵在进行主从切换过程中经历三个阶段 监控 通知 故障转移 3.3.1 监控用于同步各个节点的状态信息 获取各个sentinel的状态（是否在线） 获取master的状态 1234master属性 prunid prole：master各个slave的详细信息 获取所有slave的状态（根据master中的slave信息） 12345slave属性 prunid prole：slave pmaster_host、master_port poffset 其内部的工作原理具体如下： 3.3.2 通知sentinel在通知阶段要不断的去获取master&#x2F;slave的信息，然后在各个sentinel之间进行共享，具体的流程如下： 3.3.3 故障转移当master宕机后sentinel是如何知晓并判断出master是真的宕机了呢？我们来看具体的操作流程 当sentinel认定master下线之后，此时需要决定更换master，那这件事由哪个sentinel来做呢？这时候sentinel之间要进行选举，如下图所示： 在选举的时候每一个人手里都有一票，而每一个人的又都想当这个处理事故的人，那怎么办？大家就开始抢，于是每个人都会发出一个指令，在内网里边告诉大家我要当选举人，比如说现在的sentinel1和sentinel4发出这个选举指令了，那么sentinel2既能接到sentinel1的也能接到sentinel4的，接到了他们的申请以后呢，sentinel2他就会把他的一票投给其中一方，投给谁呢？谁先过来我投给谁，假设sentinel1先过来，所以这个票就给到了sentinel1。那么给过去以后呢，现在sentinel1就拿到了一票，按照这样的一种形式，最终会有一个选举结果。对应的选举最终得票多的，那自然就成为了处理事故的人。需要注意在这个过程中有可能会存在失败的现象，就是一轮选举完没有选取，那就会接着进行第二轮第三轮直到完成选举。 接下来就是由选举胜出的sentinel去从slave中选一个新的master出来的工作，这个流程是什么样的呢？ 首先它有一个在服务器列表中挑选备选master的原则 不在线的OUT 响应慢的OUT 与原master断开时间久的OUT 优先原则 ​ 优先级​ offset​ runid 选出新的master之后，发送指令（ sentinel ）给其他的slave： 向新的master发送slaveof no one 向其他slave发送slaveof 新masterIP端口 总结：故障转移阶段 发现问题，主观下线与客观下线 竞选负责人 优选新master 新master上任，其他slave切换master，原master作为slave故障恢复后连接 4.集群cluster现状问题：业务发展过程中遇到的峰值瓶颈 redis提供的服务OPS可以达到10万&#x2F;秒，当前业务OPS已经达到10万&#x2F;秒 内存单机容量达到256G，当前业务需求内存容量1T 使用集群的方式可以快速解决上述问题 4.1 集群简介集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果 集群作用： 分散单台服务器的访问压力，实现负载均衡 分散单台服务器的存储压力，实现可扩展性 降低单台服务器宕机带来的业务灾难 4.2 Cluster集群结构设计数据存储设计： 通过算法设计，计算出key应该保存的位置 将所有的存储空间计划切割成16384份，每台主机保存一部分 注意：每份代表的是一个存储空间，不是一个key的保存空间 将key按照计算出的结果放到对应的存储空间 那redis的集群是如何增强可扩展性的呢？譬如我们要增加一个集群节点 当我们查找数据时，集群是如何操作的呢？ 各个数据库相互通信，保存各个库中槽的编号数据 一次命中，直接返回 一次未命中，告知具体位置 4.3 Cluster集群结构搭建首先要明确的几个要点： 配置服务器（3主3从） 建立通信（Meet） 分槽（Slot） 搭建主从（master-slave） Cluster配置 是否启用cluster，加入cluster节点 1cluster-enabled yes|no cluster配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容 1cluster-config-file filename 节点服务响应超时时间，用于判定该节点是否下线或切换为从节点 1cluster-node-timeout milliseconds master连接的slave最小数量 1cluster-migration-barrier min_slave_number Cluster节点操作命令 查看集群节点信息 1cluster nodes 更改slave指向新的master 1cluster replicate master-id 发现一个新节点，新增master 1cluster meet ip:port 忽略一个没有solt的节点 1cluster forget server_id 手动故障转移 1cluster failover 集群操作命令： 创建集群 1redis-cli –-cluster create masterhost1:masterport1 masterhost2:masterport2 masterhost3:masterport3 [masterhostn:masterportn …] slavehost1:slaveport1 slavehost2:slaveport2 slavehost3:slaveport3 -–cluster-replicas n 注意：master与slave的数量要匹配，一个master对应n个slave，由最后的参数n决定 master与slave的匹配顺序为第一个master与前n个slave分为一组，形成主从结构 添加master到当前集群中，连接时可以指定任意现有节点地址与端口 1redis-cli --cluster add-node new-master-host:new-master-port now-host:now-port 添加slave 1redis-cli --cluster add-node new-slave-host:new-slave-port master-host:master-port --cluster-slave --cluster-master-id masterid 删除节点，如果删除的节点是master，必须保障其中没有槽slot 1redis-cli --cluster del-node del-slave-host:del-slave-port del-slave-id 重新分槽，分槽是从具有槽的master中划分一部分给其他master，过程中不创建新的槽 1redis-cli --cluster reshard new-master-host:new-master:port --cluster-from src- master-id1, src-master-id2, src-master-idn --cluster-to target-master-id -- cluster-slots slots 注意：将需要参与分槽的所有masterid不分先后顺序添加到参数中，使用，分隔 指定目标得到的槽的数量，所有的槽将平均从每个来源的master处获取 重新分配槽，从具有槽的master中分配指定数量的槽到另一个master中，常用于清空指定master中的槽 1redis-cli --cluster reshard src-master-host:src-master-port --cluster-from src- master-id --cluster-to target-master-id --cluster-slots slots --cluster-yes 5.企业级解决方案5.1 缓存预热场景：“宕机” 服务器启动后迅速宕机 问题排查： 1.请求数量较高，大量的请求过来之后都需要去从缓存中获取数据，但是缓存中又没有，此时从数据库中查找数据然后将数据再存入缓存，造成了短期内对redis的高强度操作从而导致问题 2.主从之间数据吞吐量较大，数据同步操作频度较高 解决方案： 前置准备工作： 1.日常例行统计数据访问记录，统计访问频度较高的热点数据 2.利用LRU数据删除策略，构建数据留存队列例如：storm与kafka配合 准备工作： 1.将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据 2.利用分布式多服务器同时进行数据读取，提速数据加载过程 3.热点数据主从同时预热 实施： 4.使用脚本程序固定触发数据预热过程 5.如果条件允许，使用了CDN（内容分发网络），效果会更好 总的来说：缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 5.2 缓存雪崩场景：数据库服务器崩溃，一连串的场景会随之儿来 1.系统平稳运行过程中，忽然数据库连接量激增 2.应用服务器无法及时处理请求 3.大量408，500错误页面出现 4.客户反复刷新页面获取数据 5.数据库崩溃 6.应用服务器崩溃 7.重启应用服务器无效 8.Redis服务器崩溃 9.Redis集群崩溃 10.重启数据库后再次被瞬间流量放倒 问题排查： 1.在一个较短的时间内，缓存中较多的key集中过期 2.此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据 3.数据库同时接收到大量的请求无法及时处理 4.Redis大量请求被积压，开始出现超时现象 5.数据库流量激增，数据库崩溃 6.重启后仍然面对缓存中无数据可用 7.Redis服务器资源被严重占用，Redis服务器崩溃 8.Redis集群呈现崩塌，集群瓦解 9.应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃 10.应用服务器，redis，数据库全部重启，效果不理想 总而言之就两点：短时间范围内，大量key集中过期 解决方案 思路： 1.更多的页面静态化处理 2.构建多级缓存架构 ​ Nginx缓存+redis缓存+ehcache缓存 3.检测Mysql严重耗时业务进行优化 ​ 对数据库的瓶颈排查：例如超时查询、耗时较高事务等 4.灾难预警机制 ​ 监控redis服务器性能指标 ​ CPU占用、CPU使用率 ​ 内存容量 ​ 查询平均响应时间 ​ 线程数 5.限流、降级 短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问 落地实践： 1.LRU与LFU切换 2.数据有效期策略调整 ​ 根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟 ​ 过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量 3.超热数据使用永久key 4.定期维护（自动+人工） ​ 对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时 5.加锁：慎用！ 总的来说：缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的 出现（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。 5.3 缓存击穿场景：还是数据库服务器崩溃，但是跟之前的场景有点不太一样 1.系统平稳运行过程中 2.数据库连接量瞬间激增 3.Redis服务器无大量key过期 4.Redis内存平稳，无波动 5.Redis服务器CPU正常 6.数据库崩溃 问题排查： 1.Redis中某个key过期，该key访问量巨大 2.多个数据请求从服务器直接压到Redis后，均未命中 3.Redis在短时间内发起了大量对数据库中同一数据的访问 总而言之就两点：单个key高热数据，key过期 解决方案： 1.预先设定 ​ 以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长 注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势 2.现场调整 ​ 监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key 3.后台刷新数据 ​ 启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失 4.二级缓存 ​ 设置不同的失效时间，保障不会被同时淘汰就行 5.加锁 ​ 分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！ 总的来说：缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问，导致对数 据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过 期监控难度较高，配合雪崩处理策略即可。 5.4 缓存穿透场景：数据库服务器又崩溃了，跟之前的一样吗？ 1.系统平稳运行过程中 2.应用服务器流量随时间增量较大 3.Redis服务器命中率随时间逐步降低 4.Redis内存平稳，内存无压力 5.Redis服务器CPU占用激增 6.数据库服务器压力激增 7.数据库崩溃 问题排查： 1.Redis中大面积出现未命中 2.出现非正常URL访问 问题分析： 获取的数据在数据库中也不存在，数据库查询未得到对应数据 Redis获取到null数据未进行持久化，直接返回 下次此类数据到达重复上述过程 出现黑客攻击服务器 解决方案： 1.缓存null ​ 对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟 2.白名单策略 ​ 提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时放行，加载异常数据时直接拦截（效率偏低） ​ 使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略） 2.实施监控 ​ 实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比 ​ 非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象 ​ 活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象 ​ 根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营） 4.key加密 ​ 问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验 ​ 例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问 总的来说：缓存击穿是指访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。 无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。 5.5 性能指标监控redis中的监控指标如下： 性能指标：Performance 响应请求的平均时间: 1&gt;latency 平均每秒处理请求总数 1&gt;instantaneous_ops_per_sec 缓存查询命中率（通过查询总次数与查询得到非nil数据总次数计算而来） 12&gt;hit_rate(calculated) 内存指标：Memory 当前内存使用量 1&gt;used_memory 内存碎片率（关系到是否进行碎片整理） 1&gt;mem_fragmentation_ratio 为避免内存溢出删除的key的总数量 1&gt;evicted_keys 基于阻塞操作（BLPOP等）影响的客户端数量 1&gt;blocked_clients 基本活动指标：Basic_activity 当前客户端连接总数 1&gt;connected_clients 当前连接slave总数 1&gt;connected_slaves 最后一次主从信息交换距现在的秒 1&gt;master_last_io_seconds_ago key的总数 1&gt;keyspace 持久性指标：Persistence 当前服务器最后一次RDB持久化的时间 1&gt;rdb_last_save_time 当前服务器最后一次RDB持久化后数据变化总量 1&gt;rdb_changes_since_last_save 错误指标：Error 被拒绝连接的客户端总数（基于达到最大连接值的因素） 1&gt;rejected_connections key未命中的总次数 1&gt;keyspace_misses 主从断开的秒数 1&gt;master_link_down_since_seconds 要对redis的相关指标进行监控，我们可以采用一些用具： CloudInsight Redis Prometheus Redis-stat Redis-faina RedisLive zabbix 也有一些命令工具： benchmark 测试当前服务器的并发性能 1&gt;redis-benchmark [-h ] [-p ] [-c ] [-n &lt;requests]&gt; [-k ] 范例1：50个连接，10000次请求对应的性能 1&gt;redis-benchmark 范例2：100个连接，5000次请求对应的性能 1&gt;redis-benchmark -c 100 -n 5000 redis-cli ​ monitor：启动服务器调试信息 1&gt;monitor slowlog：慢日志 获取慢查询日志 1&gt;slowlog [operator] ​ get ：获取慢查询日志信息 ​ len ：获取慢查询日志条目数 ​ reset ：重置慢查询日志 相关配置 12&gt;slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙&gt;slowlog-max-len 100 #设置慢查询命令对应的日志显示长度，单位：命令数 Redis的高效在于其纯内存运算，但是有得就有失，数据全部存在内存中意味着一旦宕机，数据将会全部丢失，因此必须需要一种机制来保证Redis中的数据不会因为故障而丢失，这就需要Redis拥有数据持久化的能力。 6. 持久化Redis的持久化机制有两种，一种是快照，也就是RDB（Redis DataBase），一种是AOF（Append Only File）日志。 1.1 快照（RDB）快照是一次性的全量备份，将某一时刻的全量数据以二进制序列化的形式存储，在空间上非常紧凑，能大大缩小存储所用的空间。 Redis是单线程，而文件IO操作是不支持多路复用的。这难道意味着在进行内存快照时Redis需要停止服务？这当然是不行的，那有指令时服务，没指令时持久化这样边持久化边服务？可是这样的话持久化的同时内存数据还在被指令修改，如果在持有化一个大的Hash字典时，过来一个指令把这个字段删了，这个可怎么办? 显然这样也不行。 为此，Redis使用操作系统的多进程COW（Copy On Write）机制来实现快照持久化。 Redis在持久化时会调用glibc的函数fork产生一个子进程，快照持久化交给子进程处理，父进程继续提供服务。子进程生成时和父进程共用代码段和数据段。也就是说这时间父子进程共享内存数据，因此在分离的一瞬间，内存消耗几乎没有。接下来子内存进行数据持久化，他仅仅是读取，不会修改内存。而父进程对外提供服务，修改数据，但是操作系统的COW机制会进行数据段页面的分离，数据段由操作系统的页面组合而成，父进程修改数据时，COW机制就将数据所在页复制一份出来，父进程在这个复制出来的数据也修改，此时原数据页也就是子线程访问的数据页还是原样，也就是子进程所看到的数据在子进程产生的一瞬间就已经凝固了，可以安心复制，这也是为什么这种持久化方法称为快照原因。 随着父进程的修改，会有越来越多的页面被赋值，但是最多也就是全复制，达到原内存空间的二倍，但是这在大数据量情况下很难发生，因为总会有冷数据存在，而且可能占据多数，所以复制的一般只会是其中的一部分。另外提一下：一个页面的大小是4K。 1.2 AOF日志AOF日志是连续性的增量备份，记录的是修改内存数据的指令记录文本。这样就可以通过对一个空的Redis实例顺序执行记录的命令，也就是重放，来复原实例。Redis在收到修改指令后，会先进行校验，如果没问题，会首先把指令追加记录磁盘上的AOF日志中，然后再执行指令，这样即使突发宕机，重放时也能重放到这个指令。 AOF日志随着运行时间的增长会变的越来越庞大，Redis重启时需要加载AOF日志进行指令重放所需的时间也会更加漫长，所以需要定期对AOF重写，进行瘦身。 1.2.1 AOF重写AOF重写原理就是开辟一个子进程，然后将内存数据遍历并转换成指令，再记录到一个新的AOF文件中，完毕后再将期间发生的增量AOF日志追加到新的AOF日志中，替换旧的AOF文件，就完成了AOF重写的工作，完成了瘦身。 1.2.2 fsyncAOF日志是以文件方式存在的，程序对AOF日志进行操作时，实际上是先将内容写到内核为文件描述符分配的一块内存缓存上，然后内核异步将数据写入磁盘的。 但是如果机器突然宕机，内存缓存中的数据还没来的及写入磁盘，就会出现日志的丢失。Linux的gilbc提了了fsync(int fd)函数来强制把指定文件的内存缓存数据写入到磁盘中，实时使用fsync就能保证AOF日志不丢失。但是fsync涉及到磁盘写入，相较于内存操作会慢很多，如果每一个指令都fsync一次，Redis纯内存操作所带来的优势就不存在了。 因此目前主流的做法是Redis每隔1s执行一个fsync，1s是可配置的，可以根据需要配置。这样就在保持高效能的同时尽可能的减少日志丢失。Redis也提供了另外两种策略：一种是永不fsync，由操作系统决定什么时间将内存缓存同步到磁盘，这样无法掌控，很不安全。另一种是一次指令fsync一次，然后不会丢日志，单缺点上面也说过了，生产并不推荐。 Redis4.0新增了异步模型，可以打开fsync的异步处理开关，此时主线程不进行fsync，而是生成任务放到专门的fsync队列中去，由专门的fsync异步线程处理。 1.3 持久化选在从节点无论是快照还是AOF，都比较消耗资源。快照需要遍历整个内存，大块磁盘读写加重系统负载。AOF的fsync是一个耗时的IO操作，也会影响Redis性能，加重系统IO负担。因此Redis的持久化一般并不安排在主节点，而是在从节点进行，从节点没有客户端请求的压力，资源比较充足。但是如果出现网络分区，从节点连不上主节点，而主节点又宕机了，就会出现数据丢失产生数据一致性的问题。因此生产环境需要做好网络连通性检测，保证出现问题时能快速修复，除此之外可以再挂一个从节点，这样只要有一个从节点数据同步正常，数据就不会丢失。 1.4 Redis4.0的混合持久化Redis重启时，很少使用RDB来恢复数据，因为会丢失最后一次快照之后的数据。但是使用AOF日志重放，效率上又会慢很多。因此Redis4.0提供了混合持久化的策略，就是RDB和AOF同时使用。RDB正常持久化，而AOF不在记录全量指令，而是记录每次RDB快照之后的增量AOF，这样Redis重启时就可以先加载RDB的内容，然后再重放AOF日志，效率大大提升。 总结说出redis中的数据删除策与略淘汰策略 说出主从复制的概念，工作流程以及场景问题及解决方案 说出哨兵的作用以及工作原理，以及如何启用哨兵 说出集群的架构设计，完成集群的搭建 说出缓存预热，雪崩，击穿，穿透的概念，能说出redis的相关监控指标 说出持久化策略的其中的一些细节 第八章 缓存预热+缓存雪崩+缓存击穿+缓存穿透缓存预热统计热点数据(访问频率高的)提前存入缓存中(数据多 多服务并行写) 具体 nginx + lua 将访问量上报到消息队列(?) ​ 要统计出来当前最新的实时的热数据是哪些，我们就得将商品详情页访问的请求对应的流量，日志，实时上报 到kafka中 缓存雪崩发生: ​ redis主机挂了，Redis 全盘崩溃, ​ 比如缓存中有大量数据同时过期 解决: ​ 主从+哨兵 ​ 集群 ​ ehcache本地缓存 + Hystrix或者阿里sentinel限流&amp;降级 ​ 开启Redis持久化机制aof&#x2F;rdb，尽快恢复缓存集群 缓存穿透发生: ​ 请求去查询一条记录，先redis后mysql发现都查询不到该条记录， ​ 但是请求每次都会打到数据库上面去，导致后台数据库压力暴增， ​ 这种现象我们称为缓存穿透，这个redis变成了一个摆设。。。。。。 ​ 简单说就是本来无一物，既不在Redis缓存中，也不在数据库中 危害: ​ 第一次来查询后，一般我们有回写redis机制 ​ 第二次来查的时候redis就有了，偶尔出现穿透现象一般情况无关紧要 解决: 方案1：空对象缓存或者缺省值 一般ok but 黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。 可能会导致你的数据库由于压力过大而宕掉 方案2：Google布隆过滤器Guava解决缓存穿透 只能单机使用 Guava 中布隆过滤器的实现算是比较权威的， 所以实际项目中我们不需要手动实现一个布隆过滤器 方案3：Redis布隆过滤器解决缓存穿透 缓存击穿发生: ​ 大量的请求同时查询一个 key 时， ​ 此时这个key正好失效了，就会导致大量的请求都打到数据库上面去 ​ 简单说就是热点key突然失效了，暴打mysql 危害: ​ 会造成某一时刻数据库请求量过大，压力剧增。 解决 方案2：对于访问频繁的热点key，干脆就不设置过期时间 方案3：互斥独占锁防止击穿 多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。 其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 案例第九章 Redis分布式锁第十一 章 经典五种数据类型底层实现dictEntry启动流程到内部的表: 源码结构体及解析 将dictEntry理解 &lt;String(sds),redisObject&gt; 不一定全对 key 是字符串，但是 Redis 没有直接使用 C 的字符数组，而是存储在redis自定义的 SDS(简单动态字符串,simple dynimic string)中。 value 既不是直接作为字符串存储，也不是直接存储在 SDS 中，而是存储在redisObject 中。 set hello word为例，因为Redis是KV键值对的数据库，每个键值对都会有一个dictEntry(源码位置：dict.h)， 里面指向了key和value的指针，next 指向下一个 dictEntry。 redisObject 后面的类型会加深对redisObject的理解 SringString的三种编码格式 int当字符串键值的内容可以用一个64位有符号整形来表示时，Redis会将键值转化为long型来进行存储，此时即对应 OBJ_ENCODING_INT 编码类型。内部的内存结构表示如下: Redis 启动时会预先建立 10000 个分别存储 09999 的 redisObject 变量作为共享对象，这就意味着如果 set字符串的键值在 010000 之间的话，则可以 直接指向共享对象 而不需要再建立新对象，此时键值不占空间！ set k1 123 set k2 123 保存long 型(长整型)的64位(8个字节)有符号整数 最多19位只能整数浮点数就是字符串值了 embstr对于长度小于 44的字符串，Redis 对键值采用OBJ_ENCODING_EMBSTR 方式，EMBSTR 顾名思义即：embedded string，表示嵌入式的String。从内存结构上来讲 即字符串 sds结构体与其对应的 redisObject 对象分配在同一块连续的内存空间，字符串sds嵌入在redisObject对象之中一样。 代表 embstr 格式的 SDS(Simple Dynamic String 简单动态字符串),保存长度小于44字节的字符串 Redis中字符串的实现,SDS有多种结构（sds.h）： sdshdr5、(2^5&#x3D;32byte) sdshdr8、(2 ^ 8&#x3D;256byte) sdshdr16、(2 ^ 16&#x3D;65536byte&#x3D;64KB) sdshdr32、 (2 ^ 32byte&#x3D;4GB) sdshdr64，2的64次方byte＝17179869184G用于存储不同的长度的字符串。 len 表示 SDS 的长度，使我们在获取字符串长度的时候可以在 O(1)情况下拿到，而不是像 C 那样需要遍历一遍字符串。 alloc 可以用来计算 free 就是字符串已经分配的未使用的空间，有了这个值就可以引入预分配空间的算法了，而不用去考虑内存分配的问题。 buf 表示字符串数组，真存数据的。 raw保存长度大于44字节的字符串 当字符串的键值为长度大于44的超长字符串时，Redis 则会将键值的内部编码方式改为OBJ_ENCODING_RAW格式，这与OBJ_ENCODING_EMBSTR编码方式的不同之处在于，此时动态字符串sds的内存与其依赖的redisObject的内存不再连续了 set hello 观察以String为例的redisObject实际上五种常用的数据类型的任何一种，都是通过 redisObject 来存储的。 debug指令可能出现异常 (error) ERR DEBUG command not allowed. If the enable-debug-command option is set to “local”, you can run it from a local connection, otherwise you need to set this option in the configuration file, and then restart the server 需要设置参数 直接加一行 raw &gt;&#x3D; 44位 流程图 Hash概述hash-max-ziplist-entries：使用压缩列表保存时哈希集合中的最大元素个数。 hash-max-ziplist-value：使用压缩列表保存哈希集合中单个元素的最大长度。 结论: 1.哈希对象保存的键值对数量小于 512 个； 2.所有的键值对的健和值的字符串长度都小于等于 64byte（一个英文字母一个字节） 时用ziplist，反之用hashtable ziplist升级到hashtable可以，反过来降级不可以 一旦从压缩列表转为了哈希表，Hash类型就会一直用哈希表进行保存而不会再转回压缩列表了。 在节省内存空间方面哈希表就没有压缩列表高效了。 后面会讲 回来再看 hash的两种编码格式ziplist(压缩列表)Ziplist 压缩列表是一种紧凑编码格式，总体思想是多花时间来换取节约空间，即以部分读写性能为代价，来换取极高的内存空间利用率， 因此只会用于 字段个数少，且字段值也较小 的场景。压缩列表内存利用率极高的原因与其连续内存的特性是分不开的 想想我们的学过的一种GC垃圾回收机制：标记–压缩算法 当一个 hash对象 只包含少量键值对且每个键值对的键和值要么就是小整数要么就是长度比较短的字符串，那么它用 ziplist 作为底层实现 不懂 todo ziplist是一个经过特殊编码的双向链表，它不存储指向上一个链表节点和指向下一个链表节点的指针，而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，节约内存，是一种时间换空间的思想。只用在字段个数少，字段值小的场景里面 ZipList结构本质上是字节数组 zlend是一个单字节255(1111 1111)，用做ZipList的结尾标识符。见下：压缩列表结构：由zlbytes、zltail、zllen、entry、zlend这五部分组成 ziplistEntry结构 压缩列表zlentry节点结构：每个zlentry由前一个节点的长度、encoding和entry-data三部分组成 前节点：(前节点占用的内存字节数)表示前1个zlentry的长度，prev_len有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。 enncoding：记录节点的content保存数据的类型和长度。 content：保存实际数据内容 123456789101112131415161718192021222324252627typedef struct zlentry &#123; // 压缩列表节点 // prevrawlen是前一个节点的长度 //prevrawlensize是指prevrawlen的大小，有1字节和5字节两种 unsigned int prevrawlensize, prevrawlen; // len为当前节点长度 lensize为编码len所需的字节大小 unsigned int lensize, len; // 当前节点的header大小 unsigned int headersize; // 节点的编码方式 unsigned char encoding; // 指向节点的指针 unsigned char *p; &#125; zlentry; 压缩列表的遍历通过指向表尾节点的位置指针p1, 减去节点的previous_entry_length(前一个结点的长度)，得到前一个节点起始地址的指针。如此循环，从表尾遍历到表头节点。从表尾向表头遍历操作就是使用这一原理实现的，只要我们拥有了一个指向某个节点起始地址的指针，那么通过这个指针以及这个节点的previous_entry_length属性程序就可以一直向前一个节点回溯，最终到达压缩列表的表头节点。 存取情况 hashtable 在 Redis 中，hashtable 被称为字典（dictionary），它是一个数组+链表的结构 OBJ_ENCODING_HT源码分析OBJ_ENCODING_HT 这种编码方式内部才是真正的哈希表结构，或称为字典结构，其可以实现O(1)复杂度的读写操作，因此效率很高。 在 Redis内部，从 OBJ_ENCODING_HT类型到底层真正的散列表数据结构是一层层嵌套下去的，组织关系见面图： 源代码：dict.h Listlist的一种编码格式list用quicklist来存储，quicklist存储了一个双向链表，每个节点都是一个ziplist 在低版本的Redis中，list采用的底层数据结构是ziplist+linkedList； 高版本的Redis中底层数据结构是quicklist(它替换了ziplist+linkedList)，而quicklist也用到了ziplist quicklist 实际上是 zipList 和 linkedList 的混合体，它将 linkedList按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。 案例: (1) ziplist压缩配置：list-compress-depth 0 表示一个quicklist两端不被压缩的节点个数。这里的节点是指quicklist双向链表的节点，而不是指ziplist里面的数据项个数 参数list-compress-depth的取值含义如下：两端各有x个端点不压缩 0: 是个特殊值，表示都不压缩。这是Redis的默认值。 1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。 2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。 3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。 依此类推… (2) ziplist中entry配置：list-max-ziplist-size -2 当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值， 每个值含义如下： -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb &#x3D;&gt; 1024 bytes） -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。 -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。 -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值） -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。 源码分析 SetSet的两种编码格式intset hashtable 案例 Redis用intset或hashtable存储set。如果元素都是整数类型，就用intset存储。 如果不是整数类型，就用hashtable（数组+链表的存来储结构）。key就是元素的值，value为null。 源码分析 ZsetZSet的两种编码格式ziplist skiplist 案例: 当有序集合中包含的元素数量超过服务器属性 server.zset_max_ziplist_entries 的值（默认值为 128 ）， 或者有序集合中新添加元素的 member 的长度大于服务器属性 server.zset_max_ziplist_value 的值（默认值为 64 ）时， redis会使用跳跃表作为有序集合的底层实现。 否则会使用ziplist作为有序集合的底层实现 源码分析 skipList跳表是可以实现二分查找的有序链表 skiplist是一种以空间换取时间的结构。 由于链表，无法进行二分查找，因此借鉴数据库索引的思想，提取出链表中关键节点（索引），先在关键节点上查找，再进入下层链表查找。 提取多层关键节点，就形成了跳跃表 总结来讲 跳表 &#x3D; 链表 + 多级索引 解决方法：升维，也叫空间换时间。 跳表查询的时间复杂度分析 首先每一级索引我们提升了2倍的跨度，那就是减少了2倍的步数，所以是n&#x2F;2、n&#x2F;4、n&#x2F;8以此类推； 第 k 级索引结点的个数就是 n&#x2F;(2^k)； 假设索引有 h 级， 最高的索引有2个结点；n&#x2F;(2^h) &#x3D; 2, 从这个公式我们可以求得 h &#x3D; log2(N)-1； 所以最后得出跳表的时间复杂度是O(logN) 跳表查询的空间复杂度分析 首先原始链表长度为n 如果索引是每2个结点有一个索引结点，每层索引的结点数：n&#x2F;2, n&#x2F;4, n&#x2F;8 … , 8, 4, 2 以此类推； 或者所以是每3个结点有一个索引结点，每层索引的结点数：n&#x2F;3, n&#x2F;9, n&#x2F;27 … , 9, 3, 1 以此类推； 所以空间复杂度是O(n)； 跳表是一个最典型的空间换时间解决方案，而且只有在数据量较大的情况下才能体现出来优势。而且应该是读多写少的情况下才能使用，所以它的适用范围应该还是比较有限的 维护成本相对要高 - 新增或者删除时需要把所有索引都更新一遍； 最后在新增和删除的过程中的更新，时间复杂度也是O(log n) 第十二章 Redis与MySQL数据双写一致性工程落地案例1. canal是什么Canal是基于MySQL变更日志增量订阅和消费的组件 canal [kə’næl]，中文翻译为 水道&#x2F;管道&#x2F;沟渠&#x2F;运河，主要用途是用于 MySQL 数据库增量日志数据的订阅、消费和解析，是阿里巴巴开发并开源的，采用Java语言开发； 历史背景是早期阿里巴巴因为杭州和美国双机房部署，存在跨机房数据同步的业务需求，实现方式主要是基于业务 trigger（触发器） 获取增量变更。从2010年开始，阿里巴巴逐步尝试采用解析数据库日志获取增量变更进行同步，由此衍生出了canal项目； 能干嘛 数据库镜像 数据库实时备份 索引构建和实时维护(拆分异构索引、倒排索引等) 业务 cache 刷新 带业务逻辑的增量数据处理 2. 相关面试2.1 MySQL的主从复制 MySQL的主从复制将经过如下步骤： 1、当 master 主服务器上的数据发生改变时，则将其改变写入二进制事件日志文件中； 2、salve 从服务器会在一定时间间隔内对 master 主服务器上的二进制日志进行探测，探测其是否发生过改变， 如果探测到 master 主服务器的二进制事件日志发生了改变，则开始一个 I&#x2F;O Thread 请求 master 二进制事件日志； 3、同时 master 主服务器为每个 I&#x2F;O Thread 启动一个dump Thread，用于向其发送二进制事件日志； 4、slave 从服务器将接收到的二进制事件日志保存至自己本地的中继日志文件中； 5、salve 从服务器将启动 SQL Thread 从中继日志中读取二进制日志，在本地重放，使得其数据和主服务器保持一致； 6、最后 I&#x2F;O Thread 和 SQL Thread 将进入睡眠状态，等待下一次被唤醒； 2.2 canal工作原理canal 工作原理 canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议 MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal ) canal 解析 binary log 对象(原始为 byte 流) mysql-canal-redis双写一致性Coding第十三章 缓存双写一致性之更新策略探讨缓存双写一致性，谈谈你的理解 如果redis中有数据 需要和数据库中的值相同 如果redis中无数据 数据库中的值要是最新值 缓存按照操作来分，有细分2种 ​ 只读缓存 ​ 读写缓存 ​ 同步直写策略：写缓存时也同步写数据库，缓存和数据库中的数据⼀致； ​ 对于读写缓存来说，要想保证缓存和数据库中的数据⼀致，就要采⽤同步直写策略 数据库和缓存一致性的几种更新策略 目的给缓存设置过期时间，是保证最终一致性的解决方案。 我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存，达到一致性，切记以mysql的数据库写入库为准。 上述方案和后续落地案例是调研后的主流+成熟的做法，但是考虑到各个公司业务系统的差距， 不是100%绝对正确，不保证绝对适配全部情况，请同学们自行酌情选择打法，合适自己的最好。 先更新数据库，再更新缓存问题 1 先更新mysql的某商品的库存，当前商品的库存是100，更新为99个。 2 先更新mysql修改为99成功，然后更新redis。 3 此时假设异常出现，更新redis失败了，这导致mysql里面的库存是99而redis里面的还是100 。 4 上述发生，会让数据库里面和缓存redis里面数据不一致，读到脏数据 先删除缓存，再更新数据库问题表示更新数据库可能失败 1 A线程先成功删除了redis里面的数据，然后去更新mysql，此时mysql正在更新中，还没有结束。（比如网络延时） B突然出现要来读取缓存数据。 异常问题2: 2 此时redis里面的数据是空的，B线程来读取，先去读redis里数据(已经被A线程delete掉了)，此处出来2个问题： 2.1 B从mysql获得了旧值 ​ B线程发现redis里没有(缓存缺失)马上去mysql里面读取，从数据库里面读取来的是旧值。 2.2 B会把获得的旧值写回redis 获得旧值数据后返回前台并回写进redis(刚被A线程删除的旧数据有极大可能又被写回了)。 3 A线程更新完mysql，发现redis里面的缓存是脏数据，A线程直接懵逼了，o(╥﹏╥)o 两个并发操作，一个是更新操作，另一个是查询操作，A更新操作删除缓存后，B查询操作没有命中缓存，B先把老数据读出来后放到缓存中，然后A更新操作更新了数据库。 于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。 4 总结流程： （1）请求A进行写操作，删除缓存后，工作正在进行中……A还么有彻底更新完 （2）请求B开工，查询redis发现缓存不存在 （3）请求B继续，去数据库查询得到了myslq中的旧值 （4）请求B将旧值写入redis缓存 （5）请求A将新值写入mysql数据库 上述情况就会导致不一致的情形出现。 时间 线程A 线程B 出现的问题 t1 请求A进行写操作，删除缓存后，工作正在进行中…… t2 1 缓存中读取不到，立刻读mysql，由于A还没有对mysql更新完，读到的是旧值。 2 还把从mysql读取的旧值，写回了redis 1 A还更新完mysql，导致B读到了旧值 2 线程B遵守回写机制，把旧值写回redis，导致其它请求读取的还是旧值，A白干了。 t3 更新mysql数据库的值，over redis是被B写回的旧值， mysql是被A更新的新值。 出现了，数据不一致问题。 总结 先删除缓存，再更新数据库 如果数据库更新失败，导致B线程请求再次访问缓存时，发现redis里面没数据，缓存缺失，再去读取mysql时，从数据库中读取到旧值 解决方案多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。 其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。 后面的线程进来发现已经有缓存了，就直接走缓存。 延时双删 双删方案面试题这个删除该休眠多久呢线程Asleep的时间，就需要大于线程B读取数据再写入缓存的时间。 这个时间怎么确定呢？ 在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，自行评估自己的项目的读数据业务逻辑的耗时， 以此为基础来进行估算。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上加百毫秒即可。 这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 当前演示的效果是mysql单机，如果mysql主从读写分离架构如何？（1）请求A进行写操作，删除缓存 （2）请求A将数据写入数据库了， （3）请求B查询缓存发现，缓存没有值 （4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值 （5）请求B将旧值写入缓存 （6）数据库完成主从同步，从库变为新值 上述情形，就是数据不一致的原因。还是使用双删延时策略。 只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms 这种同步淘汰策略，吞吐量降低怎么办？ 先更新数据库，再删除缓存问题时间 线程A 线程B 出现的问题 t1 删除数据库中的值 t2 缓存中立刻命中，此时B读取的是缓存旧值。 A还没有来得及删除缓存的值，导致B缓存命中读到旧值。 t3 更新缓存的数据，over 先更新数据库，再删除缓存 假如缓存删除失败或者来不及，导致请求再次访问redis时缓存命中，读取到的是缓存旧值 解决方案 1 可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用Kafka&#x2F;RabbitMQ等）。 2 当程序没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。 3 如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了，否则还需要再次进行重试 4 如果重试超过的一定次数后还是没有成功，我们就需要向业务层发送报错信息了，通知运维人员。 总结方案2和方案3用那个？利弊如何在大多数业务场景下，我们会把Redis作为只读缓存使用。假如定位是只读缓存来说， 理论上我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存，但是没有完美方案，两害相衡趋其轻的原则 个人建议是，优先使用先更新数据库，再删除缓存的方案。理由如下： 1 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力，严重导致打满mysql。 2 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。 多补充一句：如果使用先更新数据库，再删除缓存的方案 如果业务层要求必须读取一致性的数据，那么我们就需要在更新数据库时，先在Redis缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://gouguoqiang.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://gouguoqiang.github.io/tags/redis/"}]},{"title":"Spring","slug":"all/4spring","date":"2022-10-09T03:36:23.000Z","updated":"2022-10-10T05:37:49.635Z","comments":true,"path":"2022/10/09/all/4spring/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/09/all/4spring/","excerpt":"","text":"SSM概述spring mvc1、概述SpringMVC 是 Spring 为表述层开发提供的一整套完备的解决方案。在表述层框架历经 Strust、WebWork、Strust2 等诸多产品的历代更迭之后，目前业界普遍选择了 SpringMVC 作为 Java EE 项目表述层开发的首选方案。之所以能做到这一点，是因为 SpringMVC 具备如下显著优势： Spring 家族原生产品，与 IOC 容器等基础设施无缝对接 表述层各细分领域需要解决的问题全方位覆盖，提供全面解决方案 代码清新简洁，大幅度提升开发效率 内部组件化程度高，可插拔式组件即插即用，想要什么功能配置相应组件即可 性能卓著，尤其适合现代大型、超大型互联网项目要求 2、表述层框架要解决的基本问题 请求映射 数据输入 视图界面 请求分发 表单回显 会话控制 过滤拦截 异步交互 文件上传 文件下载 数据校验 类型转换 3、SpringMVC 代码对比①基于原生 Servlet API 开发代码片段1234567protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; String userName = request.getParameter(&quot;userName&quot;); System.out.println(&quot;userName=&quot;+userName); &#125; ②基于 SpringMVC 开发代码片段1234567@RequestMapping(&quot;/user/login&quot;)public String login(@RequestParam(&quot;userName&quot;) String userName)&#123; System.out.println(&quot;userName=&quot;+userName); return &quot;result&quot;;&#125; 第0章 Spring内置的能够使用的工具速查注册Bean到IOC容器1. BeanDefinition12345AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setBeanClass(User.class);context.registerBeanDefinition(&quot;user&quot;, beanDefinition);System.out.println(context.getBean(&quot;user&quot;)); 我们还可以通过BeanDefinition设置一个Bean的其他属性 123beanDefinition.setScope(&quot;prototype&quot;); // 设置作用域beanDefinition.setInitMethodName(&quot;init&quot;); // 设置初始化方法beanDefinition.setLazyInit(true); // 设置懒加载 和申明式事务、编程式事务类似，通过，@Bean，@Component等申明式方式所定义的Bean，最终都会被Spring解析为对应的BeanDefinition对象，并放入Spring容器中。 BeanDefinitionReaderAnnotatedBeanDefinitionReader可以直接把某个类转换为BeanDefinition，并且会解析该类上的注解，比如 12345678AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);AnnotatedBeanDefinitionReader annotatedBeanDefinitionReader = new AnnotatedBeanDefinitionReader(context);// 将User.class解析为BeanDefinitionannotatedBeanDefinitionReader.register(User.class);System.out.println(context.getBean(&quot;user&quot;)); 注意：它能解析的注解是：@Conditional，**@Scope**、@Lazy、@Primary、@DependsOn、@Role、@Description XmlBeanDefinitionReader可以解析标签 123456AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);XmlBeanDefinitionReader xmlBeanDefinitionReader = new XmlBeanDefinitionReader(context);int i = xmlBeanDefinitionReader.loadBeanDefinitions(&quot;spring.xml&quot;);System.out.println(context.getBean(&quot;user&quot;)); ClassPathBeanDefinitionScannerClassPathBeanDefinitionScanner是扫描器，但是它的作用和BeanDefinitionReader类似，它可以进行扫描，扫描某个包路径，对扫描到的类进行解析，比如，扫描到的类上如果存在@Component注解，那么就会把这个类解析为一个BeanDefinition，比如：​ 1234567AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();context.refresh();ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(context);scanner.scan(&quot;com.zhouyu&quot;);System.out.println(context.getBean(&quot;userService&quot;)); 事件发布先定义一个事件监听器 123456789@Beanpublic ApplicationListener applicationListener() &#123; return new ApplicationListener() &#123; @Override public void onApplicationEvent(ApplicationEvent event) &#123; System.out.println(&quot;接收到了一个事件&quot;); &#125; &#125;;&#125; 然后发布一个事件： 12345// 可以用ApplicationEventListener.publishEvent()context.publishEvent(&quot;kkk&quot;);// 这个底层用的就是上面的// 理解: 类似于消息队列 执行到publish之后 事件监听就会执行onApplicationEvent方法 类型转化在Spring源码中，有可能需要把String转成其他类型，所以在Spring源码中提供了一些技术来更方便的做对象的类型转化，关于类型转化的应用场景， 后续看源码的过程中会遇到很多。 123@Value(&quot;ggq&quot;)public User user;// 报错 类型不匹配 PropertyEditor这其实是JDK中提供的类型转化工具类 12345678910111213public class StringToUserPropertyEditor extends PropertyEditorSupport implements PropertyEditor &#123; @Override public void setAsText(String text) throws IllegalArgumentException &#123; User user = new User(); user.setName(text); this.setValue(user); &#125;&#125;StringToUserPropertyEditor propertyEditor = new StringToUserPropertyEditor();propertyEditor.setAsText(&quot;1&quot;);User value = (User) propertyEditor.getValue();System.out.println(value); 如何向Spring中注册PropertyEditor： 12345678910@Beanpublic CustomEditorConfigurer customEditorConfigurer() &#123; CustomEditorConfigurer customEditorConfigurer = new CustomEditorConfigurer(); Map&lt;Class&lt;?&gt;, Class&lt;? extends PropertyEditor&gt;&gt; propertyEditorMap = new HashMap&lt;&gt;(); // 表示StringToUserPropertyEditor可以将String转化成User类型，在Spring源码中，如果发现当前对象是String，而需要的类型是User，就会使用该PropertyEditor来做类型转化 propertyEditorMap.put(User.class, StringToUserPropertyEditor.class); customEditorConfigurer.setCustomEditors(propertyEditorMap); return customEditorConfigurer;&#125; 假设现在有如下Bean: 1234567891011@Componentpublic class UserService &#123; @Value(&quot;xxx&quot;) private User user; public void test() &#123; System.out.println(user); &#125;&#125; 那么test属性就能正常的完成属性赋值 ConversionServiceSpring中提供的类型转化服务，它比PropertyEditor更强大 1234567891011121314151617181920212223public class StringToUserConverter implements ConditionalGenericConverter &#123; @Override public boolean matches(TypeDescriptor sourceType, TypeDescriptor targetType) &#123; return sourceType.getType().equals(String.class) &amp;&amp; targetType.getType().equals(User.class); &#125; @Override public Set&lt;ConvertiblePair&gt; getConvertibleTypes() &#123; return Collections.singleton(new ConvertiblePair(String.class, User.class)); &#125; @Override public Object convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType) &#123; User user = new User(); user.setName((String)source); return user; &#125;&#125;DefaultConversionService conversionService = new DefaultConversionService();conversionService.addConverter(new StringToUserConverter());User value = conversionService.convert(&quot;1&quot;, User.class);System.out.println(value); 如何向Spring中注册ConversionService： 1234567@Beanpublic ConversionServiceFactoryBean conversionService() &#123; ConversionServiceFactoryBean conversionServiceFactoryBean = new ConversionServiceFactoryBean(); conversionServiceFactoryBean.setConverters(Collections.singleton(new StringToUserConverter())); return conversionServiceFactoryBean;&#125; TypeConverter整合了PropertyEditor和ConversionService的功能，是Spring内部用的 12345SimpleTypeConverter typeConverter = new SimpleTypeConverter();typeConverter.registerCustomEditor(User.class, new StringToUserPropertyEditor());//typeConverter.setConversionService(conversionService);User value = typeConverter.convertIfNecessary(&quot;1&quot;, User.class);System.out.println(value); OrderComparatorOrderComparator是Spring所提供的一种比较器，可以用来根据@Order注解或实现Ordered接口来执行值进行笔记，从而可以进行排序。 比如：​ 123456789101112public class A implements Ordered &#123; @Override public int getOrder() &#123; return 3; &#125; @Override public String toString() &#123; return this.getClass().getSimpleName(); &#125;&#125; 12345678910111213141516171819202122232425262728293031public class B implements Ordered &#123; @Override public int getOrder() &#123; return 2; &#125; @Override public String toString() &#123; return this.getClass().getSimpleName(); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; A a = new A(); // order=3 B b = new B(); // order=2 OrderComparator comparator = new OrderComparator(); System.out.println(comparator.compare(a, b)); // 1 List list = new ArrayList&lt;&gt;(); list.add(a); list.add(b); // 按order值升序排序 list.sort(comparator); System.out.println(list); // B，A &#125;&#125; 另外，Spring中还提供了一个OrderComparator的子类：AnnotationAwareOrderComparator，它支持用@Order来指定order值。比如：​ 12345678910111213141516171819202122232425262728293031323334353637@Order(3)public class A &#123; @Override public String toString() &#123; return this.getClass().getSimpleName(); &#125;&#125;@Order(2)public class B &#123; @Override public String toString() &#123; return this.getClass().getSimpleName(); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; A a = new A(); // order=3 B b = new B(); // order=2 AnnotationAwareOrderComparator comparator = new AnnotationAwareOrderComparator(); System.out.println(comparator.compare(a, b)); // 1 List list = new ArrayList&lt;&gt;(); list.add(a); list.add(b); // 按order值升序排序 list.sort(comparator); System.out.println(list); // B，A &#125;&#125; MetadataReader、ClassMetadata、AnnotationMetadata在Spring中需要去解析类的信息，比如类名、类中的方法、类上的注解，这些都可以称之为类的元数据，所以Spring中对类的元数据做了抽象，并提供了一些工具类。 MetadataReader表示类的元数据读取器，默认实现类为SimpleMetadataReader。比如： 123456789101112131415161718192021public class Test &#123; public static void main(String[] args) throws IOException &#123; SimpleMetadataReaderFactory simpleMetadataReaderFactory = new SimpleMetadataReaderFactory(); // 构造一个MetadataReader MetadataReader metadataReader = simpleMetadataReaderFactory.getMetadataReader(&quot;com.zhouyu.service.UserService&quot;); // 得到一个ClassMetadata，并获取了类名 ClassMetadata classMetadata = metadataReader.getClassMetadata(); System.out.println(classMetadata.getClassName()); // 获取一个AnnotationMetadata，并获取类上的注解信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); for (String annotationType : annotationMetadata.getAnnotationTypes()) &#123; System.out.println(annotationType); &#125; &#125;&#125; 需要注意的是，SimpleMetadataReader去解析类时，使用的ASM技术。 并不是等Java类加载到JVM在解析,而是直接读取字节码文件 为什么要使用ASM技术，Spring启动的时候需要去扫描，如果指定的包路径比较宽泛，那么扫描的类是非常多的，那如果在Spring启动时就把这些类全部加载进JVM了，这样不太好，所以使用了ASM技术。 ExcludeFilter和IncludeFilter这两个Filter是Spring扫描过程中用来过滤的。ExcludeFilter表示排除过滤器，IncludeFilter表示包含过滤器。 比如以下配置，表示扫描com.zhouyu这个包下面的所有类，但是排除UserService类，也就是就算它上面有@Component注解也不会成为Bean。 123456@ComponentScan(value = &quot;com.zhouyu&quot;, excludeFilters = &#123;@ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = UserService.class)&#125;.)public class AppConfig &#123;&#125; 再比如以下配置，就算UserService类上没有@Component注解，它也会被扫描成为一个Bean。 123456@ComponentScan(value = &quot;com.zhouyu&quot;, includeFilters = &#123;@ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = UserService.class)&#125;)public class AppConfig &#123;&#125; ​ FilterType分为： ANNOTATION：表示是否包含某个注解 ASSIGNABLE_TYPE：表示是否是某个类 ASPECTJ：表示否是符合某个Aspectj表达式 REGEX：表示是否符合某个正则表达式 CUSTOM：自定义 在Spring的扫描逻辑中，默认会添加一个AnnotationTypeFilter给includeFilters，表示默认情况下Spring扫描过程中会认为类上有@Component注解的就是Bean。 第一章 Spring底层核心原理解析Spring串讲,从整体上了解Spring Bean的生命周期底层原理 依赖注入底层原理 初始化底层方法 (推断构造方法底层方法) AOP底层原理 事务底层原理 Spring的使用12345678910@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)public class SpingBootDemoApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(SpingBootDemoApplication.class, args); //run方法返回一个IOC容器 &#125; Spring中是如何创建一个对象？目前，我们都可以简单的将它们理解为就是用来创建Java对象的，比如调用getBean()就会去创建对象（此处不严谨，getBean可能也不会去创建对象，后续详解 1234567891011@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)public class SpingBootDemoApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ioc = SpringApplication.run(SpingBootDemoApplication.class, args); UserService userService = (UserService) ioc.getBean(&quot;userService&quot;); userService.test(); &#125;&#125; UserService test~~~~ 怎么实现的呢? 在Spring底层会获取类的信息:根据配置类获取扫描路径(SpingBootDemoApplication本身是配置类(@Configuration注解下的类),他的内部内置了SpringBoot本包及其子包的扫描路径) 遍历扫描路径下的所有Java类,如果有@Compoent等注解,Spring就会把这个类记录下来存到BeanDefinitionMap(后续会详解) Spring会根据某个规则生成对应的beanName作为Key存到Map中,当前类定义信息作为Value Bean的创建过程Bean的大概创建生命周期 推断构造函数实例化一个对象 确定构造方法,确定入参的Bean对象 两种情况 1种构造方法和多种构造方法 1种则就选唯一的这一个 多种: 无指定默认找默认空参数构造函数 没有则报错,有指定(@Autowired的构造方法)则选择指定的 选择有参的会根据入参类型和名字去Spring找Bean对象 先根据入参类型找，如果只找到一个，那就直接用来作为入参 如果根据类型找到多个，则再根据入参名字来确定唯一一个 最终如果没有找到，则会报错，无法创建当前Bean对象 依赖注入 之后Aware回调(判断是否实现各种XxxxAware接口,实现接口的各种setXxxx放方法) 初始化前:判断是否存在@PostConstruct方法,存在则调用(初始化前) 初始化:是否实现InitaillizingBean接口,如果实现则要实现其的afterPropertySet()方法 初始化后:最后判断需不需要AOP,如果不需要那么Bean就创建完了,否则进行动态代理生成代理对象 AOP大致流程 如果当前Bean是单例Bean，那么会把该Bean对象存入一个Map&lt;String, Object&gt;，Map的key为beanName，value为Bean对象。这样下次getBean时就可以直接从Map中拿到对应的Bean对象了。（实际上，在Spring源码中，这个Map就是单例池） 如果当前Bean是原型Bean，那么后续没有其他动作，不会存入一个Map，下次getBean时会再次执行上述创建过程，得到一个新的Bean对象。 AOP大致流程AOP就是进行动态代理，在创建一个Bean的过程中，Spring在最后一步会去判断当前正在创建的这个Bean是不是需要进行AOP，如果需要则会进行动态代理。​ 如何判断当前Bean对象需不需要进行AOP: 找出所有的切面Bean 遍历切面中的每个方法，看是否写了@Before、@After等注解 如果写了，则判断所对应的Pointcut是否和当前Bean对象的类是否匹配 如果匹配则表示当前Bean对象有匹配的的Pointcut，表示需要进行AOP 利用cglib进行AOP的大致流程： 生成代理类UserServiceProxy，代理类继承UserService 代理类中重写了父类的方法，比如UserService中的test()方法 代理类中还会有一个target属性，该属性的值为被代理对象（也就是通过UserService类推断构造方法实例化出来的对象，进行了依赖注入、初始化等步骤的对象） 代理类中的test()方法被执行时的逻辑如下： 执行切面逻辑（@Before） 调用target.test() 当我们从Spring容器得到UserService的Bean对象时，拿到的就是UserServiceProxy所生成的对象，也就是代理对象。​ UserService代理对象.test()—&gt;执行切面逻辑—&gt;target.test()，注意target对象不是代理对象，而是被代理对象。 Spring事务当我们在某个方法上加了@Transactional注解后，就表示该方法在调用时会开启Spring事务，而这个方法所在的类所对应的Bean对象会是该类的代理对象。​ Spring事务的代理对象执行某个方法时的步骤： 判断当前执行的方法是否存在@Transactional注解 如果存在，则利用事务管理器（TransactionMananger）新建一个数据库连接 修改数据库连接的autocommit为false 执行target.test()，执行程序员所写的业务逻辑代码，也就是执行sql 执行完了之后如果没有出现异常，则提交，否则回滚 Spring事务是否会失效的判断标准：某个加了@Transactional注解的方法被调用时，要判断到底是不是直接被代理对象调用的，如果是则事务会生效，如果不是则失效。 第二章 Bean生命周期1. 生成BeanDefinition关于Spring启动流程，后续会单独的课详细讲，这里先讲一下Spring扫描的底层实现：​ Spring扫描底层流程：https://www.processon.com/view/link/61370ee60e3e7412ecd95d43​ 首先，通过ResourcePatternResolver获得指定包路径下的所有.class文件（Spring源码中将此文件包装成了Resource对象） 遍历每个Resource对象 利用MetadataReaderFactory解析Resource对象得到MetadataReader（在Spring源码中MetadataReaderFactory具体的实现类为CachingMetadataReaderFactory，MetadataReader的具体实现类为SimpleMetadataReader） 利用MetadataReader进行excludeFilters和includeFilters，以及条件注解@Conditional的筛选（条件注解并不能理解：某个类上是否存在@Conditional注解，如果存在则调用注解中所指定的类的match方法进行匹配，匹配成功则通过筛选，匹配失败则pass掉。） 筛选通过后，基于metadataReader生成ScannedGenericBeanDefinition 再基于metadataReader判断是不是对应的类是不是接口或抽象类 如果筛选通过，那么就表示扫描到了一个Bean，将ScannedGenericBeanDefinition加入结果集 MetadataReader表示类的元数据读取器，主要包含了一个AnnotationMetadata，功能有 获取类的名字、 获取父类的名字 获取所实现的所有接口名 获取所有内部类的名字 判断是不是抽象类 判断是不是接口 判断是不是一个注解 获取拥有某个注解的方法集合 获取类上添加的所有注解信息 获取类上添加的所有注解类型集合 值得注意的是，CachingMetadataReaderFactory解析某个.class文件得到MetadataReader对象是利用的ASM技术，并没有加载这个类到JVM。并且，最终得到的ScannedGenericBeanDefinition对象，beanClass属性存储的是当前类的名字，而不是class对象。（beanClass属性的类型是Object，它即可以存储类的名字，也可以存储class对象）​ 最后，上面是说的通过扫描得到BeanDefinition对象，我们还可以通过直接定义BeanDefinition，或解析spring.xml文件的，或者@Bean注解得到BeanDefinition对象。（后续课程会分析@Bean注解是怎么生成BeanDefinition的）。 2. 合并BeanDefinition通过扫描得到所有BeanDefinition之后，就可以根据BeanDefinition创建Bean对象了，但是在Spring中支持父子BeanDefinition，和Java父子类类似，但是完全不是一回事。 父子BeanDefinition实际用的比较少，使用是这样的，比如： 12&lt;bean id=&quot;parent&quot; class=&quot;com.zhouyu.service.Parent&quot; scope=&quot;prototype&quot;/&gt;&lt;bean id=&quot;child&quot; class=&quot;com.zhouyu.service.Child&quot;/&gt; 这么定义的情况下，child是单例Bean。 12&lt;bean id=&quot;parent&quot; class=&quot;com.zhouyu.service.Parent&quot; scope=&quot;prototype&quot;/&gt;&lt;bean id=&quot;child&quot; class=&quot;com.zhouyu.service.Child&quot; parent=&quot;parent&quot;/&gt; 但是这么定义的情况下，child就是原型Bean了。​ 因为child的父BeanDefinition是parent，所以会继承parent上所定义的scope属性。​ 而在根据child来生成Bean对象之前，需要进行BeanDefinition的合并，得到完整的child的BeanDefinition。​ 3. 加载类BeanDefinition合并之后，就可以去创建Bean对象了，而创建Bean就必须实例化对象，而实例化就必须先加载当前BeanDefinition所对应的class，在AbstractAutowireCapableBeanFactory类的createBean()方法中，一开始就会调用： 1Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); 这行代码就是去加载类，该方法是这么实现的： 12345678910111213if (mbd.hasBeanClass()) &#123; return mbd.getBeanClass();&#125;if (System.getSecurityManager() != null) &#123; return AccessController.doPrivileged((PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;) () -&gt; doResolveBeanClass(mbd, typesToMatch), getAccessControlContext()); &#125;else &#123; return doResolveBeanClass(mbd, typesToMatch);&#125;public boolean hasBeanClass() &#123; return (this.beanClass instanceof Class);&#125; 如果beanClass属性的类型是Class，那么就直接返回，如果不是，则会根据类名进行加载（doResolveBeanClass方法所做的事情） 会利用BeanFactory所设置的类加载器来加载类，如果没有设置，则默认使用**ClassUtils.getDefaultClassLoader()**所返回的类加载器来加载。 ClassUtils.getDefaultClassLoader() 优先返回当前线程中的ClassLoader 线程中类加载器为null的情况下，返回ClassUtils类的类加载器 如果ClassUtils类的类加载器为空，那么则表示是Bootstrap类加载器加载的ClassUtils类，那么则返回系统类加载器 4. 实例化前当前BeanDefinition对应的类成功加载后，就可以实例化对象了，但是…​ 在Spring中，实例化对象之前，Spring提供了一个扩展点，允许用户来控制是否在某个或某些Bean实例化之前做一些启动动作。这个扩展点叫**InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()**。比如：​ 1234567891011@Componentpublic class ZhouyuBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; System.out.println(&quot;实例化前&quot;); &#125; return null; &#125;&#125; 如上代码会导致，在userService这个Bean实例化前，会进行打印。​ 值得注意的是，postProcessBeforeInstantiation()是有返回值的，如果这么实现： 123456789101112@Componentpublic class ZhouyuBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; System.out.println(&quot;实例化前&quot;); return new UserService(); &#125; return null; &#125;&#125; userService这个Bean，在实例化前会直接返回一个由我们所定义的UserService对象。如果是这样，表示不需要Spring来实例化了，并且后续的Spring依赖注入也不会进行了，会跳过一些步骤，直接执行初始化后这一步。 5. 实例化在这个步骤中就会根据BeanDefinition去创建一个对象了。 5.1 Supplier创建对象首先判断BeanDefinition中是否设置了Supplier，如果设置了则调用Supplier的get()得到对象。​ 得直接使用BeanDefinition对象来设置Supplier，比如： 12345678AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setInstanceSupplier(new Supplier&lt;Object&gt;() &#123; @Override public Object get() &#123; return new UserService(); &#125;&#125;);context.registerBeanDefinition(&quot;userService&quot;, beanDefinition); 5.2 工厂方法创建对象如果没有设置Supplier，则检查BeanDefinition中是否设置了factoryMethod，也就是工厂方法，有两种方式可以设置factoryMethod，比如：​ 方式一： 1&lt;bean id=&quot;userService&quot; class=&quot;com.zhouyu.service.UserService&quot; factory-method=&quot;createUserService&quot; /&gt; 对应的UserService类为： 12345678910111213public class UserService &#123; public static UserService createUserService() &#123; System.out.println(&quot;执行createUserService()&quot;); UserService userService = new UserService(); return userService; &#125; public void test() &#123; System.out.println(&quot;test&quot;); &#125;&#125; 方式二： 12&lt;bean id=&quot;commonService&quot; class=&quot;com.zhouyu.service.CommonService&quot;/&gt;&lt;bean id=&quot;userService1&quot; factory-bean=&quot;commonService&quot; factory-method=&quot;createUserService&quot; /&gt; 对应的CommonService的类为： 123456public class CommonService &#123; public UserService createUserService() &#123; return new UserService(); &#125;&#125; Spring发现当前BeanDefinition方法设置了工厂方法后，就会区分这两种方式，然后调用工厂方法得到对象。​ 值得注意的是，我们通过@Bean所定义的BeanDefinition，是存在factoryMethod和factoryBean的，也就是和上面的方式二非常类似，@Bean所注解的方法就是factoryMethod，AppConfig对象就是factoryBean。如果@Bean所所注解的方法是static的，那么对应的就是方式一。 5.3 推断构造方法第一节已经讲过一遍大概原理了，后面有一节课单独分析源码实现。推断完构造方法后，就会使用构造方法来进行实例化了。​ 额外的，在推断构造方法逻辑中除开会去选择构造方法以及查找入参对象意外，会还判断是否在对应的类中是否存在使用**@Lookup注解了方法。如果存在则把该方法封装为LookupOverride对象并添加到BeanDefinition中。**​ 在实例化时，如果判断出来当前BeanDefinition中没有LookupOverride，那就直接用构造方法反射得到一个实例对象。如果存在LookupOverride对象，也就是类中存在@Lookup注解了的方法，那就会生成一个代理对象。​ @Lookup注解就是方法注入，使用demo如下： 12345678910111213141516@Componentpublic class UserService &#123; private OrderService orderService; public void test() &#123; OrderService orderService = createOrderService(); System.out.println(orderService); &#125; @Lookup(&quot;orderService&quot;) public OrderService createOrderService() &#123; return null; &#125;&#125; 6. BeanDefinition的后置处理Bean对象实例化出来之后，接下来就应该给对象的属性赋值了。在真正给属性赋值之前，Spring又提供了一个扩展点**MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition()**，可以对此时的BeanDefinition进行加工，比如： 12345678910@Componentpublic class ZhouyuMergedBeanDefinitionPostProcessor implements MergedBeanDefinitionPostProcessor &#123; @Override public void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) &#123; if (&quot;userService&quot;.equals(beanName)) &#123; beanDefinition.getPropertyValues().add(&quot;orderService&quot;, new OrderService()); &#125; &#125;&#125; 在Spring源码中，AutowiredAnnotationBeanPostProcessor就是一个MergedBeanDefinitionPostProcessor，它的postProcessMergedBeanDefinition()中会去查找注入点，并缓存在AutowiredAnnotationBeanPostProcessor对象的一个Map中（injectionMetadataCache）。 7. 实例化后在处理完BeanDefinition后，Spring又设计了一个扩展点：**InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation()**，比如：​ 1234567891011121314@Componentpublic class ZhouyuInstantiationAwareBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; UserService userService = (UserService) bean; userService.test(); &#125; return true; &#125;&#125; 上述代码就是对userService所实例化出来的对象进行处理。​ 这个扩展点，在Spring源码中基本没有怎么使用。 8. 自动注入这里的自动注入指的是Spring的自动注入，后续依赖注入课程中单独讲​ 9. 处理属性这个步骤中，就会处理@Autowired、@Resource、@Value等注解，也是通过**InstantiationAwareBeanPostProcessor.postProcessProperties()**扩展点来实现的，比如我们甚至可以实现一个自己的自动注入功能，比如： 123456789101112131415161718192021@Componentpublic class ZhouyuInstantiationAwareBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; for (Field field : bean.getClass().getFields()) &#123; if (field.isAnnotationPresent(ZhouyuInject.class)) &#123; field.setAccessible(true); try &#123; field.set(bean, &quot;123&quot;); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; return pvs; &#125;&#125; 关于@Autowired、@Resource、@Value的底层源码，会在后续的依赖注入课程中详解。 10. 执行Aware完成了属性赋值之后，Spring会执行一些回调，包括： BeanNameAware：回传beanName给bean对象。 BeanClassLoaderAware：回传classLoader给bean对象。 BeanFactoryAware：回传beanFactory给对象。 11. 初始化前初始化前，也是Spring提供的一个扩展点：**BeanPostProcessor.postProcessBeforeInitialization()**，比如 123456789101112@Componentpublic class ZhouyuBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; System.out.println(&quot;初始化前&quot;); &#125; return bean; &#125;&#125; 利用初始化前，可以对进行了依赖注入的Bean进行处理。​ 在Spring源码中： InitDestroyAnnotationBeanPostProcessor会在初始化前这个步骤中执行@PostConstruct的方法， ApplicationContextAwareProcessor会在初始化前这个步骤中进行其他Aware的回调： EnvironmentAware：回传环境变量 EmbeddedValueResolverAware：回传占位符解析器 ResourceLoaderAware：回传资源加载器 ApplicationEventPublisherAware：回传事件发布器 MessageSourceAware：回传国际化资源 ApplicationStartupAware：回传应用其他监听对象，可忽略 ApplicationContextAware：回传Spring容器ApplicationContext 12. 初始化 查看当前Bean对象是否实现了InitializingBean接口，如果实现了就调用其afterPropertiesSet()方法 执行BeanDefinition中指定的初始化方法 13. 初始化后这是Bean创建生命周期中的最后一个步骤，也是Spring提供的一个扩展点：**BeanPostProcessor.postProcessAfterInitialization()**，比如： 123456789101112@Componentpublic class ZhouyuBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (&quot;userService&quot;.equals(beanName)) &#123; System.out.println(&quot;初始化后&quot;); &#125; return bean; &#125;&#125; 可以在这个步骤中，对Bean最终进行处理，Spring中的AOP就是基于初始化后实现的，初始化后返回的对象才是最终的Bean对象。 总结BeanPostProcessor InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() 实例化 MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition() InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation() 自动注入 InstantiationAwareBeanPostProcessor.postProcessProperties() Aware对象 BeanPostProcessor.postProcessBeforeInitialization() 初始化 BeanPostProcessor.postProcessAfterInitialization() 第三章 IOC启动前言分析通常，我们说的Spring启动，就是构造ApplicationContext对象以及调用refresh()方法的过程。​ 首先，Spring启动过程主要做了这么几件事情： 构造一个BeanFactory对象 解析配置类，得到BeanDefinition，并注册到BeanFactory中 解析@ComponentScan，此时就会完成扫描 解析@Import 解析@Bean … 因为ApplicationContext还支持国际化，所以还需要初始化MessageSource对象 因为ApplicationContext还支持事件机制，所以还需要初始化ApplicationEventMulticaster对象 把用户定义的ApplicationListener对象添加到ApplicationContext中，等Spring启动完了就要发布事件了 创建非懒加载的单例Bean对象，并存在BeanFactory的单例池中。 调用Lifecycle Bean的start()方法 发布ContextRefreshedEvent事件 由于Spring启动过程中要创建非懒加载的单例Bean对象，那么就需要用到BeanPostProcessor，所以Spring在启动过程中就需要做两件事： 生成默认的BeanPostProcessor对象，并添加到BeanFactory中 AutowiredAnnotationBeanPostProcessor：处理@Autowired、@Value CommonAnnotationBeanPostProcessor：处理@Resource、@PostConstruct、@PreDestroy ApplicationContextAwareProcessor：处理ApplicationContextAware等回调 找到外部用户所定义的BeanPostProcessor对象（类型为BeanPostProcessor的Bean对象），并添加到BeanFactory中 Spring自带的BeanPostProcessor类 BeanPostProcessor InstantiationAwareBeanPostProcessor MergeBeanDefinitionAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor spring的启动流程this() 首先要创建一个BeanFactory比较常见的是AnnotationConfigApplicationContext(隐藏会组合一个defaultListableBeanfactory对象来作为一个存储各种信息的工厂) 先创建reader读取各种bean定义信息,后续为了加载底层功能的后置处理器 注册一个注解配置处理器,给工厂准备些解析器等基础组件(传入的是一个自带的rootBeanDefinition)注册到default 注册核心组件() 给工厂准备些基础组件(各种解析器),给工厂注册核心组件 AnnotatitionConfigurationClassBeanfactory(BeanFactoryPostProcessor)处理配置类 AutowiredAnnotationBeanPostProcessor(SmartInstantiationAwareBeanPostProcessor) CommonAnnotationBeanPostProcessor(普通JSR250支持@PostContruct @PreDestroy @Resource) JPA支持后置处理器 EventListenerMethorPostProcessor(事件功能(事件方法)的后置处理器) DefaultListenerFactory(事件工厂) 创建一个scanner准备一些环境变量 register(MainConfig) reader来注册所有配置类, 完善主配置类的定义信息(解析@Lazy @ Primary @DependsOn @ Description) 把主配置注册进去 refresh() 准备上下文环境 获取this()准备好的工厂 预准备工厂 给工厂设置必要的工具比如:el表达式解析器,资源解析器,基本的后置处理器(ApplicationContextAwareProcessor判断当前组件是否实现了xxxaware接口) 还注册了一些单实例Bean: 系统属性,系统环境 后置处理BeanFactory(空方法) 执行工厂的后置增强 ConfigurationClassPostProcessor解析配置类后置处理器在此工作 通过一个代理PostProecessorRegistrationDelegate管理所有后置处理器的执行 在工厂左右定义信息中获取配置类的信息使用parser进行配置类解析 处理@Lazy,@ComponentScan,@PropertySource@Import等注解将所有的Bean定义信息全部准备好 (利用反射把BeanClass的所有元数据准备好放入BeanDefinitionMap中) 注册Bean的后置处理器 for创建所有后置处理器对象 工厂提前保存所有处理器,方便后面创建Bean使用 初始化国际化组件 初始化事件多播器组件 看容器是否有(用户自己定义的) 没有就注册个默认的 放入单例池 OnRefresh()留给子类继续增强处理逻辑 注册监听器 获取容器中定义的所有ApplicationListener并保存起来 完成工厂初始化 遍历所有BeanName创建Bean对象 详情参照Bean初始化 finishRefresh() 最后的一些清理,时间发送等 Bean初始化+生命周期 todo循环引用 Bean的销毁过程Bean销毁是发送在Spring容器关闭过程中的。​ 在Spring容器关闭时，比如： 123456AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);UserService userService = (UserService) context.getBean(&quot;userService&quot;);userService.test();// 容器关闭context.close(); 在Bean创建过程中，在最后（初始化之后），有一个步骤会去判断当前创建的Bean是不是DisposableBean： 当前Bean是否实现了DisposableBean接口 或者，当前Bean是否实现了AutoCloseable接口 BeanDefinition中是否指定了destroyMethod 调用DestructionAwareBeanPostProcessor.requiresDestruction(bean)进行判断 ApplicationListenerDetector中直接使得ApplicationListener是DisposableBean InitDestroyAnnotationBeanPostProcessor中使得拥有@PreDestroy注解了的方法就是DisposableBean 把符合上述任意一个条件的Bean适配成DisposableBeanAdapter对象，并存入disposableBeans中（一个LinkedHashMap） 在Spring容器关闭过程时： 首先发布ContextClosedEvent事件 调用lifecycleProcessor的onCloese()方法 销毁单例Bean 遍历disposableBeans 把每个disposableBean从单例池中移除 调用disposableBean的destroy() 如果这个disposableBean还被其他Bean依赖了，那么也得销毁其他Bean 如果这个disposableBean还包含了inner beans，将这些Bean从单例池中移除掉 (inner bean参考https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/core.html#beans-inner-beans) 清空manualSingletonNames，是一个Set，存的是用户手动注册的单例Bean的beanName 清空allBeanNamesByType，是一个Map，key是bean类型，value是该类型所有的beanName数组 清空singletonBeanNamesByType，和allBeanNamesByType类似，只不过只存了单例Bean 这里涉及到一个设计模式：适配器模式 在销毁时，Spring会找出实现了DisposableBean接口的Bean。​ 但是我们在定义一个Bean时，如果这个Bean实现了DisposableBean接口，或者实现了AutoCloseable接口，或者在BeanDefinition中指定了destroyMethodName，那么这个Bean都属于“DisposableBean”，这些Bean在容器关闭时都要调用相应的销毁方法。 所以，这里就需要进行适配，将实现了DisposableBean接口、或者AutoCloseable接口等适配成实现了DisposableBean接口，所以就用到了DisposableBeanAdapter。 会把实现了AutoCloseable接口的类封装成DisposableBeanAdapter，而DisposableBeanAdapter实现了DisposableBean接口。 BeanFactoryPostProcessorBeanPostProcessor表示Bean的后置处理器，是用来对Bean进行加工的，类似的，BeanFactoryPostProcessor理解为BeanFactory的后置处理器，用来用对BeanFactory进行加工的。​ Spring支持用户定义BeanFactoryPostProcessor的实现类Bean，来对BeanFactory进行加工，比如： 123456789@Componentpublic class ZhouyuBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; BeanDefinition beanDefinition = beanFactory.getBeanDefinition(&quot;userService&quot;); beanDefinition.setAutowireCandidate(false); &#125;&#125; 以上代码，就利用了BeanFactoryPostProcessor来拿到BeanFactory，然后获取BeanFactory内的某个BeanDefinition对象并进行修改，注意这一步是发生在Spring启动时，创建单例Bean之前的，所以此时对BeanDefinition就行修改是会生效的。​ 注意：在ApplicationContext内部有一个核心的DefaultListableBeanFactory，它实现了ConfigurableListableBeanFactory和BeanDefinitionRegistry接口，所以ApplicationContext和DefaultListableBeanFactory是可以注册BeanDefinition的，但是ConfigurableListableBeanFactory是不能注册BeanDefinition的，只能获取BeanDefinition，然后做修改。 所以Spring还提供了一个BeanFactoryPostProcessor的子接口：BeanDefinitionRegistryPostProcessor​ BeanDefinitionRegistryPostProcessor12345public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;&#125; 我们可以看到BeanDefinitionRegistryPostProcessor继承了BeanFactoryPostProcessor接口，并新增了一个方法，注意方法的参数为BeanDefinitionRegistry，所以如果我们提供一个类来实现BeanDefinitionRegistryPostProcessor，那么在postProcessBeanDefinitionRegistry()方法中就可以注册BeanDefinition了。比如：​ 12345678910111213141516@Componentpublic class ZhouyuBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition(); beanDefinition.setBeanClass(User.class); registry.registerBeanDefinition(&quot;user&quot;, beanDefinition); &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; BeanDefinition beanDefinition = beanFactory.getBeanDefinition(&quot;userService&quot;); beanDefinition.setAutowireCandidate(false); &#125;&#125; 如何理解refresh()？1234567891011/** * Load or refresh the persistent representation of the configuration, * which might an XML file, properties file, or relational database schema. * &lt;p&gt;As this is a startup method, it should destroy already created singletons * if it fails, to avoid dangling resources. In other words, after invocation * of that method, either all or no singletons at all should be instantiated. * @throws BeansException if the bean factory could not be initialized * @throws IllegalStateException if already initialized and multiple refresh * attempts are not supported */ void refresh() throws BeansException, IllegalStateException; 这是ConfigurableApplicationContext接口上refresh()方法的注释，意思是：加载或刷新持久化的配置，可能是XML文件、属性文件或关系数据库中存储的。由于这是一个启动方法，如果失败，它应该销毁已经创建的单例，以避免暂用资源。换句话说，在调用该方法之后，应该实例化所有的单例，或者根本不实例化单例 。 有个理念需要注意：ApplicationContext关闭之后不代表JVM也关闭了，ApplicationContext是属于JVM的，说白了ApplicationContext也是JVM中的一个对象。​ 在Spring的设计中，也提供可以刷新的ApplicationContext和不可以刷新的ApplicationContext。比如： 1AbstractRefreshableApplicationContext extends AbstractApplicationContext 就是可以刷新的 1GenericApplicationContext extends AbstractApplicationContext 就是不可以刷新的。 AnnotationConfigApplicationContext继承的是GenericApplicationContext，所以它是不能刷新的。AnnotationConfigWebApplicationContext继承的是AbstractRefreshableWebApplicationContext，所以它是可以刷的。 上面说的不能刷新是指不能重复刷新，只能调用一次refresh方法，第二次时会报错。 refresh()底层原理流程底层原理流程图：https://www.processon.com/view/link/5f60a7d71e08531edf26a919 下面以AnnotationConfigApplicationContext为例子，来介绍refresh的底层原理。 在调用AnnotationConfigApplicationContext的构造方法之前，会调用父类GenericApplicationContext的无参构造方法，会构造一个BeanFactory，为DefaultListableBeanFactory。 构造AnnotatedBeanDefinitionReader（ 主要作用添加一些基础的PostProcessor，同时可以通过reader进行BeanDefinition的注册 ），同时对BeanFactory进行设置和添加 PostProcessor （后置处理器） 设置dependencyComparator：AnnotationAwareOrderComparator，它是一个Comparator，是用来进行排序的，会获取某个对象上的Order注解或者通过实现Ordered接口所定义的值进行排序，在日常开发中可以利用这个类来进行排序。 设置autowireCandidateResolver：ContextAnnotationAutowireCandidateResolver，用来解析某个Bean能不能进行自动注入，比如某个Bean的autowireCandidate属性是否等于true 向BeanFactory中添加ConfigurationClassPostProcessor对应的BeanDefinition，它是一个BeanDefinitionRegistryPostProcessor，并且实现了PriorityOrdered接口 向BeanFactory中添加AutowiredAnnotationBeanPostProcessor对应的BeanDefinition，它是一个InstantiationAwareBeanPostProcessorAdapter，MergedBeanDefinitionPostProcessor 向BeanFactory中添加CommonAnnotationBeanPostProcessor对应的BeanDefinition，它是一个InstantiationAwareBeanPostProcessor，InitDestroyAnnotationBeanPostProcessor 向BeanFactory中添加EventListenerMethodProcessor对应的BeanDefinition，它是一个BeanFactoryPostProcessor，SmartInitializingSingleton 向BeanFactory中添加DefaultEventListenerFactory对应的BeanDefinition，它是一个EventListenerFactory 构造ClassPathBeanDefinitionScanner（ 主要作用可以用来扫描得到并注册BeanDefinition ），同时进行设置： 设置this.includeFilters &#x3D; AnnotationTypeFilter(Component.class) 设置environment 设置resourceLoader 利用reader注册AppConfig为BeanDefinition，类型为AnnotatedGenericBeanDefinition 接下来就是调用refresh方法 prepareRefresh()： 记录启动时间 可以允许子容器设置一些内容到Environment中 验证Environment中是否包括了必须要有的属性 obtainFreshBeanFactory()：进行BeanFactory的refresh，在这里会去调用子类的refreshBeanFactory方法，具体子类是怎么刷新的得看子类，然后再调用子类的getBeanFactory方法，重新得到一个BeanFactory prepareBeanFactory(beanFactory)： 设置beanFactory的类加载器 设置表达式解析器：StandardBeanExpressionResolver，用来解析Spring中的表达式 添加PropertyEditorRegistrar：ResourceEditorRegistrar，PropertyEditor类型转化器注册器，用来注册一些默认的PropertyEditor 添加一个Bean的后置处理器：ApplicationContextAwareProcessor，是一个BeanPostProcessor，用来执行EnvironmentAware、ApplicationEventPublisherAware等回调方法 添加 ignoredDependencyInterface ：可以向这个属性中添加一些接口，如果某个类实现了这个接口，并且这个类中的某些set方法在接口中也存在，那么这个set方法在自动注入的时候是不会执行的，比如EnvironmentAware这个接口，如果某个类实现了这个接口，那么就必须实现它的setEnvironment方法，而这是一个set方法，和Spring中的autowire是冲突的，那么Spring在自动注入时是不会调用setEnvironment方法的，而是等到回调Aware接口时再来调用（注意，这个功能仅限于xml的autowire，@Autowired注解是忽略这个属性的） EnvironmentAware EmbeddedValueResolverAware ResourceLoaderAware ApplicationEventPublisherAware MessageSourceAware ApplicationContextAware 另外其实在构造BeanFactory的时候就已经提前添加了另外三个： BeanNameAware BeanClassLoaderAware BeanFactoryAware 添加 resolvableDependencies ：在byType进行依赖注入时，会先从这个属性中根据类型找bean BeanFactory.class：当前BeanFactory对象 ResourceLoader.class：当前ApplicationContext对象 ApplicationEventPublisher.class：当前ApplicationContext对象 ApplicationContext.class：当前ApplicationContext对象 添加一个Bean的后置处理器：ApplicationListenerDetector，是一个BeanPostProcessor，用来判断某个Bean是不是ApplicationListener，如果是则把这个Bean添加到ApplicationContext中去，注意一个ApplicationListener只能是单例的 添加一个Bean的后置处理器：LoadTimeWeaverAwareProcessor，是一个BeanPostProcessor，用来判断某个Bean是不是实现了LoadTimeWeaverAware接口，如果实现了则把ApplicationContext中的loadTimeWeaver回调setLoadTimeWeaver方法设置给该Bean。 添加一些单例bean到单例池： “environment”：Environment对象 “systemProperties”：System.getProperties()返回的Map对象 “systemEnvironment”：System.getenv()返回的Map对象 postProcessBeanFactory(beanFactory) ： 提供给AbstractApplicationContext的子类进行扩展，具体的子类，可以继续向BeanFactory中再添加一些东西 invokeBeanFactoryPostProcessors(beanFactory)： 执行BeanFactoryPostProcessor 此时在BeanFactory中会存在一个BeanFactoryPostProcessor：ConfigurationClassPostProcessor，它也是一个BeanDefinitionRegistryPostProcessor 第一阶段 从BeanFactory中找到类型为BeanDefinitionRegistryPostProcessor的beanName，也就是ConfigurationClassPostProcessor， 然后调用BeanFactory的getBean方法得到实例对象 执行**ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry()**方法: 解析AppConfig类 扫描得到BeanDefinition并注册 解析@Import，@Bean等注解得到BeanDefinition并注册 详细的看另外的笔记，专门分析了ConfigurationClassPostProcessor是如何工作的 在这里，我们只需要知道在这一步会去得到BeanDefinition，而这些BeanDefinition中可能存在BeanFactoryPostProcessor和BeanDefinitionRegistryPostProcessor，所以执行完ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry()方法后，还需要继续执行其他BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry()方法 执行其他BeanDefinitionRegistryPostProcessor的**postProcessBeanDefinitionRegistry()**方法 执行所有BeanDefinitionRegistryPostProcessor的**postProcessBeanFactory()**方法 第二阶段 从BeanFactory中找到类型为BeanFactoryPostProcessor的beanName，而这些BeanFactoryPostProcessor包括了上面的BeanDefinitionRegistryPostProcessor 执行还没有执行过的BeanFactoryPostProcessor的**postProcessBeanFactory()**方法 到此，所有的BeanFactoryPostProcessor的逻辑都执行完了，主要做的事情就是得到BeanDefinition并注册到BeanFactory中 registerBeanPostProcessors(beanFactory)：因为上面的步骤完成了扫描，这个过程中程序员可能自己定义了一些BeanPostProcessor，在这一步就会把BeanFactory中所有的BeanPostProcessor找出来并实例化得到一个对象，并添加到BeanFactory中去（属性beanPostProcessors），最后再重新添加一个ApplicationListenerDetector对象（之前其实就添加了过，这里是为了把ApplicationListenerDetector移动到最后） initMessageSource()：如果BeanFactory中存在一个叫做”messageSource“的BeanDefinition，那么就会把这个Bean对象创建出来并赋值给ApplicationContext的messageSource属性，让ApplicationContext拥有国际化的功能 initApplicationEventMulticaster()：如果BeanFactory中存在一个叫做”applicationEventMulticaster“的BeanDefinition，那么就会把这个Bean对象创建出来并赋值给ApplicationContext的applicationEventMulticaster属性，让ApplicationContext拥有事件发布的功能 onRefresh()：提供给AbstractApplicationContext的子类进行扩展，没用 registerListeners()：从BeanFactory中获取ApplicationListener类型的beanName，然后添加到ApplicationContext中的事件广播器applicationEventMulticaster中去，到这一步因为FactoryBean还没有调用getObject()方法生成Bean对象，所以这里要在根据类型找一下ApplicationListener，记录一下对应的beanName finishBeanFactoryInitialization(beanFactory)：完成BeanFactory的初始化，主要就是实例化非懒加载的单例Bean，单独的笔记去讲。 finishRefresh()：BeanFactory的初始化完后，就到了Spring启动的最后一步了 设置ApplicationContext的lifecycleProcessor，默认情况下设置的是DefaultLifecycleProcessor 调用lifecycleProcessor的onRefresh()方法，如果是DefaultLifecycleProcessor，那么会获取所有类型为Lifecycle的Bean对象，然后调用它的start()方法，这就是ApplicationContext的生命周期扩展机制 发布ContextRefreshedEvent事件 执行BeanFactoryPostProcessor 执行通过ApplicationContext添加进来的BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry()方法 执行BeanFactory中实现了PriorityOrdered接口的BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry()方法 执行BeanFactory中实现了Ordered接口的BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry()方法 执行BeanFactory中其他的BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry()方法 执行上面所有的BeanDefinitionRegistryPostProcessor的postProcessBeanFactory()方法 执行通过ApplicationContext添加进来的BeanFactoryPostProcessor的postProcessBeanFactory()方法 执行BeanFactory中实现了PriorityOrdered接口的BeanFactoryPostProcessor的postProcessBeanFactory()方法 执行BeanFactory中实现了Ordered接口的BeanFactoryPostProcessor的postProcessBeanFactory()方法 执行BeanFactory中其他的BeanFactoryPostProcessor的postProcessBeanFactory()方法 Lifecycle的使用Lifecycle表示的是ApplicationContext的生命周期，可以定义一个SmartLifecycle来监听ApplicationContext的启动和关闭： 1234567891011121314151617181920212223@Componentpublic class ZhouyuLifecycle implements SmartLifecycle &#123; private boolean isRunning = false; @Override public void start() &#123; System.out.println(&quot;启动&quot;); isRunning = true; &#125; @Override public void stop() &#123; // 要触发stop()，要调用context.close()，或者注册关闭钩子（context.registerShutdownHook();） System.out.println(&quot;停止&quot;); isRunning = false; &#125; @Override public boolean isRunning() &#123; return isRunning; &#125;&#125; 解析配置类解析配置类流程图：https://www.processon.com/view/link/5f9512d5e401fd06fda0b2dd解析配置类思维脑图：https://www.processon.com/view/link/614c83cae0b34d7b342f6d14 在启动Spring时，需要传入一个AppConfig.class给ApplicationContext，ApplicationContext会根据AppConfig类封装为一个BeanDefinition，这种BeanDefinition我们把它称为配置类BeanDefinition。 ConfigurationClassPostProcessor中会把配置类BeanDefinition取出来 构造一个ConfigurationClassParser用来解析配置类BeanDefinition，并且会生成一个配置类对象ConfigurationClass 如果配置类上存在@Component注解，那么解析配置类中的内部类（这里有递归，如果内部类也是配置类的话） 如果配置类上存在@PropertySource注解，那么则解析该注解，并得到PropertySource对象，并添加到environment中去 如果配置类上存在@ComponentScan注解，那么则解析该注解，进行扫描，扫描得到一系列的BeanDefinition对象，然后判断这些BeanDefinition是不是也是配置类BeanDefinition（只要存在@Component注解就是配置类，所以基本上扫描出来的都是配置类），如果是则继续解析该配置类，（也有递归），并且会生成对应的ConfigurationClass 如果配置类上存在@Import注解，那么则判断Import的类的类型： 如果是ImportSelector，那么调用执行selectImports方法得到类名，然后在把这个类当做配置类进行解析（也是递归） 如果是ImportBeanDefinitionRegistrar，那么则生成一个ImportBeanDefinitionRegistrar实例对象，并添加到配置类对象中（ConfigurationClass）的importBeanDefinitionRegistrars属性中。 如果配置类上存在@ImportResource注解，那么则把导入进来的资源路径存在配置类对象中的importedResources属性中。 如果配置类中存在@Bean的方法，那么则把这些方法封装为BeanMethod对象，并添加到配置类对象中的beanMethods属性中。 如果配置类实现了某些接口，则看这些接口内是否定义了@Bean的默认方法 如果配置类有父类，则把父类当做配置类进行解析 AppConfig这个配置类会对应一个ConfigurationClass，同时在解析的过程中也会生成另外的一些ConfigurationClass，接下来就利用reader来进一步解析ConfigurationClass 如果ConfigurationClass是通过@Import注解导入进来的，则把这个类生成一个BeanDefinition，同时解析这个类上@Scope,@Lazy等注解信息，并注册BeanDefinition 如果ConfigurationClass中存在一些BeanMethod，也就是定义了一些@Bean，那么则解析这些@Bean，并生成对应的BeanDefinition，并注册 如果ConfigurationClass中导入了一些资源文件，比如xx.xml，那么则解析这些xx.xml文件，得到并注册BeanDefinition 如果ConfigurationClass中导入了一些ImportBeanDefinitionRegistrar，那么则执行对应的registerBeanDefinitions进行BeanDefinition的注册 总结一下 解析AppConfig类，生成对应的ConfigurationClass 再扫描，扫描到的类都会生成对应的BeanDefinition，并且同时这些类也是ConfigurationClass 再解析ConfigurationClass的其他信息，比如@ImportResource注解的处理，@Import注解的处理，@Bean注解的处理 第四章 依赖注入Spring中到底有几种依赖注入的方式？首先分两种： 手动注入 自动注入 手动注入在XML中定义Bean时，就是手动注入，因为是程序员手动给某个属性指定了值。 123&lt;bean name=&quot;userService&quot; class=&quot;com.luban.service.UserService&quot;&gt; &lt;property name=&quot;orderService&quot; ref=&quot;orderService&quot;/&gt;&lt;/bean&gt; 上面这种底层是通过set方法进行注入。 123&lt;bean name=&quot;userService&quot; class=&quot;com.luban.service.UserService&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;orderService&quot;/&gt;&lt;/bean&gt; 上面这种底层是通过构造方法进行注入。 所以手动注入的底层也就是分为两种： set方法注入 构造方法注入 自动注入自动注入又分为两种： XML的autowire自动注入 @Autowired注解的自动注入 XML的autowire自动注入在XML中，我们可以在定义一个Bean时去指定这个Bean的自动注入模式： byType byName constructor default no 比如： 1&lt;bean id=&quot;userService&quot; class=&quot;com.luban.service.UserService&quot; autowire=&quot;byType&quot;/&gt; 这么写，表示Spring会自动的给userService中所有的属性自动赋值（不需要这个属性上有@Autowired注解，但需要这个属性有对应的set方法）。 在创建Bean的过程中，在填充属性时，Spring会去解析当前类，把当前类的所有方法都解析出来，Spring会去解析每个方法得到对应的PropertyDescriptor对象，PropertyDescriptor中有几个属性： name：这个name并不是方法的名字，而是拿方法名字进过处理后的名字 如果方法名字以“get”开头，比如“getXXX”,那么name&#x3D;XXX 如果方法名字以“is”开头，比如“isXXX”,那么name&#x3D;XXX 如果方法名字以“set”开头，比如“setXXX”,那么name&#x3D;XXX readMethodRef：表示get方法的Method对象的引用 readMethodName：表示get方法的名字 writeMethodRef：表示set方法的Method对象的引用 writeMethodName：表示set方法的名字 propertyTypeRef：如果有get方法那么对应的就是返回值的类型，如果是set方法那么对应的就是set方法中唯一参数的类型 get方法的定义是： 方法参数个数为0个，并且 （方法名字以”get”开头 或者 方法名字以”is”开头并且方法的返回类型为boolean） set方法的定义是：方法参数个数为1个，并且 （方法名字以”set”开头并且方法返回类型为void） 所以，Spring在通过byName的自动填充属性时流程是： 找到所有set方法所对应的XXX部分的名字 根据XXX部分的名字去获取bean Spring在通过byType的自动填充属性时流程是： 获取到set方法中的唯一参数的参数类型，并且根据该类型去容器中获取bean 如果找到多个，会报错。 以上，分析了autowire的byType和byName情况，那么接下来分析constructor，constructor表示通过构造方法注入，其实这种情况就比较简单了，没有byType和byName那么复杂。​ 如果是constructor，那么就可以不写set方法了，当某个bean是通过构造方法来注入时，spring利用构造方法的参数信息从Spring容器中去找bean，找到bean之后作为参数传给构造方法，从而实例化得到一个bean对象，并完成属性赋值（属性赋值的代码得程序员来写）。 我们这里先不考虑一个类有多个构造方法的情况，后面单独讲推断构造方法。我们这里只考虑只有一个有参构造方法。 其实构造方法注入相当于byType+byName，普通的byType是根据set方法中的参数类型去找bean，找到多个会报错，而constructor就是通过构造方法中的参数类型去找bean，如果找到多个会根据参数名确定。 另外两个： no，表示关闭autowire default，表示默认值，我们一直演示的某个bean的autowire，而也可以直接在标签中设置autowire，如果设置了，那么标签中设置的autowire如果为default，那么则会用标签中设置的autowire。 可以发现XML中的自动注入是挺强大的，那么问题来了，为什么我们平时都是用的@Autowired注解呢？而没有用上文说的这种自动注入方式呢？ @Autowired注解相当于XML中的autowire属性的注解方式的替代。这是在官网上有提到的。 1Essentially, the @Autowired annotation provides the same capabilities as described in Autowiring Collaborators but with more fine-grained control and wider applicability 翻译一下：从本质上讲，@Autowired注解提供了与autowire相同的功能，但是拥有更细粒度的控制和更广泛的适用性。 注意：更细粒度的控制。 XML中的autowire控制的是整个bean的所有属性，而@Autowired注解是直接写在某个属性、某个set方法、某个构造方法上的。 再举个例子，如果一个类有多个构造方法，那么如果用XML的autowire&#x3D;constructor，你无法控制到底用哪个构造方法，而你可以用@Autowired注解来直接指定你想用哪个构造方法。 同时，用@Autowired注解，还可以控制，哪些属性想被自动注入，哪些属性不想，这也是细粒度的控制。 但是@Autowired无法区分byType和byName，@Autowired是先byType，如果找到多个则byName。 那么XML的自动注入底层其实也就是: set方法注入 构造方法注入 @Autowired注解的自动注入上文说了@Autowired注解，是byType和byName的结合。 @Autowired注解可以写在： 属性上：先根据属性类型去找Bean，如果找到多个再根据属性名确定一个 构造方法上：先根据方法参数类型去找Bean，如果找到多个再根据参数名确定一个 set方法上：先根据方法参数类型去找Bean，如果找到多个再根据参数名确定一个 而这种底层到了： 属性注入 set方法注入 构造方法注入 寻找注入点在创建一个Bean的过程中，Spring会利用AutowiredAnnotationBeanPostProcessor的**postProcessMergedBeanDefinition()**找出注入点并缓存，找注入点的流程为： 遍历当前类的所有的属性字段Field 查看字段上是否存在@Autowired、@Value、@Inject中的其中任意一个，存在则认为该字段是一个注入点 如果字段是static的，则不进行注入 怎么判断 获取@Autowired中的required属性的值 将字段信息构造成一个AutowiredFieldElement对象，作为一个注入点对象添加到currElements集合中。 遍历当前类的所有方法Method 判断当前Method是否是桥接方法，如果是找到原方法 查看方法上是否存在@Autowired、@Value、@Inject中的其中任意一个，存在则认为该方法是一个注入点 如果方法是static的，则不进行注入 获取@Autowired中的required属性的值 将方法信息构造成一个AutowiredMethodElement对象，作为一个注入点对象添加到currElements集合中。 遍历完当前类的字段和方法后，将遍历父类的，直到没有父类。 最后将currElements集合封装成一个InjectionMetadata对象，作为当前Bean对于的注入点集合对象，并缓存。 static的字段或方法为什么不支持123456@Component@Scope(&quot;prototype&quot;)public class OrderService &#123;&#125; 123456789101112@Component@Scope(&quot;prototype&quot;)public class UserService &#123; @Autowired private static OrderService orderService; public void test() &#123; System.out.println(&quot;test123&quot;); &#125;&#125; 看上面代码，UserService和OrderService都是原型Bean，假设Spring支持static字段进行自动注入，那么现在调用两次 UserService userService1 &#x3D; context.getBean(“userService”) UserService userService2 &#x3D; context.getBean(“userService”) 问此时，userService1的orderService值是什么？还是它自己注入的值吗？​ 答案是不是，一旦userService2 创建好了之后，static orderService字段的值就发生了修改了，从而出现bug。 桥接方法12345678910111213141516171819public interface UserInterface&lt;T&gt; &#123; void setOrderService(T t);&#125;@Componentpublic class UserService implements UserInterface&lt;OrderService&gt; &#123; private OrderService orderService; @Override @Autowired public void setOrderService(OrderService orderService) &#123; this.orderService = orderService; &#125; public void test() &#123; System.out.println(&quot;test123&quot;); &#125;&#125; UserService对应的字节码为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// class version 52.0 (52)// access flags 0x21// signature Ljava/lang/Object;Lcom/zhouyu/service/UserInterface&lt;Lcom/zhouyu/service/OrderService;&gt;;// declaration: com/zhouyu/service/UserService implements com.zhouyu.service.UserInterface&lt;com.zhouyu.service.OrderService&gt;public class com/zhouyu/service/UserService implements com/zhouyu/service/UserInterface &#123; // compiled from: UserService.java @Lorg/springframework/stereotype/Component;() // access flags 0x2 private Lcom/zhouyu/service/OrderService; orderService // access flags 0x1 public &lt;init&gt;()V L0 LINENUMBER 12 L0 ALOAD 0 INVOKESPECIAL java/lang/Object.&lt;init&gt; ()V RETURN L1 LOCALVARIABLE this Lcom/zhouyu/service/UserService; L0 L1 0 MAXSTACK = 1 MAXLOCALS = 1 // access flags 0x1 public setOrderService(Lcom/zhouyu/service/OrderService;)V @Lorg/springframework/beans/factory/annotation/Autowired;() L0 LINENUMBER 19 L0 ALOAD 0 ALOAD 1 PUTFIELD com/zhouyu/service/UserService.orderService : Lcom/zhouyu/service/OrderService; L1 LINENUMBER 20 L1 RETURN L2 LOCALVARIABLE this Lcom/zhouyu/service/UserService; L0 L2 0 LOCALVARIABLE orderService Lcom/zhouyu/service/OrderService; L0 L2 1 MAXSTACK = 2 MAXLOCALS = 2 // access flags 0x1 public test()V L0 LINENUMBER 23 L0 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC &quot;test123&quot; INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V L1 LINENUMBER 24 L1 RETURN L2 LOCALVARIABLE this Lcom/zhouyu/service/UserService; L0 L2 0 MAXSTACK = 2 MAXLOCALS = 1 // access flags 0x1041 public synthetic bridge setOrderService(Ljava/lang/Object;)V @Lorg/springframework/beans/factory/annotation/Autowired;() L0 LINENUMBER 11 L0 ALOAD 0 ALOAD 1 CHECKCAST com/zhouyu/service/OrderService INVOKEVIRTUAL com/zhouyu/service/UserService.setOrderService (Lcom/zhouyu/service/OrderService;)V RETURN L1 LOCALVARIABLE this Lcom/zhouyu/service/UserService; L0 L1 0 MAXSTACK = 2 MAXLOCALS = 2&#125; 可以看到在UserSerivce的字节码中有两个setOrderService方法： public setOrderService(Lcom&#x2F;zhouyu&#x2F;service&#x2F;OrderService;)V public synthetic bridge setOrderService(Ljava&#x2F;lang&#x2F;Object;)V 并且都是存在@Autowired注解的。​ 所以在Spring中需要处理这种情况，当遍历到桥接方法时，得找到原方法。 注入点进行注入Spring在AutowiredAnnotationBeanPostProcessor的**postProcessProperties()**方法中，会遍历所找到的注入点依次进行注入。​ 字段注入 遍历所有的AutowiredFieldElement对象。 将对应的字段封装为DependencyDescriptor对象。 调用BeanFactory的resolveDependency()方法，传入DependencyDescriptor对象，进行依赖查找，找到当前字段所匹配的Bean对象。 将DependencyDescriptor对象和所找到的结果对象beanName封装成一个ShortcutDependencyDescriptor对象作为缓存，比如如果当前Bean是原型Bean，那么下次再来创建该Bean时，就可以直接拿缓存的结果对象beanName去BeanFactory中去那bean对象了，不用再次进行查找了 利用反射将结果对象赋值给字段。 Set方法注入 遍历所有的AutowiredMethodElement对象 遍历将对应的方法的参数，将每个参数封装成MethodParameter对象 将MethodParameter对象封装为DependencyDescriptor对象 调用BeanFactory的resolveDependency()方法，传入DependencyDescriptor对象，进行依赖查找，找到当前方法参数所匹配的Bean对象。 将DependencyDescriptor对象和所找到的结果对象beanName封装成一个ShortcutDependencyDescriptor对象作为缓存，比如如果当前Bean是原型Bean，那么下次再来创建该Bean时，就可以直接拿缓存的结果对象beanName去BeanFactory中去那bean对象了，不用再次进行查找了 利用反射将找到的所有结果对象传给当前方法，并执行。 上节课我们讲了Spring中的自动注入(byName,byType)和@Autowired注解的工作原理以及源码分析，那么今天这节课，我们来分析还没讲完的，剩下的核心的方法： 123@NullableObject resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException; 该方法表示，传入一个依赖描述（DependencyDescriptor），该方法会根据该依赖描述从BeanFactory中找出对应的唯一的一个Bean对象。 下面来分析一下DefaultListableBeanFactory中resolveDependency()方法的具体实现，具体流程图：https://www.processon.com/view/link/5f8d3c895653bb06ef076688 findAutowireCandidates()实现根据类型找beanName的底层流程：https://www.processon.com/view/link/6135bb430e3e7412ecd5d1f2对应执行流程图为：https://www.processon.com/view/link/5f8fdfa8e401fd06fd984f20​ 找出BeanFactory中类型为type的所有的Bean的名字，注意是名字，而不是Bean对象，因为我们可以根据BeanDefinition就能判断和当前type是不是匹配，不用生成Bean对象 把resolvableDependencies中key为type的对象找出来并添加到result中 遍历根据type找出的beanName，判断当前beanName对应的Bean是不是能够被自动注入 先判断beanName对应的BeanDefinition中的autowireCandidate属性，如果为false，表示不能用来进行自动注入，如果为true则继续进行判断 判断当前type是不是泛型，如果是泛型是会把容器中所有的beanName找出来的，如果是这种情况，那么在这一步中就要获取到泛型的真正类型，然后进行匹配，如果当前beanName和当前泛型对应的真实类型匹配，那么则继续判断 如果当前DependencyDescriptor上存在@Qualifier注解，那么则要判断当前beanName上是否定义了Qualifier，并且是否和当前DependencyDescriptor上的Qualifier相等，相等则匹配 经过上述验证之后，当前beanName才能成为一个可注入的，添加到result中 关于依赖注入中泛型注入的实现首先在Java反射中，有一个Type接口，表示类型，具体分类为： raw types：也就是普通Class parameterized types：对应ParameterizedType接口，泛型类型 array types：对应GenericArrayType，泛型数组 type variables：对应TypeVariable接口，表示类型变量，也就是所定义的泛型，比如T、K primitive types：基本类型，int、boolean 大家可以好好看看下面代码所打印的结果：​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class TypeTest&lt;T&gt; &#123; private int i; private Integer it; private int[] iarray; private List list; private List&lt;String&gt; slist; private List&lt;T&gt; tlist; private T t; private T[] tarray; public static void main(String[] args) throws NoSuchFieldException &#123; test(TypeTest.class.getDeclaredField(&quot;i&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;it&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;iarray&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;list&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;slist&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;tlist&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;t&quot;)); System.out.println(&quot;=======&quot;); test(TypeTest.class.getDeclaredField(&quot;tarray&quot;)); &#125; public static void test(Field field) &#123; if (field.getType().isPrimitive()) &#123; System.out.println(field.getName() + &quot;是基本数据类型&quot;); &#125; else &#123; System.out.println(field.getName() + &quot;不是基本数据类型&quot;); &#125; if (field.getGenericType() instanceof ParameterizedType) &#123; System.out.println(field.getName() + &quot;是泛型类型&quot;); &#125; else &#123; System.out.println(field.getName() + &quot;不是泛型类型&quot;); &#125; if (field.getType().isArray()) &#123; System.out.println(field.getName() + &quot;是普通数组&quot;); &#125; else &#123; System.out.println(field.getName() + &quot;不是普通数组&quot;); &#125; if (field.getGenericType() instanceof GenericArrayType) &#123; System.out.println(field.getName() + &quot;是泛型数组&quot;); &#125; else &#123; System.out.println(field.getName() + &quot;不是泛型数组&quot;); &#125; if (field.getGenericType() instanceof TypeVariable) &#123; System.out.println(field.getName() + &quot;是泛型变量&quot;); &#125; else &#123; System.out.println(field.getName() + &quot;不是泛型变量&quot;); &#125; &#125;&#125; Spring中，但注入点是一个泛型时，也是会进行处理的，比如：​ 1234567891011121314151617@Componentpublic class UserService extends BaseService&lt;OrderService, StockService&gt; &#123; public void test() &#123; System.out.println(o); &#125;&#125;public class BaseService&lt;O, S&gt; &#123; @Autowired protected O o; @Autowired protected S s;&#125; Spring扫描时发现UserService是一个Bean 那就取出注入点，也就是BaseService中的两个属性o、s 接下来需要按注入点类型进行注入，但是o和s都是泛型，所以Spring需要确定o和s的具体类型。 因为当前正在创建的是UserService的Bean，所以可以通过userService.getClass().getGenericSuperclass().getTypeName()获取到具体的泛型信息，比如com.zhouyu.service.BaseService&lt;com.zhouyu.service.OrderService, com.zhouyu.service.StockService&gt; 然后再拿到UserService的父类BaseService的泛型变量： for (TypeVariable&lt;? extends Class&lt;?&gt;&gt; typeParameter : userService.getClass().getSuperclass().getTypeParameters()) &#123; System._out_.println(typeParameter.getName()); &#125; 通过上面两段代码，就能知道，o对应的具体就是OrderService，s对应的具体类型就是StockService 然后再调用oField.getGenericType()就知道当前field使用的是哪个泛型，就能知道具体类型了 @Qualifier的使用定义两个注解： 12345678910@Target(&#123;ElementType.TYPE, ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)@Qualifier(&quot;random&quot;)public @interface Random &#123;&#125;@Target(&#123;ElementType.TYPE, ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)@Qualifier(&quot;roundRobin&quot;)public @interface RoundRobin &#123;&#125; 定义一个接口和两个实现类，表示负载均衡： 123public interface LoadBalance &#123; String select();&#125; 123456789101112131415161718@Component@Randompublic class RandomStrategy implements LoadBalance &#123; @Override public String select() &#123; return null; &#125;&#125;@Component@RoundRobinpublic class RoundRobinStrategy implements LoadBalance &#123; @Override public String select() &#123; return null; &#125;&#125; 使用： 123456789101112@Componentpublic class UserService &#123; @Autowired @RoundRobin private LoadBalance loadBalance; public void test() &#123; System.out.println(loadBalance); &#125;&#125; @Resource@Resource注解底层工作流程图：https://www.processon.com/view/link/5f91275f07912906db381f6e 第五章 循环依赖什么是循环依赖？很简单，就是A对象依赖了B对象，B对象依赖了A对象。 比如： 123456789// A依赖了Bclass A&#123; public B b;&#125;// B依赖了Aclass B&#123; public A a;&#125; 那么循环依赖是个问题吗？ 如果不考虑Spring，循环依赖并不是问题，因为对象之间相互依赖是很正常的事情。 比如 12345A a = new A();B b = new B();a.b = b;b.a = a; 这样，A,B就依赖上了。 但是，在Spring中循环依赖就是一个问题了，为什么？因为，在Spring中，一个对象并不是简单new出来了，而是会经过一系列的Bean的生命周期，就是因为Bean的生命周期所以才会出现循环依赖问题。当然，在Spring中，出现循环依赖的场景很多，有的场景Spring自动帮我们解决了，而有的场景则需要程序员来解决，下文详细来说。 要明白Spring中的循环依赖，得先明白Spring中Bean的生命周期。 Bean的生命周期这里不会对Bean的生命周期进行详细的描述，只描述一下大概的过程。 Bean的生命周期指的就是：在Spring中，Bean是如何生成的？ 被Spring管理的对象叫做Bean。Bean的生成步骤如下： Spring扫描class得到BeanDefinition 根据得到的BeanDefinition去生成bean 首先根据class推断构造方法 根据推断出来的构造方法，反射，得到一个对象（暂时叫做原始对象） 填充原始对象中的属性（依赖注入） 如果原始对象中的某个方法被AOP了，那么则需要根据原始对象生成一个代理对象 把最终生成的代理对象放入单例池（源码中叫做singletonObjects）中，下次getBean时就直接从单例池拿即可 可以看到，对于Spring中的Bean的生成过程，步骤还是很多的，并且不仅仅只有上面的7步，还有很多很多，比如Aware回调、初始化等等，这里不详细讨论。 可以发现，在Spring中，构造一个Bean，包括了new这个步骤（第4步构造方法反射）。 得到一个原始对象后，Spring需要给对象中的属性进行依赖注入，那么这个注入过程是怎样的？ 比如上文说的A类，A类中存在一个B类的b属性，所以，当A类生成了一个原始对象之后，就会去给b属性去赋值，此时就会根据b属性的类型和属性名去BeanFactory中去获取B类所对应的单例bean。如果此时BeanFactory中存在B对应的Bean，那么直接拿来赋值给b属性；如果此时BeanFactory中不存在B对应的Bean，则需要生成一个B对应的Bean，然后赋值给b属性。 问题就出现在第二种情况，如果此时B类在BeanFactory中还没有生成对应的Bean，那么就需要去生成，就会经过B的Bean的生命周期。 那么在创建B类的Bean的过程中，如果B类中存在一个A类的a属性，那么在创建B的Bean的过程中就需要A类对应的Bean，但是，触发B类Bean的创建的条件是A类Bean在创建过程中的依赖注入，所以这里就出现了循环依赖： ABean创建–&gt;依赖了B属性–&gt;触发BBean创建—&gt;B依赖了A属性—&gt;需要ABean（但ABean还在创建过程中） 从而导致ABean创建不出来，BBean也创建不出来。 这是循环依赖的场景，但是上文说了，在Spring中，通过某些机制帮开发者解决了部分循环依赖的问题，这个机制就是三级缓存。 三级缓存三级缓存是通用的叫法。一级缓存为：singletonObjects二级缓存为：earlySingletonObjects三级缓存为：singletonFactories​ 先稍微解释一下这三个缓存的作用，后面详细分析： singletonObjects中缓存的是已经经历了完整生命周期的bean对象。 earlySingletonObjects比singletonObjects多了一个early，表示缓存的是早期的bean对象。早期是什么意思？表示Bean的生命周期还没走完就把这个Bean放入了earlySingletonObjects。 singletonFactories中缓存的是ObjectFactory，表示对象工厂，表示用来创建早期bean对象的工厂。 解决循环依赖思路分析先来分析为什么缓存能解决循环依赖。 上文分析得到，之所以产生循环依赖的问题，主要是： A创建时—&gt;需要B—-&gt;B去创建—&gt;需要A，从而产生了循环 那么如何打破这个循环，加个中间人（缓存） A的Bean在创建过程中，在进行依赖注入之前，先把A的原始Bean放入缓存（提早暴露，只要放到缓存了，其他Bean需要时就可以从缓存中拿了），放入缓存后，再进行依赖注入，此时A的Bean依赖了B的Bean，如果B的Bean不存在，则需要创建B的Bean，而创建B的Bean的过程和A一样，也是先创建一个B的原始对象，然后把B的原始对象提早暴露出来放入缓存中，然后在对B的原始对象进行依赖注入A，此时能从缓存中拿到A的原始对象（虽然是A的原始对象，还不是最终的Bean），B的原始对象依赖注入完了之后，B的生命周期结束，那么A的生命周期也能结束。 因为整个过程中，都只有一个A原始对象，所以对于B而言，就算在属性注入时，注入的是A原始对象，也没有关系，因为A原始对象在后续的生命周期中在堆中没有发生变化。 从上面这个分析过程中可以得出，只需要一个缓存就能解决循环依赖了，那么为什么Spring中还需要singletonFactories呢？ 这是难点，基于上面的场景想一个问题：如果A的原始对象注入给B的属性之后，A的原始对象进行了AOP产生了一个代理对象，此时就会出现，对于A而言，它的Bean对象其实应该是AOP之后的代理对象，而B的a属性对应的并不是AOP之后的代理对象，这就产生了冲突。 B依赖的A和最终的A不是同一个对象。 AOP就是通过一个BeanPostProcessor来实现的，这个BeanPostProcessor就是AnnotationAwareAspectJAutoProxyCreator，它的父类是AbstractAutoProxyCreator，而在Spring中AOP利用的要么是JDK动态代理，要么CGLib的动态代理，所以如果给一个类中的某个方法设置了切面，那么这个类最终就需要生成一个代理对象。 一般过程就是：A类—&gt;生成一个普通对象–&gt;属性注入–&gt;基于切面生成一个代理对象–&gt;把代理对象放入singletonObjects单例池中。 而AOP可以说是Spring中除开IOC的另外一大功能，而循环依赖又是属于IOC范畴的，所以这两大功能想要并存，Spring需要特殊处理。 如何处理的，就是利用了第三级缓存singletonFactories。 首先，singletonFactories中存的是某个beanName对应的ObjectFactory，在bean的生命周期中，生成完原始对象之后，就会构造一个ObjectFactory存入singletonFactories中。这个ObjectFactory是一个函数式接口，所以支持Lambda表达式：**() -&gt; getEarlyBeanReference(beanName, mbd, bean)** 上面的Lambda表达式就是一个ObjectFactory，执行该Lambda表达式就会去执行getEarlyBeanReference方法，而该方法如下： 123456789101112protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject;&#125; 该方法会去执行SmartInstantiationAwareBeanPostProcessor中的getEarlyBeanReference方法，而这个接口下的实现类中只有两个类实现了这个方法，一个是AbstractAutoProxyCreator，一个是InstantiationAwareBeanPostProcessorAdapter，它的实现如下： 123456789101112// InstantiationAwareBeanPostProcessorAdapter@Overridepublic Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; return bean;&#125;// AbstractAutoProxyCreator@Overridepublic Object getEarlyBeanReference(Object bean, String beanName) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey);&#125; 在整个Spring中，默认就只有AbstractAutoProxyCreator真正意义上实现了getEarlyBeanReference方法，而该类就是用来进行AOP的。上文提到的AnnotationAwareAspectJAutoProxyCreator的父类就是AbstractAutoProxyCreator。 那么getEarlyBeanReference方法到底在干什么？首先得到一个cachekey，cachekey就是beanName。然后把beanName和bean（这是原始对象）存入earlyProxyReferences中调用wrapIfNecessary进行AOP，得到一个代理对象。 那么，什么时候会调用getEarlyBeanReference方法呢？回到循环依赖的场景中 左边文字：这个ObjectFactory就是上文说的labmda表达式，中间有getEarlyBeanReference方法，注意存入singletonFactories时并不会执行lambda表达式，也就是不会执行getEarlyBeanReference方法 右边文字：从singletonFactories根据beanName得到一个ObjectFactory，然后执行ObjectFactory，也就是执行getEarlyBeanReference方法，此时会得到一个A原始对象经过AOP之后的代理对象，然后把该代理对象放入earlySingletonObjects中，注意此时并没有把代理对象放入singletonObjects中，那什么时候放入到singletonObjects中呢？ 我们这个时候得来理解一下earlySingletonObjects的作用，此时，我们只得到了A原始对象的代理对象，这个对象还不完整，因为A原始对象还没有进行属性填充，所以此时不能直接把A的代理对象放入singletonObjects中，所以只能把代理对象放入earlySingletonObjects，假设现在有其他对象依赖了A，那么则可以从earlySingletonObjects中得到A原始对象的代理对象了，并且是A的同一个代理对象。 当B创建完了之后，A继续进行生命周期，而A在完成属性注入后，会按照它本身的逻辑去进行AOP，而此时我们知道A原始对象已经经历过了AOP，所以对于A本身而言，不会再去进行AOP了，那么怎么判断一个对象是否经历过了AOP呢？会利用上文提到的earlyProxyReferences，在AbstractAutoProxyCreator的postProcessAfterInitialization方法中，会去判断当前beanName是否在earlyProxyReferences，如果在则表示已经提前进行过AOP了，无需再次进行AOP。 对于A而言，进行了AOP的判断后，以及BeanPostProcessor的执行之后，就需要把A对应的对象放入singletonObjects中了，但是我们知道，应该是要把A的代理对象放入singletonObjects中，所以此时需要从earlySingletonObjects中得到代理对象，然后入singletonObjects中。 整个循环依赖解决完毕。 总结至此，总结一下三级缓存： singletonObjects：缓存经过了完整生命周期的bean earlySingletonObjects：缓存未经过完整生命周期的bean，如果某个bean出现了循环依赖，就会提前把这个暂时未经过完整生命周期的bean放入earlySingletonObjects中，这个bean如果要经过AOP，那么就会把代理对象放入earlySingletonObjects中，否则就是把原始对象放入earlySingletonObjects，但是不管怎么样，就是是代理对象，代理对象所代理的原始对象也是没有经过完整生命周期的，所以放入earlySingletonObjects我们就可以统一认为是未经过完整生命周期的bean。 singletonFactories：缓存的是一个ObjectFactory，也就是一个Lambda表达式。在每个Bean的生成过程中，经过实例化得到一个原始对象后，都会提前基于原始对象暴露一个Lambda表达式，并保存到三级缓存中，这个Lambda表达式可能用到，也可能用不到，如果当前Bean没有出现循环依赖，那么这个Lambda表达式没用，当前bean按照自己的生命周期正常执行，执行完后直接把当前bean放入singletonObjects中，如果当前bean在依赖注入时发现出现了循环依赖（当前正在创建的bean被其他bean依赖了），则从三级缓存中拿到Lambda表达式，并执行Lambda表达式得到一个对象，并把得到的对象放入二级缓存（(如果当前Bean需要AOP，那么执行lambda表达式，得到就是对应的代理对象，如果无需AOP，则直接得到一个原始对象)）。 其实还要一个缓存，就是earlyProxyReferences，它用来记录某个原始对象是否进行过AOP了。 反向分析一下singletonFactories为什么需要singletonFactories？假设没有singletonFactories，只有earlySingletonObjects，earlySingletonObjects是二级缓存，它内部存储的是为经过完整生命周期的bean对象，Spring原有的流程是出现了循环依赖的情况下： 先从singletonFactories中拿到lambda表达式，这里肯定是能拿到的，因为每个bean实例化之后，依赖注入之前，就会生成一个lambda表示放入singletonFactories中 执行lambda表达式，得到结果，将结果放入earlySingletonObjects中 那如果没有singletonFactories，该如何把原始对象或AOP之后的代理对象放入earlySingletonObjects中呢？何时放入呢？​ 首先，将原始对象或AOP之后的代理对象放入earlySingletonObjects中的有两种： 实例化之后，依赖注入之前：如果是这样，那么对于每个bean而言，都是在依赖注入之前会去进行AOP，这是不符合bean生命周期步骤的设计的。 真正发现某个bean出现了循环依赖时：按现在Spring源码的流程来说，就是getSingleton(String beanName, boolean allowEarlyReference)中，是在这个方法中判断出来了当前获取的这个bean在创建中，就表示获取的这个bean出现了循环依赖，那在这个方法中该如何拿到原始对象呢？更加重要的是，该如何拿到AOP之后的代理对象呢？难道在这个方法中去循环调用BeanPostProcessor的初始化后的方法吗？不是做不到，不太合适，代码太丑。最关键的是在这个方法中该如何拿到原始对象呢？还是得需要一个Map，预习把这个Bean实例化后的对象存在这个Map中，那这样的话还不如直接用第一种方案，但是第一种又直接打破了Bean生命周期的设计。 所以，我们可以发现，现在Spring所用的singletonFactories，为了调和不同的情况，在singletonFactories中存的是lambda表达式，这样的话，只有在出现了循环依赖的情况，才会执行lambda表达式，才会进行AOP，也就说只有在出现了循环依赖的情况下才会打破Bean生命周期的设计，如果一个Bean没有出现循环依赖，那么它还是遵守了Bean的生命周期的设计的。 推断构造方法流程图：https://www.processon.com/view/link/5f97bc717d9c0806f291d7eb​ AutowiredAnnotationBeanPostProcessor中推断构造方法不同情况思维脑图：https://www.processon.com/view/link/6146def57d9c08198c58bb26​ Spring中的一个bean，需要实例化得到一个对象，而实例化就需要用到构造方法。 一般情况下，一个类只有一个构造方法： 要么是无参的构造方法 要么是有参的构造方法 如果只有一个无参的构造方法，那么实例化就只能使用这个构造方法了。如果只有一个有参的构造方法，那么实例化时能使用这个构造方法吗？要分情况讨论： 使用AnnotationConfigApplicationContext，会使用这个构造方法进行实例化，那么Spring会根据构造方法的参数信息去寻找bean，然后传给构造方法 使用ClassPathXmlApplicationContext，表示使用XML的方式来使用bean，要么在XML中指定构造方法的参数值(手动指定)，要么配置autowire&#x3D;constructor让Spring自动去寻找bean做为构造方法参数值。 上面是只有一个构造方法的情况，那么如果有多个构造方法呢？ 又分为两种情况，多个构造方法中存不存在无参的构造方法。 分析：一个类存在多个构造方法，那么Spring进行实例化之前，该如何去确定到底用哪个构造方法呢？ 如果开发者指定了想要使用的构造方法，那么就用这个构造方法 如果开发者没有指定想要使用的构造方法，则看开发者有没有让Spring自动去选择构造方法 如果开发者也没有让Spring自动去选择构造方法，则Spring利用无参构造方法，如果没有无参构造方法，则报错 针对第一点，开发者可以通过什么方式来指定使用哪个构造方法呢？ xml中的标签，这个标签表示构造方法参数，所以可以根据这个确定想要使用的构造方法的参数个数，从而确定想要使用的构造方法 通过@Autowired注解，@Autowired注解可以写在构造方法上，所以哪个构造方法上写了@Autowired注解，表示开发者想使用哪个构造方法，当然，它和第一个方式的不同点是，通过xml的方式，我们直接指定了构造方法的参数值，而通过@Autowired注解的方式，需要Spring通过byType+byName的方式去找到符合条件的bean作为构造方法的参数值 再来看第二点，如果开发者没有指定想要使用的构造方法，则看开发者有没有让Spring自动去选择构造方法，对于这一点，只能用在ClassPathXmlApplicationContext，因为通过AnnotationConfigApplicationContext没有办法去指定某个bean可以自动去选择构造方法，而通过ClassPathXmlApplicationContext可以在xml中指定某个bean的autowire为constructor，虽然这个属性表示通过构造方法自动注入，所以需要自动的去选择一个构造方法进行自动注入，因为是构造方法，所以顺便是进行实例化。 当然，还有一种情况，就是多个构造方法上写了@Autowired注解，那么此时Spring会报错。但是，因为@Autowired还有一个属性required，默认为ture，所以一个类中，只有能一个构造方法标注了@Autowired或@Autowired（required&#x3D;true），有多个会报错。但是可以有多个@Autowired（required&#x3D;false）,这种情况下，需要Spring从这些构造方法中去自动选择一个构造方法。 源码思路 AbstractAutowireCapableBeanFactory类中的createBeanInstance()方法会去创建一个Bean实例 根据BeanDefinition加载类得到Class对象 如果BeanDefinition绑定了一个Supplier，那就调用Supplier的get方法得到一个对象并直接返回 如果BeanDefinition中存在factoryMethodName，那么就调用该工厂方法得到一个bean对象并返回 如果BeanDefinition已经自动构造过了，那就调用autowireConstructor()自动构造一个对象 调用SmartInstantiationAwareBeanPostProcessor的determineCandidateConstructors()方法得到哪些构造方法是可以用的 如果存在可用得构造方法，或者当前BeanDefinition的autowired是AUTOWIRE_CONSTRUCTOR，或者BeanDefinition中指定了构造方法参数值，或者创建Bean的时候指定了构造方法参数值，那么就调用**autowireConstructor()**方法自动构造一个对象 最后，如果不是上述情况，就根据无参的构造方法实例化一个对象 autowireConstructor() 先检查是否指定了具体的构造方法和构造方法参数值，或者在BeanDefinition中缓存了具体的构造方法或构造方法参数值，如果存在那么则直接使用该构造方法进行实例化 如果没有确定的构造方法或构造方法参数值，那么 如果没有确定的构造方法，那么则找出类中所有的构造方法 如果只有一个无参的构造方法，那么直接使用无参的构造方法进行实例化 如果有多个可用的构造方法或者当前Bean需要自动通过构造方法注入 根据所指定的构造方法参数值，确定所需要的最少的构造方法参数值的个数 对所有的构造方法进行排序，参数个数多的在前面 遍历每个构造方法 如果不是调用getBean方法时所指定的构造方法参数值，那么则根据构造方法参数类型找值 如果时调用getBean方法时所指定的构造方法参数值，就直接利用这些值 如果根据当前构造方法找到了对应的构造方法参数值，那么这个构造方法就是可用的，但是不一定这个构造方法就是最佳的，所以这里会涉及到是否有多个构造方法匹配了同样的值，这个时候就会用值和构造方法类型进行匹配程度的打分，找到一个最匹配的 为什么分越少优先级越高？主要是计算找到的bean和构造方法参数类型匹配程度有多高。 假设bean的类型为A，A的父类是B，B的父类是C，同时A实现了接口D如果构造方法的参数类型为A，那么完全匹配，得分为0如果构造方法的参数类型为B，那么得分为2如果构造方法的参数类型为C，那么得分为4如果构造方法的参数类型为D，那么得分为1 可以直接使用如下代码进行测试： 12345678910111213Object[] objects = new Object[]&#123;new A()&#125;;// 0System.out.println(MethodInvoker.getTypeDifferenceWeight(new Class[]&#123;A.class&#125;, objects));// 2System.out.println(MethodInvoker.getTypeDifferenceWeight(new Class[]&#123;B.class&#125;, objects));// 4System.out.println(MethodInvoker.getTypeDifferenceWeight(new Class[]&#123;C.class&#125;, objects));// 1System.out.println(MethodInvoker.getTypeDifferenceWeight(new Class[]&#123;D.class&#125;, objects)); 所以，我们可以发现，越匹配分数越低。 @Bean的情况首先，Spring会把@Bean修饰的方法解析成BeanDefinition： 如果方法是static的，那么解析出来的BeanDefinition中： factoryBeanName为AppConfig所对应的beanName，比如”appConfig” factoryMethodName为对应的方法名，比如”aService” factoryClass为AppConfig.class 如果方法不是static的，那么解析出来的BeanDefinition中： factoryBeanName为null factoryMethodName为对应的方法名，比如”aService” factoryClass也为AppConfig.class 在由@Bean生成的BeanDefinition中，有一个重要的属性isFactoryMethodUnique，表示factoryMethod是不是唯一的，在普通情况下@Bean生成的BeanDefinition的isFactoryMethodUnique为true，但是如果出现了方法重载，那么就是特殊的情况，比如： 123456789@Beanpublic static AService aService()&#123; return new AService();&#125;@Beanpublic AService aService(BService bService)&#123; return new AService();&#125; 虽然有两个@Bean，但是肯定只会生成一个aService的Bean，那么Spring在处理@Bean时，也只会生成一个aService的BeanDefinition，比如Spring先解析到第一个@Bean，会生成一个BeanDefinition，此时isFactoryMethodUnique为true，但是解析到第二个@Bean时，会判断出来beanDefinitionMap中已经存在一个aService的BeanDefinition了，那么会把之前的这个BeanDefinition的isFactoryMethodUnique修改为false，并且不会生成新的BeanDefinition了。​ 并且后续在根据BeanDefinition创建Bean时，会根据isFactoryMethodUnique来操作，如果为true，那就表示当前BeanDefinition只对应了一个方法，那也就是只能用这个方法来创建Bean了，但是如果isFactoryMethodUnique为false，那就表示当前BeanDefition对应了多个方法，需要和推断构造方法的逻辑一样，去选择用哪个方法来创建Bean。 第六章 Spring之整合Mybatis mybatis-spring jar包 JDK动态代理返回xxxMapper代理类 注册组件的整合 整合核心思路由很多框架都需要和Spring进行整合，而整合的核心思想就是把其他框架所产生的对象放到Spring容器中，让其成为Bean。 \\ 比如Mybatis，Mybatis框架可以单独使用，而单独使用Mybatis框架就需要用到Mybatis所提供的一些类构造出对应的对象，然后使用该对象，就能使用到Mybatis框架给我们提供的功能，和Mybatis整合Spring就是为了将这些对象放入Spring容器中成为Bean，只要成为了Bean，在我们的Spring项目中就能很方便的使用这些对象了，也就能很方便的使用Mybatis框架所提供的功能了。 实现简易mybatismybatis使用&#x2F;需求分析 根据类型注入Mapper增强类型(将增强类型注册到容器) 多个Mapper写活 给构造器指定值 通过后置处理器增强 写死不好,想要拿到扫描路径 也可以写 这个 接口会给你一些工具 比如这个注解原信息 spring自带Scanner 但是不关心接口 ,可mybatis只关心接口 需要重写扫描器的逻辑 两个判断 带component和另一个sbd才能被扫描器扫入 mybatis解决: 不符合要求 Beandefinition里是接口mapper 需要 是factoryBean里的代理类 解决 Mybatis-Spring 1.3.2版本底层源码执行流程 通过@MapperScan导入了MapperScannerRegistrar类 MapperScannerRegistrar类实现了ImportBeanDefinitionRegistrar接口，所以Spring在启动时会调用MapperScannerRegistrar类中的registerBeanDefinitions方法 在registerBeanDefinitions方法中定义了一个ClassPathMapperScanner对象，用来扫描mapper 设置ClassPathMapperScanner对象可以扫描到接口，因为在Spring中是不会扫描接口的 同时因为ClassPathMapperScanner中重写了isCandidateComponent方法，导致isCandidateComponent只会认为接口是备选者Component 通过利用Spring的扫描后，会把接口扫描出来并且得到对应的BeanDefinition 接下来把扫描得到的BeanDefinition进行修改，把BeanClass修改为MapperFactoryBean，把AutowireMode修改为byType 扫描完成后，Spring就会基于BeanDefinition去创建Bean了，相当于每个Mapper对应一个FactoryBean 在MapperFactoryBean中的getObject方法中，调用了getSqlSession()去得到一个sqlSession对象，然后根据对应的Mapper接口生成一个Mapper接口代理对象，这个代理对象就成为Spring容器中的Bean sqlSession对象是Mybatis中的，一个sqlSession对象需要SqlSessionFactory来产生 MapperFactoryBean的AutowireMode为byType，所以Spring会自动调用set方法，有两个set方法，一个setSqlSessionFactory，一个setSqlSessionTemplate，而这两个方法执行的前提是根据方法参数类型能找到对应的bean，所以Spring容器中要存在SqlSessionFactory类型的bean或者SqlSessionTemplate类型的bean。 如果你定义的是一个SqlSessionFactory类型的bean，那么最终也会被包装为一个SqlSessionTemplate对象，并且赋值给sqlSession属性 而在SqlSessionTemplate类中就存在一个getMapper方法，这个方法中就产生一个Mapper接口代理对象 到时候，当执行该代理对象的某个方法时，就会进入到Mybatis框架的底层执行流程，详细的请看下图 Spring整合Mybatis之后SQL执行流程：https://www.processon.com/view/link/6152cc385653bb6791db436c Mybatis-Spring 2.0.6版本(最新版)底层源码执行流程 通过@MapperScan导入了MapperScannerRegistrar类 MapperScannerRegistrar类实现了ImportBeanDefinitionRegistrar接口，所以Spring在启动时会调用MapperScannerRegistrar类中的registerBeanDefinitions方法 在registerBeanDefinitions方法中注册一个MapperScannerConfigurer类型的BeanDefinition 而MapperScannerConfigurer实现了BeanDefinitionRegistryPostProcessor接口，所以Spring在启动过程中时会调用它的postProcessBeanDefinitionRegistry()方法 在postProcessBeanDefinitionRegistry方法中会生成一个ClassPathMapperScanner对象，然后进行扫描 后续的逻辑和1.3.2版本一样。 带来的好处是，可以不使用@MapperScan注解，而可以直接定义一个Bean，比如： 123456@Beanpublic MapperScannerConfigurer mapperScannerConfigurer() &#123; MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer(); mapperScannerConfigurer.setBasePackage(&quot;com.luban&quot;); return mapperScannerConfigurer;&#125; Spring整合Mybatis后一级缓存失效问题先看下图：Spring整合Mybatis之后SQL执行流程：https://www.processon.com/view/link/6152cc385653bb6791db436c​ Mybatis中的一级缓存是基于SqlSession来实现的，所以在执行同一个sql时，如果使用的是同一个SqlSession对象，那么就能利用到一级缓存，提高sql的执行效率。​ 但是在Spring整合Mybatis后，如果没有执行某个方法时，该方法上没有加@Transactional注解，也就是没有开启Spring事务，那么后面在执行具体sql时，没执行一个sql时都会新生成一个SqlSession对象来执行该sql，这就是我们说的一级缓存失效（也就是没有使用同一个SqlSession对象），而如果开启了Spring事务，那么该Spring事务中的多个sql，在执行时会使用同一个SqlSession对象，从而一级缓存生效，具体的底层执行流程在上图。​ 个人理解：实际上Spring整合Mybatis后一级缓存失效并不是问题，是正常的实现，因为，一个方法如果没有开启Spring事务，那么在执行sql时候，那就是每个sql单独一个事务来执行，也就是单独一个SqlSession对象来执行该sql，如果开启了Spring事务，那就是多个sql属于同一个事务，那自然就应该用一个SqlSession来执行这多个sql。所以，在没有开启Spring事务的时候，SqlSession的一级缓存并不是失效了，而是存在的生命周期太短了（执行完一个sql后就被销毁了，下一个sql执行时又是一个新的SqlSession了）。​ 第七章 AOP动态代理代理模式的解释：为其他对象提供一种代理以控制对这个对象的访问，增强一个类中的某个方法，对程序进行扩展。 比如，现在存在一个UserService类： 1234567public class UserService &#123; public void test() &#123; System.out.println(&quot;test...&quot;); &#125;&#125; 此时，我们new一个UserService对象，然后执行test()方法，结果是显而易见的。​ 如果我们现在想在不修改UserService类的源码前提下，给test()增加额外逻辑，那么就可以使用动态代理机制来创建UserService对象了，比如： 12345678910111213141516171819202122UserService target = new UserService();// 通过cglib技术Enhancer enhancer = new Enhancer();enhancer.setSuperclass(UserService.class);// 定义额外逻辑，也就是代理逻辑enhancer.setCallbacks(new Callback[]&#123;new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;before...&quot;); Object result = methodProxy.invoke(target, objects); System.out.println(&quot;after...&quot;); return result; &#125;&#125;&#125;);// 动态代理所创建出来的UserService对象UserService userService = (UserService) enhancer.create();// 执行这个userService的test方法时，就会额外会执行一些其他逻辑userService.test(); 得到的都是UserService对象，但是执行test()方法时的效果却不一样了，这就是代理所带来的效果。 上面是通过cglib来实现的代理对象的创建，是基于父子类的，被代理类（UserService）是父类，代理类是子类，代理对象就是代理类的实例对象，代理类是由cglib创建的，对于程序员来说不用关心。​ 除开cglib技术，jdk本身也提供了一种创建代理对象的动态代理机制，但是它只能代理接口，也就是UserService得先有一个接口才能利用jdk动态代理机制来生成一个代理对象，比如： 1234567891011public interface UserInterface &#123; public void test();&#125;public class UserService implements UserInterface &#123; public void test() &#123; System.out.println(&quot;test...&quot;); &#125;&#125; 利用JDK动态代理来生成一个代理对象： 123456789101112131415UserService target = new UserService();// UserInterface接口的代理对象Object proxy = Proxy.newProxyInstance(UserService.class.getClassLoader(), new Class[]&#123;UserInterface.class&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;before...&quot;); Object result = method.invoke(target, args); System.out.println(&quot;after...&quot;); return result; &#125;&#125;);UserInterface userService = (UserInterface) proxy;userService.test(); 如果你把new Class[]{UserInterface.class}，替换成new Class[]{UserService.class}，允许代码会直接报错： 1Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: com.zhouyu.service.UserService is not an interface 表示一定要是个接口。​ 由于这个限制，所以产生的代理对象的类型是UserInterface，而不是UserService，这是需要注意的。 ProxyFactory上面我们介绍了两种动态代理技术，那么在Spring中进行了封装，封装出来的类叫做ProxyFactory，表示是创建代理对象的一个工厂，使用起来会比上面的更加方便，比如： 1234567891011121314151617UserService target = new UserService();ProxyFactory proxyFactory = new ProxyFactory();proxyFactory.setTarget(target);proxyFactory.addAdvice(new MethodInterceptor() &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; //增强所有的方法 System.out.println(&quot;before...&quot;); Object result = invocation.proceed(); System.out.println(&quot;after...&quot;); return result; &#125;&#125;);UserInterface userService = (UserInterface) proxyFactory.getProxy();userService.test(); 通过ProxyFactory，我们可以不再关系到底是用cglib还是jdk动态代理了，ProxyFactory会帮我们去判断，如果UserService实现了接口，那么ProxyFactory底层就会用jdk动态代理，如果没有实现接口，就会用cglib技术，上面的代码，就是由于UserService实现了UserInterface接口，所以最后产生的代理对象是UserInterface类型。 &#x2F;&#x2F; 123456789101112131415 //增强逻辑Object result = null; // 判断哪些方法需要增强 if (&quot;selectAll&quot;.equals(method.getName())) &#123; //权限校验 System.out.println(&quot;权限校验&quot;); //执行被代理类的目标方法 result = methodProxy.invokeSuper(proxy, args); //日志记录 System.out.println(&quot;日志记录&quot;); &#125; else &#123; //不是addUser和deleteUser执行目标方法 result = methodProxy.invokeSuper(proxy, args); &#125; return result; Advice的分类 Before Advice：方法之前执行 After returning advice：方法return后执行 After throwing advice：方法抛异常后执行 After (finally) advice：方法执行完finally之后执行，这是最后的，比return更后 Around advice：这是功能最强大的Advice，可以自定义执行顺序 看课上给的代码例子将一目了然​ Advisor的理解跟Advice类似的还有一个Advisor的概念，一个Advisor是有一个Pointcut和一个Advice组成的，通过Pointcut可以指定要需要被代理的逻辑，比如一个UserService类中有两个方法，按上面的例子，这两个方法都会被代理，被增强，那么我们现在可以通过Advisor，来控制到具体代理哪一个方法，比如： 12345678910111213141516171819202122232425262728293031323334353637 UserService target = new UserService(); ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.setTarget(target); proxyFactory.addAdvisor(new PointcutAdvisor() &#123; @Override public Pointcut getPointcut() &#123; return new StaticMethodMatcherPointcut() &#123; @Override public boolean matches(Method method, Class&lt;?&gt; targetClass) &#123; return method.getName().equals(&quot;testAbc&quot;); &#125; &#125;; &#125; @Override public Advice getAdvice() &#123; return new MethodInterceptor() &#123; //注意是覆写invoke方法的方法拦截器 @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(&quot;before...&quot;); Object result = invocation.proceed(); System.out.println(&quot;after...&quot;); return result; &#125; &#125;; &#125;// 这一步 @Override public boolean isPerInstance() &#123; return false; &#125; &#125;); UserInterface userService = (UserInterface) proxyFactory.getProxy(); userService.test(); 上面代码表示，产生的代理对象，只有在执行testAbc这个方法时才会被增强，会执行额外的逻辑，而在执行其他方法时是不会增强的。​ 创建代理对象的方式 proxyFactoryBean 类似proxyfacoty(只能单个Bean增强)返回一个代理对象放到IOC容器中 指定一个Advice 根据Beanname (BeanNameAutoProxyCreater) 指定一个Advice 找所有Advisor根据Advisor中的PointCut和Advice信息，确定要代理的Bean以及代理逻辑 上面介绍了Spring中所提供了ProxyFactory、Advisor、Advice、PointCut等技术来实现代理对象的创建，但是我们在使用Spring时，我们并不会直接这么去使用ProxyFactory，比如说，我们希望ProxyFactory所产生的代理对象能直接就是Bean，能直接从Spring容器中得到UserSerivce的代理对象，而这些，Spring都是支持的，只不过，作为开发者的我们肯定得告诉Spring，那些类需要被代理，代理逻辑是什么。 ProxyFactoryBean1234567891011121314151617@Beanpublic ProxyFactoryBean userServiceProxy()&#123; UserService userService = new UserService(); ProxyFactoryBean proxyFactoryBean = new ProxyFactoryBean(); proxyFactoryBean.setTarget(userService); proxyFactoryBean.addAdvice(new MethodInterceptor() &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(&quot;before...&quot;); Object result = invocation.proceed(); System.out.println(&quot;after...&quot;); return result; &#125; &#125;); return proxyFactoryBean;&#125; 通过这种方法来定义一个UserService的Bean，并且是经过了AOP的。但是这种方式只能针对某一个Bean。它是一个FactoryBean，所以利用的就是FactoryBean技术，间接的将UserService的代理对象作为了Bean。​ ProxyFactoryBean还有额外的功能，比如可以把某个Advise或Advisor定义成为Bean，然后在ProxyFactoryBean中进行设置 12345678910111213141516171819202122@Beanpublic MethodInterceptor zhouyuAroundAdvise()&#123; return new MethodInterceptor() &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(&quot;before...&quot;); Object result = invocation.proceed(); System.out.println(&quot;after...&quot;); return result; &#125; &#125;;&#125;@Beanpublic ProxyFactoryBean userService()&#123; UserService userService = new UserService(); ProxyFactoryBean proxyFactoryBean = new ProxyFactoryBean(); proxyFactoryBean.setTarget(userService); proxyFactoryBean.setInterceptorNames(&quot;zhouyuAroundAdvise&quot;); return proxyFactoryBean;&#125; BeanNameAutoProxyCreatorProxyFactoryBean得自己指定被代理的对象，那么我们可以通过BeanNameAutoProxyCreator来通过指定某个bean的名字，来对该bean进行代理 123456789@Beanpublic BeanNameAutoProxyCreator beanNameAutoProxyCreator() &#123; BeanNameAutoProxyCreator beanNameAutoProxyCreator = new BeanNameAutoProxyCreator(); beanNameAutoProxyCreator.setBeanNames(&quot;userSe*&quot;); beanNameAutoProxyCreator.setInterceptorNames(&quot;zhouyuAroundAdvise&quot;); beanNameAutoProxyCreator.setProxyTargetClass(true); return beanNameAutoProxyCreator;&#125; 通过BeanNameAutoProxyCreator可以对批量的Bean进行AOP，并且指定了代理逻辑，指定了一个InterceptorName，也就是一个Advise，前提条件是这个Advise也得是一个Bean，这样Spring才能找到的，但是BeanNameAutoProxyCreator的缺点很明显，它只能根据beanName来指定想要代理的Bean。​ DefaultAdvisorAutoProxyCreator12345678910111213141516171819@Beanpublic DefaultPointcutAdvisor defaultPointcutAdvisor()&#123; NameMatchMethodPointcut pointcut = new NameMatchMethodPointcut(); pointcut.addMethodName(&quot;test&quot;); DefaultPointcutAdvisor defaultPointcutAdvisor = new DefaultPointcutAdvisor(); defaultPointcutAdvisor.setPointcut(pointcut); defaultPointcutAdvisor.setAdvice(new ZhouyuAfterReturningAdvise()); return defaultPointcutAdvisor;&#125;@Beanpublic DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() &#123; DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); return defaultAdvisorAutoProxyCreator;&#125; 通过DefaultAdvisorAutoProxyCreator会直接去找所有Advisor类型的Bean，根据Advisor中的PointCut和Advice信息，确定要代理的Bean以及代理逻辑。 但是，我们发现，通过这种方式，我们得依靠某一个类来实现定义我们的Advisor，或者Advise，或者Pointcut，那么这个步骤能不能更加简化一点呢？​ 对的，通过注解！ 比如我们能不能只定义一个类，然后通过在类中的方法上通过某些注解，来定义PointCut以及Advice，可以的，比如： 12345678910@Aspect@Componentpublic class ZhouyuAspect &#123; @Before(&quot;execution(public void com.zhouyu.service.UserService.test())&quot;) public void zhouyuBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;zhouyuBefore&quot;); &#125;&#125; 通过上面这个类，我们就直接定义好了所要代理的方法(通过一个表达式)，以及代理逻辑（被@Before修饰的方法），简单明了，这样对于Spring来说，它要做的就是来解析这些注解了，解析之后得到对应的Pointcut对象、Advice对象，生成Advisor对象，扔进ProxyFactory中，进而产生对应的代理对象，具体怎么解析这些注解就是**@EnableAspectJAutoProxy注解**所要做的事情了，后面详细分析。 对Spring AOP的理解OOP表示面向对象编程，是一种编程思想，AOP表示面向切面编程，也是一种编程思想，而我们上面所描述的就是Spring为了让程序员更加方便的做到面向切面编程所提供的技术支持，换句话说，就是Spring提供了一套机制，可以让我们更加容易的来进行AOP，所以这套机制我们也可以称之为Spring AOP。​ 但是值得注意的是，上面所提供的注解的方式来定义Pointcut和Advice，Spring并不是首创，首创是AspectJ，而且也不仅仅只有Spring提供了一套机制来支持AOP，还有比如 JBoss 4.0、aspectwerkz等技术都提供了对于AOP的支持。而刚刚说的注解的方式，Spring是依赖了AspectJ的，或者说，Spring是直接把AspectJ中所定义的那些注解直接拿过来用，自己没有再重复定义了，不过也仅仅只是把注解的定义赋值过来了，每个注解具体底层是怎么解析的，还是Spring自己做的，所以我们在用Spring时，如果你想用@Before、@Around等注解，是需要单独引入aspecj相关jar包的，比如： 12compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjrt&#x27;, version: &#x27;1.9.5&#x27;compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjweaver&#x27;, version: &#x27;1.9.5&#x27; 值得注意的是：AspectJ是在编译时对字节码进行了修改，是直接在UserService类对应的字节码中进行增强的，也就是可以理解为是在编译时就会去解析@Before这些注解，然后得到代理逻辑，加入到被代理的类中的字节码中去的，所以如果想用AspectJ技术来生成代理对象 ，是需要用单独的AspectJ编译器的。我们在项目中很少这么用，我们仅仅只是用了@Before这些注解，而我们在启动Spring的过程中，Spring会去解析这些注解，然后利用动态代理机制生成代理对象的。​ IDEA中使用Aspectj：https://blog.csdn.net/gavin_john/article/details/80156963 AOP中的概念 Aspect：表示切面，比如被@Aspect注解的类就是切面，可以在切面中去定义Pointcut、Advice等等 Join point：表示连接点，表示一个程序在执行过程中的一个点，比如一个方法的执行，比如一个异常的处理，在Spring AOP中，一个连接点通常表示一个方法的执行。 Advice：表示通知，表示在一个特定连接点上所采取的动作。Advice分为不同的类型，后面详细讨论，在很多AOP框架中，包括Spring，会用Interceptor拦截器来实现Advice，并且在连接点周围维护一个Interceptor链 Pointcut：表示切点，用来匹配一个或多个连接点，Advice与切点表达式是关联在一起的，Advice将会执行在和切点表达式所匹配的连接点上 Introduction：可以使用@DeclareParents来给所匹配的类添加一个接口，并指定一个默认实现 Target object：目标对象，被代理对象 AOP proxy：表示代理工厂，用来创建代理对象的，在Spring Framework中，要么是JDK动态代理，要么是CGLIB代理 Weaving：表示织入，表示创建代理对象的动作，这个动作可以发生在编译时期（比如Aspejctj），或者运行时，比如Spring AOP Advice在Spring AOP中对应API上面说到的Aspject中的注解，其中有五个是用来定义Advice的，表示代理逻辑，以及执行时机： @Before @AfterReturning @AfterThrowing @After @Around 我们前面也提到过，Spring自己也提供了类似的执行实际的实现类： 接口MethodBeforeAdvice，继承了接口BeforeAdvice 接口AfterReturningAdvice 接口ThrowsAdvice 接口AfterAdvice 接口MethodInterceptor Spring会把五个注解解析为对应的Advice类： @Before：AspectJMethodBeforeAdvice，实际上就是一个MethodBeforeAdvice @AfterReturning：AspectJAfterReturningAdvice，实际上就是一个AfterReturningAdvice @AfterThrowing：AspectJAfterThrowingAdvice，实际上就是一个MethodInterceptor @After：AspectJAfterAdvice，实际上就是一个MethodInterceptor @Around：AspectJAroundAdvice，实际上就是一个MethodInterceptor TargetSource的使用在我们日常的AOP中，被代理对象就是Bean对象，是由BeanFactory给我们创建出来的，但是Spring AOP中提供了TargetSource机制，可以让我们用来自定义逻辑来创建被代理对象。​ 比如之前所提到的**@Lazy注解，当加在属性上时，会产生一个代理对象赋值给这个属性**，产生代理对象的代码为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455protected Object buildLazyResolutionProxy(final DependencyDescriptor descriptor, final @Nullable String beanName) &#123; BeanFactory beanFactory = getBeanFactory(); Assert.state(beanFactory instanceof DefaultListableBeanFactory, &quot;BeanFactory needs to be a DefaultListableBeanFactory&quot;); final DefaultListableBeanFactory dlbf = (DefaultListableBeanFactory) beanFactory; TargetSource ts = new TargetSource() &#123; @Override public Class&lt;?&gt; getTargetClass() &#123; return descriptor.getDependencyType(); &#125; @Override public boolean isStatic() &#123; return false; &#125; @Override public Object getTarget() &#123; Set&lt;String&gt; autowiredBeanNames = (beanName != null ? new LinkedHashSet&lt;&gt;(1) : null); Object target = dlbf.doResolveDependency(descriptor, beanName, autowiredBeanNames, null); if (target == null) &#123; Class&lt;?&gt; type = getTargetClass(); if (Map.class == type) &#123; return Collections.emptyMap(); &#125; else if (List.class == type) &#123; return Collections.emptyList(); &#125; else if (Set.class == type || Collection.class == type) &#123; return Collections.emptySet(); &#125; throw new NoSuchBeanDefinitionException(descriptor.getResolvableType(), &quot;Optional dependency not present for lazy injection point&quot;); &#125; if (autowiredBeanNames != null) &#123; for (String autowiredBeanName : autowiredBeanNames) &#123; if (dlbf.containsBean(autowiredBeanName)) &#123; dlbf.registerDependentBean(autowiredBeanName, beanName); &#125; &#125; &#125; return target; &#125; @Override public void releaseTarget(Object target) &#123; &#125; &#125;; ProxyFactory pf = new ProxyFactory(); pf.setTargetSource(ts); Class&lt;?&gt; dependencyType = descriptor.getDependencyType(); if (dependencyType.isInterface()) &#123; pf.addInterface(dependencyType); &#125; return pf.getProxy(dlbf.getBeanClassLoader()); &#125; 这段代码就利用了ProxyFactory来生成代理对象，以及使用了TargetSource，以达到代理对象在执行某个方法时，调用TargetSource的getTarget()方法实时得到一个被代理对象。 ProxyFactory选择cglib或jdk动态代理原理ProxyFactory在生成代理对象之前需要决定到底是使用JDK动态代理还是CGLIB技术： 1234567891011121314151617181920// config就是ProxyFactory对象// optimize为true,或proxyTargetClass为true,或用户没有给ProxyFactory对象添加interfaceif (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; // targetClass是接口，直接使用Jdk动态代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; // 使用Cglib return new ObjenesisCglibAopProxy(config);&#125;else &#123; // 使用Jdk动态代理 return new JdkDynamicAopProxy(config);&#125; 代理对象创建过程JdkDynamicAopProxy 在构造JdkDynamicAopProxy对象时，会先拿到被代理对象自己所实现的接口，并且额外的增加SpringProxy、Advised、DecoratingProxy三个接口，组合成一个Class[]，并赋值给proxiedInterfaces属性 并且检查这些接口中是否定义了equals()、hashcode()方法 执行Proxy.newProxyInstance(classLoader, this.proxiedInterfaces, this)，得到代理对象，JdkDynamicAopProxy作为InvocationHandler，代理对象在执行某个方法时，会进入到JdkDynamicAopProxy的**invoke()**方法中 ObjenesisCglibAopProxy 创建Enhancer对象 设置Enhancer的superClass为通过ProxyFactory.setTarget()所设置的对象的类 设置Enhancer的interfaces为通过ProxyFactory.addInterface()所添加的接口，以及SpringProxy、Advised、DecoratingProxy接口 设置Enhancer的Callbacks为DynamicAdvisedInterceptor 最后创建一个代理对象，代理对象在执行某个方法时，会进入到DynamicAdvisedInterceptor的intercept()方法中 代理对象执行过程 在使用ProxyFactory创建代理对象之前，需要往ProxyFactory先添加Advisor 代理对象在执行某个方法时，会把ProxyFactory中的Advisor拿出来和当前正在执行的方法进行匹配筛选 把和方法所匹配的Advisor适配成MethodInterceptor 把和当前方法匹配的MethodInterceptor链，以及被代理对象、代理对象、代理类、当前Method对象、方法参数封装为MethodInvocation对象 调用MethodInvocation的proceed()方法，开始执行各个MethodInterceptor以及被代理对象的对应方法 按顺序调用每个MethodInterceptor的invoke()方法，并且会把MethodInvocation对象传入invoke()方法 直到执行完最后一个MethodInterceptor了，就会调用invokeJoinpoint()方法，从而执行被代理对象的当前方法 各注解对应的MethodInterceptor @Before 对应的是AspectJMethodBeforeAdvice，在进行动态代理时会把AspectJMethodBeforeAdvice转成 MethodBeforeAdviceInterceptor 先执行advice对应的方法 再执行MethodInvocation的proceed()，会执行下一个Interceptor，如果没有下一个Interceptor了，会执行target对应的方法 @After 对应的是AspectJAfterAdvice，直接实现了 MethodInterceptor 先执行MethodInvocation的proceed()，会执行下一个Interceptor，如果没有下一个Interceptor了，会执行target对应的方法 再执行advice对应的方法 @Around 对应的是AspectJAroundAdvice，直接实现了 MethodInterceptor 直接执行advice对应的方法，由@Around自己决定要不要继续往后面调用 @AfterThrowing 对应的是AspectJAfterThrowingAdvice，直接实现了 MethodInterceptor 先执行MethodInvocation的proceed()，会执行下一个Interceptor，如果没有下一个Interceptor了，会执行target对应的方法 如果上面抛了Throwable，那么则会执行advice对应的方法 @AfterReturning 对应的是AspectJAfterReturningAdvice，在进行动态代理时会把AspectJAfterReturningAdvice转成 AfterReturningAdviceInterceptor 先执行MethodInvocation的proceed()，会执行下一个Interceptor，如果没有下一个Interceptor了，会执行target对应的方法 执行上面的方法后得到最终的方法的返回值 再执行Advice对应的方法 AbstractAdvisorAutoProxyCreatorDefaultAdvisorAutoProxyCreator的父类是AbstractAdvisorAutoProxyCreator。 AbstractAdvisorAutoProxyCreator非常强大以及重要，只要Spring容器中存在这个类型的Bean，就相当于开启了AOP，AbstractAdvisorAutoProxyCreator实际上就是一个BeanPostProcessor，所以在创建某个Bean时，就会进入到它对应的生命周期方法中，比如：在某个Bean初始化之后，会调用wrapIfNecessary()方法进行AOP，底层逻辑是，AbstractAdvisorAutoProxyCreator会找到所有的Advisor，然后判断当前这个Bean是否存在某个Advisor与之匹配（根据Pointcut），如果匹配就表示当前这个Bean有对应的切面逻辑，需要进行AOP，需要产生一个代理对象。 @EnableAspectJAutoProxy这个注解主要就是往Spring容器中添加了一个AnnotationAwareAspectJAutoProxyCreator类型的Bean。AspectJAwareAdvisorAutoProxyCreator继承了AbstractAdvisorAutoProxyCreator，重写了findCandidateAdvisors()方法，AbstractAdvisorAutoProxyCreator只能找到所有Advisor类型的Bean对象，但是AspectJAwareAdvisorAutoProxyCreator除开可以找到所有Advisor类型的Bean对象，还能把@Aspect注解所标注的Bean中的@Before等注解及方法进行解析，并生成对应的Advisor对象。​ 所以，我们可以理解@EnableAspectJAutoProxy，其实就是像Spring容器中添加了一个AbstractAdvisorAutoProxyCreator类型的Bean，从而开启了AOP，并且还会解析@Before等注解生成Advisor。 第八章 事务增强已有类的组合 @EnableTransactionManagement工作原理开启Spring事务本质上就是增加了一个Advisor，但我们使用@EnableTransactionManagement注解来开启Spring事务是，该注解代理的功能就是向Spring容器中添加了两个Bean： AutoProxyRegistrar ProxyTransactionManagementConfiguration AutoProxyRegistrar主要的作用是向Spring容器中注册了一个InfrastructureAdvisorAutoProxyCreator的Bean。而InfrastructureAdvisorAutoProxyCreator继承了AbstractAdvisorAutoProxyCreator，所以这个类的主要作用就是开启自动代理的作用，也就是一个BeanPostProcessor，会在初始化后步骤中去寻找Advisor类型的Bean，并判断当前某个Bean是否有匹配的Advisor，是否需要利用动态代理产生一个代理对象。​ ProxyTransactionManagementConfiguration是一个配置类，它又定义了另外三个bean： BeanFactoryTransactionAttributeSourceAdvisor：一个Advisor AnnotationTransactionAttributeSource：相当于BeanFactoryTransactionAttributeSourceAdvisor中的Pointcut TransactionInterceptor：相当于BeanFactoryTransactionAttributeSourceAdvisor中的Advice AnnotationTransactionAttributeSource就是用来判断某个类上是否存在@Transactional注解，或者判断某个方法上是否存在@Transactional注解的。​ TransactionInterceptor就是代理逻辑，当某个类中存在@Transactional注解时，到时就产生一个代理对象作为Bean，代理对象在执行某个方法时，最终就会进入到TransactionInterceptor的invoke()方法。 Spring事务基本执行原理一个Bean在执行Bean的创建生命周期时，会经过InfrastructureAdvisorAutoProxyCreator的初始化后的方法，会判断当前当前Bean对象是否和BeanFactoryTransactionAttributeSourceAdvisor匹配，匹配逻辑为判断该Bean的类上是否存在@Transactional注解，或者类中的某个方法上是否存在@Transactional注解，如果存在则表示该Bean需要进行动态代理产生一个代理对象作为Bean对象。​ 该代理对象在执行某个方法时，会再次判断当前执行的方法是否和BeanFactoryTransactionAttributeSourceAdvisor匹配，如果匹配则执行该Advisor中的TransactionInterceptor的invoke()方法，执行基本流程为： 利用所配置的PlatformTransactionManager事务管理器新建一个数据库连接 修改数据库连接的autocommit为false 执行MethodInvocation.proceed()方法，简单理解就是执行业务方法，其中就会执行sql 如果没有抛异常，则提交 如果抛了异常，则回滚 Spring事务详细执行流程Spring事务执行流程图：https://www.processon.com/view/link/5fab6edf1e0853569633cc06 Spring事务传播机制在开发过程中，经常会出现一个方法调用另外一个方法，那么这里就涉及到了多种场景，比如a()调用b()： a()和b()方法中的所有sql需要在同一个事务中吗？ a()和b()方法需要单独的事务吗？ a()需要在事务中执行，b()还需要在事务中执行吗？ 等等情况… 所以，这就要求Spring事务能支持上面各种场景，这就是Spring事务传播机制的由来。那Spring事务传播机制是如何实现的呢?​ 先来看上述几种场景中的一种情况，a()在一个事务中执行，调用b()方法时需要新开一个事务执行：​ 首先，代理对象执行a()方法前，先利用事务管理器新建一个数据库连接a 将数据库连接a的autocommit改为false 把数据库连接a设置到ThreadLocal中 执行a()方法中的sql 执行a()方法过程中，调用了b()方法（注意用代理对象调用b()方法） 代理对象执行b()方法前，判断出来了当前线程中已经存在一个数据库连接a了，表示当前线程其实已经拥有一个Spring事务了，则进行挂起 挂起就是把ThreadLocal中的数据库连接a从ThreadLocal中移除，并放入一个挂起资源对象中 挂起完成后，再次利用事务管理器新建一个数据库连接b 将数据库连接b的autocommit改为false 把数据库连接b设置到ThreadLocal中 执行b()方法中的sql b()方法正常执行完，则从ThreadLocal中拿到数据库连接b进行提交 提交之后会恢复所挂起的数据库连接a，这里的恢复，其实只是把在挂起资源对象中所保存的数据库连接a再次设置到ThreadLocal中 a()方法正常执行完，则从ThreadLocal中拿到数据库连接a进行提交 这个过程中最为核心的是：在执行某个方法时，判断当前是否已经存在一个事务，就是判断当前线程的ThreadLocal中是否存在一个数据库连接对象，如果存在则表示已经存在一个事务了。 Spring事务传播机制分类其中，以非事务方式运行，表示以非Spring事务运行，表示在执行这个方法时，Spring事务管理器不会去建立数据库连接，执行sql时，由Mybatis或JdbcTemplate自己来建立数据库连接来执行sql。 案例分析情况112345678910111213141516@Componentpublic class UserService &#123; @Autowired private UserService userService; @Transactional public void test() &#123; // test方法中的sql userService.a(); &#125; @Transactional public void a() &#123; // a方法中的sql &#125;&#125; 默认情况下传播机制为REQUIRED，表示当前如果没有事务则新建一个事务，如果有事务则在当前事务中执行。​ 所以上面这种情况的执行流程如下： 新建一个数据库连接conn 设置conn的autocommit为false 执行test方法中的sql 执行a方法中的sql 执行conn的commit()方法进行提交 情况2假如是这种情况 1234567891011121314151617@Componentpublic class UserService &#123; @Autowired private UserService userService; @Transactional public void test() &#123; // test方法中的sql userService.a(); int result = 100/0; &#125; @Transactional public void a() &#123; // a方法中的sql &#125;&#125; 所以上面这种情况的执行流程如下： 新建一个数据库连接conn 设置conn的autocommit为false 执行test方法中的sql 执行a方法中的sql 抛出异常 执行conn的rollback()方法进行回滚，所以两个方法中的sql都会回滚掉 情况3假如是这种情况： 1234567891011121314151617@Componentpublic class UserService &#123; @Autowired private UserService userService; @Transactional public void test() &#123; // test方法中的sql userService.a(); &#125; @Transactional public void a() &#123; // a方法中的sql int result = 100/0; &#125;&#125; 所以上面这种情况的执行流程如下： 新建一个数据库连接conn 设置conn的autocommit为false 执行test方法中的sql 执行a方法中的sql 抛出异常 执行conn的rollback()方法进行回滚，所以两个方法中的sql都会回滚掉 情况4如果是这种情况： 1234567891011121314151617@Componentpublic class UserService &#123; @Autowired private UserService userService; @Transactional public void test() &#123; // test方法中的sql userService.a(); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void a() &#123; // a方法中的sql int result = 100/0; &#125;&#125; 所以上面这种情况的执行流程如下： 新建一个数据库连接conn 设置conn的autocommit为false 执行test方法中的sql 又新建一个数据库连接conn2 执行a方法中的sql 抛出异常 执行conn2的rollback()方法进行回滚 继续抛异常，对于test()方法而言，它会接收到一个异常，然后抛出 执行conn的rollback()方法进行回滚，最终还是两个方法中的sql都回滚了 Spring事务强制回滚正常情况下，a()调用b()方法时，如果b()方法抛了异常，但是在a()方法捕获了，那么a()的事务还是会正常提交的，但是有的时候，我们捕获异常可能仅仅只是不把异常信息返回给客户端，而是为了返回一些更友好的错误信息，而这个时候，我们还是希望事务能回滚的，那这个时候就得告诉Spring把当前事务回滚掉，做法就是： 12345678910111213141516@Transactionalpublic void test()&#123; // 执行sql try &#123; b(); &#125; catch (Exception e) &#123; // 构造友好的错误信息返回 TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); &#125; &#125;public void b() throws Exception &#123; throw new Exception();&#125; TransactionSynchronizationSpring事务有可能会提交，回滚、挂起、恢复，所以Spring事务提供了一种机制，可以让程序员来监听当前Spring事务所处于的状态。​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Componentpublic class UserService &#123; @Autowired private JdbcTemplate jdbcTemplate; @Autowired private UserService userService; @Transactional public void test()&#123; TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() &#123; @Override public void suspend() &#123; System.out.println(&quot;test被挂起了&quot;); &#125; @Override public void resume() &#123; System.out.println(&quot;test被恢复了&quot;); &#125; @Override public void beforeCommit(boolean readOnly) &#123; System.out.println(&quot;test准备要提交了&quot;); &#125; @Override public void beforeCompletion() &#123; System.out.println(&quot;test准备要提交或回滚了&quot;); &#125; @Override public void afterCommit() &#123; System.out.println(&quot;test提交成功了&quot;); &#125; @Override public void afterCompletion(int status) &#123; System.out.println(&quot;test提交或回滚成功了&quot;); &#125; &#125;); jdbcTemplate.execute(&quot;insert into t1 values(1,1,1,1,&#x27;1&#x27;)&quot;); System.out.println(&quot;test&quot;); userService.a(); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void a()&#123; TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() &#123; @Override public void suspend() &#123; System.out.println(&quot;a被挂起了&quot;); &#125; @Override public void resume() &#123; System.out.println(&quot;a被恢复了&quot;); &#125; @Override public void beforeCommit(boolean readOnly) &#123; System.out.println(&quot;a准备要提交了&quot;); &#125; @Override public void beforeCompletion() &#123; System.out.println(&quot;a准备要提交或回滚了&quot;); &#125; @Override public void afterCommit() &#123; System.out.println(&quot;a提交成功了&quot;); &#125; @Override public void afterCompletion(int status) &#123; System.out.println(&quot;a提交或回滚成功了&quot;); &#125; &#125;); jdbcTemplate.execute(&quot;insert into t1 values(2,2,2,2,&#x27;2&#x27;)&quot;); System.out.println(&quot;a&quot;); &#125;&#125; 第九章 Spring MVC请求流程源码Spring集成Sring MVC (无SpringBoot) 1234567public class MyApplicationInitializer implements WebApplicationInitializer &#123; @Override public void onStartup(ServletContext servletContext) throws ServletException &#123; //注册DispatcherServlet到容器里 &#125;&#125;// todo 启动Tomcat Servlet规范定义接口,tomcat通过SPI机制加载 实现是 @HandlerTypes(感兴趣的类) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; /** * Delegate the &#123;@code ServletContext&#125; to any &#123;@link WebApplicationInitializer&#125; * implementations present on the application classpath. * &lt;p&gt;Because this class declares @&#123;@code HandlesTypes(WebApplicationInitializer.class)&#125;, * Servlet 3.0+ containers will automatically scan the classpath for implementations * of Spring&#x27;s &#123;@code WebApplicationInitializer&#125; interface and provide the set of all * such types to the &#123;@code webAppInitializerClasses&#125; parameter of this method. * &lt;p&gt;If no &#123;@code WebApplicationInitializer&#125; implementations are found on the classpath, * this method is effectively a no-op. An INFO-level log message will be issued notifying * the user that the &#123;@code ServletContainerInitializer&#125; has indeed been invoked but that * no &#123;@code WebApplicationInitializer&#125; implementations were found. * &lt;p&gt;Assuming that one or more &#123;@code WebApplicationInitializer&#125; types are detected, * they will be instantiated (and &lt;em&gt;sorted&lt;/em&gt; if the @&#123;@link * org.springframework.core.annotation.Order @Order&#125; annotation is present or * the &#123;@link org.springframework.core.Ordered Ordered&#125; interface has been * implemented). Then the &#123;@link WebApplicationInitializer#onStartup(ServletContext)&#125; * method will be invoked on each instance, delegating the &#123;@code ServletContext&#125; such * that each instance may register and configure servlets such as Spring&#x27;s * &#123;@code DispatcherServlet&#125;, listeners such as Spring&#x27;s &#123;@code ContextLoaderListener&#125;, * or any other Servlet API componentry such as filters. * @param webAppInitializerClasses all implementations of * &#123;@link WebApplicationInitializer&#125; found on the application classpath * @param servletContext the servlet context to be initialized * @see WebApplicationInitializer#onStartup(ServletContext) * @see AnnotationAwareOrderComparator */ @Override public void onStartup(@Nullable Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = Collections.emptyList();// 这里面会有我们自己写的myWebApplicationInitializer if (webAppInitializerClasses != null) &#123; initializers = new ArrayList&lt;&gt;(webAppInitializerClasses.size()); for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; // Be defensive: Some servlet containers provide us with invalid classes, // no matter what @HandlesTypes says... if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123; initializers.add((WebApplicationInitializer) ReflectionUtils.accessibleConstructor(waiClass).newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(&quot;Failed to instantiate WebApplicationInitializer class&quot;, ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(&quot;No Spring WebApplicationInitializer types detected on classpath&quot;); return; &#125; servletContext.log(initializers.size() + &quot; Spring WebApplicationInitializers detected on classpath&quot;); AnnotationAwareOrderComparator.sort(initializers); for (WebApplicationInitializer initializer : initializers) &#123; initializer.onStartup(servletContext); &#125; &#125;&#125; SpringMVC —请求源码流程 有道云链接：http://note.youdao.com/noteshare?id=ec3ca523300ad31d7f6f673b9e92bbeb&amp;sub=1D1BF1D55D0148879F53878CB24F8214 ​ SpringMVC —请求源码流程 ​ 前言 ​ 从Servlet到SpringMVC ​ 传统Servlet： ​ SpringMVC ​ SpringMVC的具体执行流程： ​ HandlerMapping 前言 Spring官网的MVC模块介绍： Spring Web MVC is the original web framework built on the Servlet API and has been included in the Spring Framework from the very beginning. The formal name, “Spring Web MVC,” comes from the name of its source module (spring-webmvc), but it is more commonly known as “Spring MVC”. Spring Web MVC是基于Servlet API构建的原始Web框架，从一开始就已包含在Spring框架中。正式名称“ Spring Web MVC”来自其源模块的名称（spring-webmvc），但它通常被称为“ Spring MVC”。 从Servlet到SpringMVC 最典型的MVC就是JSP + servlet + javabean的模式。 传统Servlet： ​ 弊端： 1.xml下配置servlet的映射非常麻烦 开发效率低 2.必须要继承父类、重写方法 侵入性强 2.如果想在一个Servlet中处理同一业务模块的的功能分发给不同方法进行处理非常麻烦 3.参数解析麻烦:单个参数（转换类型）—&gt;pojo对象 Json文本—&gt;pojo对象 4.**数据响应麻烦:**pojo对象—&gt;json … Content-type 5.跳转页面麻烦, 对path的控制、 如果使用其他模板也很麻烦 、设置编码麻烦…等等… 所以SpringMVC 就是在Servlet的基础上进行了封装，帮我把这些麻烦事都给我们做了。 Web框架的升级是一个不断偷懒的过程 从最开始的Servlet到现在的SpringMVC、SpringBoot等等 SpringMVC 基于xml的实现方式： 1.给Servlet容器配置一个DispatcherServlet（web.xml ) 2.添加SpringMVC的配置信息 继承类&#x2F;实现接口 方式： ​ implements HttpRequestHandler 不同的HandlerMapping ​ simpleController 注解方式： 配置控制器@Controller和处理方法的映射—@RequstMapping 即可 其实SpringMVC请求原理很简单：说白了就是用一个DispatcherServlet 封装了一个Servlet的调度中心， 由调度中心帮我们调用我们的处理方法： 在这个过程中调度中心委托给各个组件执行具体工作 ，比如帮我们映射方法请求、帮我解析参数、调用处理方法、响应数据和页面 等 这就相当于你在家自己做饭和去饭店吃饭的区别了， 在家你买菜、洗菜、蒸饭、炒菜、洗碗都得自己来. 饭店都给你做好了， 你只要分服务员说你吃什么、就能得到响应. 殊不知呢， 你只是说了吃什么（请求）， 后厨（DispatcherServlet）就有配菜员你给找到菜单-对应的食材（映射） 、切菜员切菜（解析参数）、 厨师给你炒菜（调用处理方法）、装盘（处理返回值)、 抄完给你端出来（响应） SpringMVC的具体执行流程： Spring MVC 是围绕前端控制器模式设计的，其中：中央 Servlet DispatcherServlet 为请求处理流程提供统一调度，实际工作则交给可配置组件执行。这个模型是灵活的且开放的，我们可以通过自己去定制这些组件从而进行定制自己的工作流。 ​ DispatcherServlet： 前端调度器 ， 负责将请求拦截下来分发到各控制器方法中 HandlerMapping: 负责根据请求的URL和配置@RequestMapping映射去匹配， 匹配到会返回Handler（具体控制器的方法） HandlerAdaper: 负责调用Handler-具体的方法- 返回视图的名字 Handler将它封装到ModelAndView(封装视图名，request域的数据） ViewReslover: 根据ModelAndView里面的视图名地址去找到具体的jsp封装在View对象中 View：进行视图渲染（将jsp转换成html内容 –这是Servlet容器的事情了） 最终response到的客户端 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求调用处理器映射器HandlerMapping。 处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter,执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 执行处理器Handler(Controller，也叫页面控制器)。 Handler执行完成返回ModelAndView HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 DispatcherServlet响应用户。 整个调用过程其实都在doDispatch中体现了： 用户发送请求至前端控制器DispatcherServlet 由于它是个Servlet会先进入service方法——&gt;doGet&#x2F;doPost——&gt;processRequestdoService——&gt;doDispatch ↓ 这个doDispatch非常重要–体现了整个请求流程 ​ protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { try { try { &#x2F;&#x2F; 文件上传相关 processedRequest &#x3D; checkMultipart(request); multipartRequestParsed &#x3D; (processedRequest !&#x3D; request); &#x2F;&#x2F; DispatcherServlet收到请求调用处理器映射器HandlerMapping。 &#x2F;&#x2F; 处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 mappedHandler &#x3D; getHandler(processedRequest); if (mappedHandler &#x3D;&#x3D; null) { noHandlerFound(processedRequest, response); return; } 4.DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter, HandlerAdapter ha &#x3D; getHandlerAdapter(mappedHandler.getHandler()); &#x2F;&#x2F; Process last-modified header, if supported by the handler. HTTP缓存相关 String method &#x3D; request.getMethod(); boolean isGet &#x3D; HttpMethod.GET.matches(method); if (isGet || HttpMethod.HEAD.matches(method)) { long lastModified &#x3D; ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) { return; } } &#x2F;&#x2F; 前置拦截器 if (!mappedHandler.applyPreHandle(processedRequest, response)) { &#x2F;&#x2F; 返回false就不进行后续处理了 return; } &#x2F;&#x2F; 执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 &#x2F;&#x2F; 执行处理器Handler(Controller，也叫页面控制器)。 &#x2F;&#x2F; Handler执行完成返回ModelAndView &#x2F;&#x2F; HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet mv &#x3D; ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) { return; } &#x2F;&#x2F; 如果没有视图，给你设置默认视图 json忽略 applyDefaultViewName(processedRequest, mv); &#x2F;&#x2F;后置拦截器 mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Exception ex) { dispatchException &#x3D; ex; } catch (Throwable err) { &#x2F;&#x2F; As of 4.3, we’re processing Errors thrown from handler methods as well, &#x2F;&#x2F; making them available for @ExceptionHandler methods and other scenarios. dispatchException &#x3D; new NestedServletException(“Handler dispatch failed”, err); } &#x2F;&#x2F; DispatcherServlet将ModelAndView传给ViewReslover视图解析器 &#x2F;&#x2F; ViewReslover解析后返回具体View &#x2F;&#x2F; DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 &#x2F;&#x2F; DispatcherServlet响应用户。 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); } catch (Exception ex) { triggerAfterCompletion(processedRequest, response, mappedHandler, ex); } catch (Throwable err) { triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(“Handler processing failed”, err)); } finally { if (asyncManager.isConcurrentHandlingStarted()) { &#x2F;&#x2F; Instead of postHandle and afterCompletion if (mappedHandler !&#x3D; null) { mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); } } else { &#x2F;&#x2F; Clean up any resources used by a multipart request. if (multipartRequestParsed) { cleanupMultipart(processedRequest); } } } 详细过程我们课程中分析…. HandlerMapping 在整个过程中，涉及到非常多的组件，每个组件解析各个环节，其中HandlerMapping最为重要它是用来映射请求的，我们就着重介绍下HandlerMapping的解析过程和请求映射过程： 附上流程图： https://www.processon.com/view/link/615ea79e1efad4070b2d6707 ​ 第十章 Spring MVC父子容器1、Spring整合SpringMVC 特性： 说到Spring整合SpringMVC唯一的体现就是父子容器： 通常我们会设置父容器（Spring）管理Service、Dao层的Bean, 子容器(SpringMVC)管理Controller的Bean . 子容器可以访问父容器的Bean, 父容器无法访问子容器的Bean。 实现： 也就是零配置（零xml）的放式来说明SpringMVC的原理！！ 此方式作为我们本文重点介绍，也是很多人缺失的一种方式， 其实早在Spring3+就已经提供， 只不过我们直到SpringBoot才使用该方式进行自动配置， 这也是很多人从xml调到SpringBoot不适应的原因， 因为你缺失了这个版本。 所以我们以这种方式作为源码切入点既可以理解到XML的方式又能兼顾到SpringBoot的方式 。 3、实现基于SPI规范的SpringMVC TulingStarterInitializer 此类继承AbstractAnnotationConfigDispatcherServletInitializer 这是个啥？ 待会我们讲原理来介绍 getRootConfigClasses 提供父容器的配置类 getServletConfigClasses 提供子容器的配置类 getServletMappings 设置DispatcherServlet的映射 ​ public class TulingStarterInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { &#x2F;** * 方法实现说明:IOC 父容器的启动类 * @author:xsls * @date:2019&#x2F;7&#x2F;31 22:12 &#x2F; @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[]{RootConfig.class}; } &#x2F;* * 方法实现说明 IOC子容器配置 web容器配置 * @author:xsls * @date:2019&#x2F;7&#x2F;31 22:12 &#x2F; @Override protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{WebAppConfig.class}; } &#x2F;* * 方法实现说明 * @author:xsls * @return: 我们前端控制器DispatcherServlet的拦截路径 * @exception: * @date:2019&#x2F;7&#x2F;31 22:16 *&#x2F; @Override protected String[] getServletMappings() { return new String[]{“&#x2F;“}; RootConfig 父容器的配置类 &#x3D;以前的spring.xml 扫描的包排除掉@Controller ​ @Configuration @ComponentScan(basePackages &#x3D; “com.tuling”,excludeFilters &#x3D; { @ComponentScan.Filter(type &#x3D; FilterType.ANNOTATION,value&#x3D;{RestController.class,Controller.class}), @ComponentScan.Filter(type &#x3D; ASSIGNABLE_TYPE,value &#x3D;WebAppConfig.class ), }) public class RootConfig { WebAppConfig 子容器的配置类 &#x3D;以前的spring-mvc.xml 扫描的包：包含掉@Controller ​ @Configuration @ComponentScan(basePackages &#x3D; {“com.tuling”},includeFilters &#x3D; { @ComponentScan.Filter(type &#x3D; FilterType.ANNOTATION,value &#x3D; {RestController.class, Controller.class}) },useDefaultFilters &#x3D;false) @EnableWebMvc &#x2F;&#x2F; ≈mvc:annotation-driven/ public class WebAppConfig implements WebMvcConfigurer{ &#x2F;** * 配置拦截器 * @return &#x2F; @Bean public TulingInterceptor tulingInterceptor() { return new TulingInterceptor(); } &#x2F;* * 文件上传下载的组件 * @return &#x2F; @Bean public MultipartResolver multipartResolver() { CommonsMultipartResolver multipartResolver &#x3D; new CommonsMultipartResolver(); multipartResolver.setDefaultEncoding(“UTF-8”); multipartResolver.setMaxUploadSize(1024102410); return multipartResolver; } &#x2F;* * 注册处理国际化资源的组件 * @return &#x2F; &#x2F; @Bean public AcceptHeaderLocaleResolver localeResolver() { AcceptHeaderLocaleResolver acceptHeaderLocaleResolver &#x3D; new AcceptHeaderLocaleResolver(); return acceptHeaderLocaleResolver; }&#x2F; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(tulingInterceptor()).addPathPatterns(“&#x2F;“); } &#x2F;** * 方法实现说明:配置试图解析器 * @author:xsls * @exception: * @date:2019&#x2F;8&#x2F;6 16:23 *&#x2F; @Bean public InternalResourceViewResolver internalResourceViewResolver() { InternalResourceViewResolver viewResolver &#x3D; new InternalResourceViewResolver(); viewResolver.setSuffix(“.jsp”); viewResolver.setPrefix(“&#x2F;WEB-INF&#x2F;jsp&#x2F;“); return viewResolver; } @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { converters.add(new MappingJackson2HttpMessageConverter()); } 自己去添加个Controller进行测试 OK， 现在可以访问你的SpringMVC了 4、SPI的方式****SpringMVC启动原理 接着我们来看看SPI方式的原理是什么： SpringMVC 大致可以分为 启动 和请求 2大部分， 所以我们本文先研究启动部分 流程图： ​ 源码流程 外置Tomcat启动的时候通过SPI 找到我们应用中的&#x2F;META-INF&#x2F;service&#x2F;javax.servlet.ServletContainerInitializer ​ 调用SpringServletContainerInitializer.onStartUp() ​ 调用onStartUp()前会先找到@HandlesTypes(WebApplicationInitializer.class) 所有实现了WebApplicationInitializer的类，传入到OnStartup的webAppInitializerClasses参数中，并传入Servlet上下文对象。 重点关注这组类：他们组成了父子容器 ​ 找到所有WebApplicationInitializer的实现类后， 不是接口、不是抽象则通过反射进行实例化（所以，你会发现内部实现类都是抽象的，你想让其起作用我们必须添加一个自定义实现类，在下文提供我的自定义实现类） 调用所有上一步实例化后的对象的onStartup方法 ​ ​ \\1. 首先来到AbstractDispatcherServletInitializer#onStartup再执行super.onStartup(servletContext); ​ @Override public void onStartup(ServletContext servletContext) throws ServletException { &#x2F;&#x2F;实例化我们的spring root上下文 super.onStartup(servletContext); &#x2F;&#x2F;注册我们的DispatcherServlet 创建我们spring web 上下文对象 registerDispatcherServlet(servletContext); 创建父容器——ContextLoaderListener 2.父类AbstractContextLoaderInitializer#onStartup执行registerContextLoaderListener(servletContext); createRootApplicationContext()该方法中会创建父容器 该方法是抽象方法，实现类是AbstractAnnotationConfigDispatcherServletInitializer 调用getRootConfigClasses();方法获取父容器配置类（此抽象方法在我们自定义的子类中实现提供我们自定义的映射路径 ） 创建父容器，注册配置类 ​ 会创建ContextLoaderListener并通过ServletContext注册 ​ 看完大家是不是感觉跟我们XML的配置ContextLoaderListener对上了： ​ 创建子容器——DispatcherServlet 3.回到AbstractDispatcherServletInitializer#onStartup再执行registerDispatcherServlet(servletContext); ​ registerDispatcherServlet方法说明： 调用createServletApplicationContext创建子容器 该方法是抽象方法，实现类是AbstractAnnotationConfigDispatcherServletInitializer 创建子容器（下图很明显不多介绍） 调用抽象方法：getServletConfigClasses();获得配置类（此抽象方法在我们自定义的子类中实现提供我们自定义的配置类 ） 配置类除了可以通过ApplicationContext()构造函数的方式传入 ， 也可以通过这种方式动态添加，不知道了吧~ ​ 调用createDispatcherServlet(servletAppContext);创建DispatcherServlet 设置启动时加载：registration.setLoadOnStartup(1); 调用抽象方法设置映射路径：getServletMappings()（此抽象方法在我们自定义的子类中实现提供我们自定义的映射路径 ） 看完大家是不是感觉跟我们XML的配置DispatcherServlet对上了 ​ 4. 初始化ContextLoaderListener ​ ContextLoaderListener加载过程比较简单： 外置tomcat会帮我们调用ContextLoaderListener#contextInitialized 进行初始化 xml的方式下会判断容器为空时创建父容器 在里面会调用父容器的refresh方法加载 将父容器存入到Servlet域中供子容器使用 ​ 5. 初始化DispatcherServlet ​ 可以看到流程比ContextLoaderListener流程更多 外置tomcat会帮我们调用DispatcherServlet#init() 进行初始化—&gt;重点关注：initWebApplicationContext方法 getWebApplicationContext(getServletContext())获得父容器（从之前的Servlet域中拿到） cwac.setParent(rootContext);给子容器设置父容器 调用configureAndRefreshWebApplicationContext(cwac); ​ 注册一个监听器（该监听会初始化springmvc所需信息） ContextRefreshedEvent可以看到该监听器监听的是容器refreshed事件， 会在finishRefresh中发布 刷新容器 ​ 当执行refresh 即加载ioc容器 完了会调用finishRefresh(): publishEvent(new ContextRefreshedEvent(this));发布ContextRefreshedEvent事件 触发上面的ContextRefreshListener监听器： —-&gt;FrameworkServlet.this.onApplicationEvent(event); ——–&gt;onRefresh(event.getApplicationContext()); ————–&gt;initStrategies(context); ​ protected void initStrategies(ApplicationContext context) { &#x2F;&#x2F;初始化我们web上下文对象的 用于文件上传下载的解析器对象 initMultipartResolver(context); &#x2F;&#x2F;初始化我们web上下文对象用于处理国际化资源的 initLocaleResolver(context); &#x2F;&#x2F;主题解析器对象初始化 initThemeResolver(context); &#x2F;&#x2F;初始化我们的HandlerMapping initHandlerMappings(context); &#x2F;&#x2F;实例化我们的HandlerAdapters initHandlerAdapters(context); &#x2F;&#x2F;实例化我们处理器异常解析器对象 initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); &#x2F;&#x2F;给DispatcherSerlvet的ViewResolvers处理器 initViewResolvers(context); initFlashMapManager(context); 这里面的每一个方法不用太细看， 就是给SpringMVC准备初始化的数据， 为后续SpringMVC处理请求做准备 基本都是从容器中拿到已经配置的Bean（RequestMappingHandlerMapping、RequestMappingHandlerAdapter、HandlerExceptionResolver ）放到dispatcherServlet中做准备: ​ ​ ​ … 但是这些Bean又是从哪来的呢？？ 来来来， 回到我们的WebAppConfig 我们使用的一个@EnableWebMvc 导入了DelegatingWebMvcConfiguration@Import(DelegatingWebMvcConfiguration.class) DelegatingWebMvcConfiguration的父类就配置了这些Bean 而且我告诉你SpringBoot也是用的这种方式， ​ 总结 Tomcat在启动时会通过SPI注册 ContextLoaderListener和DispatcherServlet对象 同时创建父子容器 分别创建在ContextLoaderListener初始化时创建父容器设置配置类 在DispatcherServlet初始化时创建子容器 即2个ApplicationContext实例设置配置类 Tomcat在启动时执行ContextLoaderListener和DispatcherServlet对象的初始化方法， 执行容器refresh进行加载 在子容器加载时 创建SpringMVC所需的Bean和预准备的数据：(通过配置类+@EnableWebMvc配置（DelegatingWebMvcConfiguration）——可实现WebMvcConfigurer进行定制扩展） RequestMappingHandlerMapping，它会处理@RequestMapping 注解 RequestMappingHandlerAdapter，则是处理请求的适配器，确定调用哪个类的哪个方法，并且构造方法参数，返回值。 HandlerExceptionResolver 错误视图解析器 addDefaultHttpMessageConverters 添加默认的消息转换器（解析json、解析xml） 等…. 子容器需要注入父容器的Bean时（比如Controller中需要@Autowired Service的Bean）; 会先从子容器中找，没找到会去父容器中找： 详情见AbstractBeanFactory#doGetBean方法 ​ &#x2F;** * 一般情况下,只有Spring 和SpringMvc整合的时才会有父子容器的概念, * 作用： * 比如我们的Controller中注入Service的时候，发现我们依赖的是一个引用对象，那么他就会调用getBean去把service找出来 * 但是当前所在的容器是web子容器，那么就会在这里的 先去父容器找 *&#x2F; BeanFactory parentBeanFactory &#x3D; getParentBeanFactory(); &#x2F;&#x2F;若存在父工厂,且当前的bean工厂不存在当前的bean定义,那么bean定义是存在于父beanFacotry中 if (parentBeanFactory !&#x3D; null &amp;&amp; !containsBeanDefinition(beanName)) { &#x2F;&#x2F;获取bean的原始名称 String nameToLookup &#x3D; originalBeanName(name); &#x2F;&#x2F;若为 AbstractBeanFactory 类型，委托父类处理 if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args !&#x3D; null) { &#x2F;&#x2F; 委托给构造函数 getBean() 处理 return (T) parentBeanFactory.getBean(nameToLookup, args); } else { &#x2F;&#x2F; 没有 args，委托给标准的 getBean() 处理 return parentBeanFactory.getBean(nameToLookup, requiredType); } 用几道面试题做个总结: Spring和SpringMVC为什么需要父子容器？不要不行吗？ 就实现层面来说不用子父容器也可以完成所需功能（参考：SpringBoot就没用子父容器） 所以父子容器的主要作用应该是早期Spring为了划分框架边界。有点单一职责的味道。service、dao层我们一般使用spring框架来管理、controller层交给springmvc管理 规范整体架构 使 父容器service无法访问子容器controller、子容器controller可以访问父容器 service 方便子容器的切换。如果现在我们想把web层从spring mvc替换成struts，那么只需要将spring-mvc.xml替换成Struts的配置文件struts.xml即可，而spring-core.xml不需要改变。 为了节省重复bean创建 是否可以把所有Bean都通过Spring容器来管理？（Spring的applicationContext.xml中配置全局扫描) 不可以，这样会导致我们请求接口的时候产生404。 如果所有的Bean都交给父容器，SpringMVC在初始化HandlerMethods的时候（initHandlerMethods）无法根据Controller的handler方法注册HandlerMethod，并没有去查找父容器的bean； 也就无法根据请求URI 获取到 HandlerMethod来进行匹配. ​ 是否可以把我们所需的Bean都放入Spring-mvc子容器里面来管理（springmvc的spring-servlet.xml中配置全局扫描）? 可以 ， 因为父容器的体现无非是为了获取子容器不包含的bean, 如果全部包含在子容器完全用不到父容器了， 所以是可以全部放在springmvc子容器来管理的。 虽然可以这么做不过一般应该是不推荐这么去做的，一般人也不会这么干的。如果你的项目里有用到事物、或者aop记得也需要把这部分配置需要放到Spring-mvc子容器的配置文件来，不然一部分内容在子容器和一部分内容在父容器,可能就会导致你的事物或者AOP不生效。 所以如果aop或事物如果不生效也有可能是通过父容器(spring)去增强子容器(Springmvc)，也就无法增强 这也是很多同学会遇到的问题。 第十一章 Mybatis本章着重介绍MyBatis执行Sql的流程，关于在执行过程中缓存、动态SQl生成等细节不在本章中体现 还是以之前的查询作为列子： &#x2F;*** * @Author 徐庶 QQ:1092002729 * @Slogan 致敬大师，致敬未来的你 *&#x2F; public class App { public static void main(String[] args) { String resource &#x3D; “mybatis-config.xml”; Reader reader; try { &#x2F;&#x2F;将XML配置文件构建为Configuration配置类 reader &#x3D; Resources.getResourceAsReader(resource); &#x2F;&#x2F; 通过加载配置文件流构建一个SqlSessionFactory DefaultSqlSessionFactory SqlSessionFactory sqlMapper &#x3D; new SqlSessionFactoryBuilder().build(reader); &#x2F;&#x2F; 数据源 执行器 DefaultSqlSession SqlSession session &#x3D; sqlMapper.openSession(); try { &#x2F;&#x2F; 执行查询 底层执行jdbc &#x2F;&#x2F;User user &#x3D; (User)session.selectOne(“com.tuling.mapper.selectById”, 1); UserMapper mapper &#x3D; session.getMapper(UserMapper.class); System.out.println(mapper.getClass()); User user &#x3D; mapper.selectById(1L); System.out.println(user.getUserName()); } catch (Exception e) { e.printStackTrace(); }finally { session.close(); } } catch (IOException e) { e.printStackTrace(); } } } 之前提到拿到sqlSession之后就能进行各种CRUD操作了，所以我们就从sqlSession.getMapper这个方法开始分析，看下整个Sql的执行流程是怎么样的。 openSession的过程: Copy private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx &#x3D; null; try { final Environment environment &#x3D; configuration.getEnvironment(); final TransactionFactory transactionFactory &#x3D; getTransactionFactoryFromEnvironment(environment); tx &#x3D; transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); &#x2F;&#x2F;获取执行器，这边获得的执行器已经代理拦截器的功能（见下面代码） final Executor executor &#x3D; configuration.newExecutor(tx, execType); &#x2F;&#x2F;根据获取的执行器创建SqlSession return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); &#x2F;&#x2F; may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(“Error opening session. Cause: “ + e, e); } finally { ErrorContext.instance().reset(); } } Copy &#x2F;&#x2F;interceptorChain生成代理类，具体参见Plugin这个类的方法 public Executor newExecutor(Transaction transaction, ExecutorType executorType) { executorType &#x3D; executorType &#x3D;&#x3D; null ? defaultExecutorType : executorType; executorType &#x3D; executorType &#x3D;&#x3D; null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH &#x3D;&#x3D; executorType) { executor &#x3D; new BatchExecutor(this, transaction); } else if (ExecutorType.REUSE &#x3D;&#x3D; executorType) { executor &#x3D; new ReuseExecutor(this, transaction); } else { executor &#x3D; new SimpleExecutor(this, transaction); } if (cacheEnabled) { executor &#x3D; new CachingExecutor(executor); } executor &#x3D; (Executor) interceptorChain.pluginAll(executor); return executor; } Executor分成两大类，一类是CacheExecutor，另一类是普通Executor。 普通Executor又分为三种基本的Executor执行器，SimpleExecutor、ReuseExecutor、BatchExecutor。 SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。 ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。简言之，就是重复使用Statement对象。 BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。 作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。 CacheExecutor其实是封装了普通的Executor，和普通的区别是在查询前先会查询缓存中是否存在结果，如果存在就使用缓存中的结果，如果不存在还是使用普通的Executor进行查询，再将查询出来的结果存入缓存。 ​ 到此为止，我们已经获得了SqlSession，拿到SqlSession就可以执行各种CRUD方法了。 简单总结 拿到SqlSessionFactory对象后，会调用SqlSessionFactory的openSesison方法，这个方法会创建一个Sql执行器（Executor），这个Sql执行器会代理你配置的拦截器方法。 获得上面的Sql执行器后，会创建一个SqlSession（默认使用DefaultSqlSession）,这个SqlSession中也包含了Configration对象，所以通过SqlSession也能拿到全局配置； 获得SqlSession对象后就能执行各种CRUD方法了。 SQL的具体执行流程见后续博客。 一些重要类总结： SqlSessionFactory SqlSessionFactoryBuilder SqlSession（默认使用DefaultSqlSession） Executor接口 Plugin、InterceptorChain的pluginAll方法 获取Mapper的流程 进入sqlSession.getMapper方法，会发现调的是Configration对象的getMapper方法： public T getMapper(Class type, SqlSession sqlSession) { &#x2F;&#x2F;mapperRegistry实质上是一个Map，里面注册了启动过程中解析的各种Mapper.xml &#x2F;&#x2F;mapperRegistry的key是接口的Class类型 &#x2F;&#x2F;mapperRegistry的Value是MapperProxyFactory,用于生成对应的MapperProxy（动态代理类） return mapperRegistry.getMapper(type, sqlSession); } 进入getMapper方法： public T getMapper(Class type, SqlSession sqlSession) { final MapperProxyFactory mapperProxyFactory &#x3D; (MapperProxyFactory) knownMappers.get(type); &#x2F;&#x2F;如果配置文件中没有配置相关Mapper,直接抛异常 if (mapperProxyFactory &#x3D;&#x3D; null) { throw new BindingException(“Type “ + type + “ is not known to the MapperRegistry.”); } try { &#x2F;&#x2F;关键方法 return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(“Error getting mapper instance. Cause: “ + e, e); } } 进入MapperProxyFactory的newInstance方法： public class MapperProxyFactory { private final Class mapperInterface; private final Map methodCache &#x3D; new ConcurrentHashMap(); public MapperProxyFactory(Class mapperInterface) { this.mapperInterface &#x3D; mapperInterface; } public Class getMapperInterface() { return mapperInterface; } public Map getMethodCache() { return methodCache; } &#x2F;&#x2F;生成Mapper接口的动态代理类MapperProxy，MapperProxy实现了InvocationHandler 接口 @SuppressWarnings(“unchecked”) protected T newInstance(MapperProxy mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); } public T newInstance(SqlSession sqlSession) { final MapperProxy mapperProxy &#x3D; new MapperProxy(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); } } 获取Mapper的流程总结如下： ​ Mapper方法的执行流程 下面是动态代理类MapperProxy，调用Mapper接口的所有方法都会先调用到这个代理类的invoke方法（注意由于Mybatis中的Mapper接口没有实现类，所以MapperProxy这个代理对象中没有委托类，也就是说MapperProxy干了代理类和委托类的事情）。好了下面重点看下invoke方法。 &#x2F;&#x2F;MapperProxy代理类 public class MapperProxy implements InvocationHandler, Serializable { private static final long serialVersionUID &#x3D; -6424540398559729838L; private final SqlSession sqlSession; private final Class mapperInterface; private final Map methodCache; public MapperProxy(SqlSession sqlSession, Class mapperInterface, Map methodCache) { this.sqlSession &#x3D; sqlSession; this.mapperInterface &#x3D; mapperInterface; this.methodCache &#x3D; methodCache; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } else if (isDefaultMethod(method)) { return invokeDefaultMethod(proxy, method, args); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } &#x2F;&#x2F;获取MapperMethod，并调用MapperMethod final MapperMethod mapperMethod &#x3D; cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); } MapperProxy的invoke方法非常简单，主要干的工作就是创建MapperMethod对象或者是从缓存中获取MapperMethod对象。获取到这个对象后执行execute方法。 所以这边需要进入MapperMethod的execute方法：这个方法判断你当前执行的方式是增删改查哪一种，并通过SqlSession执行相应的操作。（这边以sqlSession.selectOne这种方式进行分析~） public Object execute(SqlSession sqlSession, Object[] args) { Object result; &#x2F;&#x2F;判断是CRUD那种方法 switch (command.getType()) { case INSERT: { Object param &#x3D; method.convertArgsToSqlCommandParam(args); result &#x3D; rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param &#x3D; method.convertArgsToSqlCommandParam(args); result &#x3D; rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param &#x3D; method.convertArgsToSqlCommandParam(args); result &#x3D; rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result &#x3D; null; } else if (method.returnsMany()) { result &#x3D; executeForMany(sqlSession, args); } else if (method.returnsMap()) { result &#x3D; executeForMap(sqlSession, args); } else if (method.returnsCursor()) { result &#x3D; executeForCursor(sqlSession, args); } else { Object param &#x3D; method.convertArgsToSqlCommandParam(args); result &#x3D; sqlSession.selectOne(command.getName(), param); } break; case FLUSH: result &#x3D; sqlSession.flushStatements(); break; default: throw new BindingException(“Unknown execution method for: “ + command.getName()); } if (result &#x3D;&#x3D; null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) { throw new BindingException(“Mapper method ‘“ + command.getName() + “ attempted to return null from a method with a primitive return type (“ + method.getReturnType() + “).”); } return result; } 详细流程图 https://www.processon.com/view/link/5efc23966376891e81f2a37e sqlSession.selectOne方法会会调到DefaultSqlSession的selectList方法。这个方法获取了获取了MappedStatement对象，并最终调用了Executor的query方法。 public List selectList(String statement, Object parameter, RowBounds rowBounds) { try { MappedStatement ms &#x3D; configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception e) { throw ExceptionFactory.wrapException(“Error querying database. Cause: “ + e, e); } finally { ErrorContext.instance().reset(); } } 然后，通过一层一层的调用（这边省略了缓存操作的环节，会在后面的文章中介绍），最终会来到doQuery方法， 这儿咱们就随便找个Excutor看看doQuery方法的实现吧，我这儿选择了SimpleExecutor: Copy public List doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt &#x3D; null; try { Configuration configuration &#x3D; ms.getConfiguration(); &#x2F;&#x2F;内部封装了ParameterHandler和ResultSetHandler StatementHandler handler &#x3D; configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt &#x3D; prepareStatement(handler, ms.getStatementLog()); &#x2F;&#x2F;StatementHandler封装了Statement, 让 StatementHandler 去处理 return handler.query(stmt, resultHandler); } finally { closeStatement(stmt); } } 接下来，咱们看看StatementHandler 的一个实现类 PreparedStatementHandler（这也是我们最常用的，封装的是PreparedStatement）, 看看它使怎么去处理的： Copy public List query(Statement statement, ResultHandler resultHandler) throws SQLException { &#x2F;&#x2F;到此，原形毕露， PreparedStatement, 这个大家都已经滚瓜烂熟了吧 PreparedStatement ps &#x3D; (PreparedStatement) statement; ps.execute(); &#x2F;&#x2F;结果交给了ResultSetHandler 去处理,处理完之后返回给客户端 return resultSetHandler. handleResultSets(ps); } 到此，整个调用流程结束。 ​ 简单总结 这边结合获取SqlSession的流程，做下简单的总结： SqlSessionFactoryBuilder解析配置文件，包括属性配置、别名配置、拦截器配置、环境（数据源和事务管理器）、Mapper配置等；解析完这些配置后会生成一个Configration对象，这个对象中包含了MyBatis需要的所有配置，然后会用这个Configration对象创建一个SqlSessionFactory对象，这个对象中包含了Configration对象； 拿到SqlSessionFactory对象后，会调用SqlSessionFactory的openSesison方法，这个方法会创建一个Sql执行器（Executor组件中包含了Transaction对象），这个Sql执行器会代理你配置的拦截器方法。 获得上面的Sql执行器后，会创建一个SqlSession（默认使用DefaultSqlSession）,这个SqlSession中也包含了Configration对象和上面创建的Executor对象，所以通过SqlSession也能拿到全局配置； 获得SqlSession对象后就能执行各种CRUD方法了。 以上是获得SqlSession的流程，下面总结下本博客中介绍的Sql的执行流程： 调用SqlSession的getMapper方法，获得Mapper接口的动态代理对象MapperProxy，调用Mapper接口的所有方法都会调用到MapperProxy的invoke方法（动态代理机制）； MapperProxy的invoke方法中唯一做的就是创建一个MapperMethod对象，然后调用这个对象的execute方法，sqlSession会作为execute方法的入参； 往下，层层调下来会进入Executor组件（如果配置插件会对Executor进行动态代理）的query方法，这个方法中会创建一个StatementHandler对象，这个对象中同时会封装ParameterHandler和ResultSetHandler对象。调用StatementHandler预编译参数以及设置参数值，使用ParameterHandler来给sql设置参数。 Executor组件有两个直接实现类，分别是BaseExecutor和CachingExecutor。CachingExecutor静态代理了BaseExecutor。Executor组件封装了Transction组件，Transction组件中又分装了Datasource组件。 调用StatementHandler的增删改查方法获得结果，ResultSetHandler对结果进行封装转换，请求结束。 Executor、StatementHandler 、ParameterHandler、ResultSetHandler，Mybatis的插件会对上面的四个组件进行动态代理。 Mybatis-插件原理 链接：http://note.youdao.com/noteshare?id=80acf548788cef82ffb924f043241365&amp;sub=FAE1C62BE5C4422EBA80EF27A171C067 重要类 MapperRegistry：本质上是一个Map，其中的key是Mapper接口的全限定名，value的MapperProxyFactory； MapperProxyFactory：这个类是MapperRegistry中存的value值，在通过sqlSession获取Mapper时，其实先获取到的是这个工厂，然后通过这个工厂创建Mapper的动态代理类； MapperProxy：实现了InvocationHandler接口，Mapper的动态代理接口方法的调用都会到达这个类的invoke方法； MapperMethod：判断你当前执行的方式是增删改查哪一种，并通过SqlSession执行相应的操作； SqlSession：作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能； Executor：MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护； StatementHandler:封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。 ParameterHandler:负责对用户传递的参数转换成JDBC Statement 所需要的参数， ResultSetHandler:负责将JDBC返回的ResultSet结果集对象转换成List类型的集合； TypeHandler:负责java数据类型和jdbc数据类型之间的映射和转换 MappedStatement:MappedStatement维护了一条节点的封装， SqlSource:负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql:表示动态生成的SQL语句以及相应的参数信息 Configuration:MyBatis所有的配置信息都维持在Configuration对象之中。 调试主要关注点 MapperProxy.invoke方法：MyBatis的所有Mapper对象都是通过动态代理生成的，任何方法的调用都会调到invoke方法，这个方法的主要功能就是创建MapperMethod对象，并放进缓存。所以调试时我们可以在这个位置打个断点，看下是否成功拿到了MapperMethod对象，并执行了execute方法。 MapperMethod.execute方法：这个方法会判断你当前执行的方式是增删改查哪一种，并通过SqlSession执行相应的操作。Debug时也建议在此打个断点看下。 DefaultSqlSession.selectList方法：这个方法获取了获取了MappedStatement对象，并最终调用了Executor的query方法； 问题： 1.请介绍下MyBatissql语句的解析过程原理 2.请介绍下MyBatis缓存的原理 3.请介绍下MyBatis插件的原理 第十二章Spring容器(Beanfactory整体架构)BeanFactoryBeanFactory表示Bean工厂，所以很明显，BeanFactory会负责创建Bean，并且提供获取Bean的API。​ 而ApplicationContext是BeanFactory的一种，在Spring源码中，是这么定义的：​ 12345public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; ...&#125; 所以，我们可以直接来使用DefaultListableBeanFactory，而不用使用ApplicationContext的某个实现类，比如： 12345678DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setBeanClass(User.class);beanFactory.registerBeanDefinition(&quot;user&quot;, beanDefinition);System.out.println(beanFactory.getBean(&quot;user&quot;)); DefaultListableBeanFactory是非常强大的，支持很多功能，可以通过查看DefaultListableBeanFactory的类继承实现结构来看 这部分现在看不懂没关系，源码熟悉一点后回来再来看都可以。 它实现了很多接口，表示，它拥有很多功能： AliasRegistry：支持别名功能，一个名字可以对应多个别名 BeanDefinitionRegistry：可以注册、保存、移除、获取某个BeanDefinition BeanFactory：Bean工厂，可以根据某个bean的名字、或类型、或别名获取某个Bean对象 SingletonBeanRegistry：可以直接注册、获取某个单例Bean SimpleAliasRegistry：它是一个类，实现了AliasRegistry接口中所定义的功能，支持别名功能 ListableBeanFactory：在BeanFactory的基础上，增加了其他功能，可以获取所有BeanDefinition的beanNames，可以根据某个类型获取对应的beanNames，可以根据某个类型获取{类型：对应的Bean}的映射关系 HierarchicalBeanFactory：在BeanFactory的基础上，添加了获取父BeanFactory的功能 DefaultSingletonBeanRegistry：它是一个类，实现了SingletonBeanRegistry接口，拥有了直接注册、获取某个单例Bean的功能 ConfigurableBeanFactory：在HierarchicalBeanFactory和SingletonBeanRegistry的基础上，添加了设置父BeanFactory、类加载器（表示可以指定某个类加载器进行类的加载）、设置Spring EL表达式解析器（表示该BeanFactory可以解析EL表达式）、设置类型转化服务（表示该BeanFactory可以进行类型转化）、可以添加BeanPostProcessor（表示该BeanFactory支持Bean的后置处理器），可以合并BeanDefinition，可以销毁某个Bean等等功能 FactoryBeanRegistrySupport：支持了FactoryBean的功能 AutowireCapableBeanFactory：是直接继承了BeanFactory，在BeanFactory的基础上，支持在创建Bean的过程中能对Bean进行自动装配 AbstractBeanFactory：实现了ConfigurableBeanFactory接口，继承了FactoryBeanRegistrySupport，这个BeanFactory的功能已经很全面了，但是不能自动装配和获取beanNames ConfigurableListableBeanFactory：继承了ListableBeanFactory、AutowireCapableBeanFactory、ConfigurableBeanFactory AbstractAutowireCapableBeanFactory：继承了AbstractBeanFactory，实现了AutowireCapableBeanFactory，拥有了自动装配的功能 DefaultListableBeanFactory：继承了AbstractAutowireCapableBeanFactory，实现了ConfigurableListableBeanFactory接口和BeanDefinitionRegistry接口，所以DefaultListableBeanFactory的功能很强大 ApplicationContext上面有分析到，ApplicationContext是个接口，实际上也是一个BeanFactory，不过比BeanFactory更加强大，比如：​ HierarchicalBeanFactory：拥有获取父BeanFactory的功能 ListableBeanFactory：拥有获取beanNames的功能 ResourcePatternResolver：资源加载器，可以一次性获取多个资源（文件资源等等） EnvironmentCapable：可以获取运行时环境（没有设置运行时环境功能） ApplicationEventPublisher：拥有广播事件的功能（没有添加事件监听器的功能） MessageSource：拥有国际化功能 具体的功能演示，后面会有。 我们先来看ApplicationContext两个比较重要的实现类： AnnotationConfigApplicationContext ClassPathXmlApplicationContext AnnotationConfigApplicationContext 这部分现在看不懂没关系，源码熟悉一点后回来再来看都可以。 ConfigurableApplicationContext：继承了ApplicationContext接口，增加了，添加事件监听器、添加BeanFactoryPostProcessor、设置Environment，获取ConfigurableListableBeanFactory等功能 AbstractApplicationContext：实现了ConfigurableApplicationContext接口 GenericApplicationContext：继承了AbstractApplicationContext，实现了BeanDefinitionRegistry接口，拥有了所有ApplicationContext的功能，并且可以注册BeanDefinition，注意这个类中有一个属性(DefaultListableBeanFactory beanFactory) AnnotationConfigRegistry：可以单独注册某个为类为BeanDefinition（可以处理该类上的**@Configuration注解，已经可以处理@Bean注解**），同时可以扫描 AnnotationConfigApplicationContext：继承了GenericApplicationContext，实现了AnnotationConfigRegistry接口，拥有了以上所有的功能 ClassPathXmlApplicationContext它也是继承了AbstractApplicationContext，但是相对于AnnotationConfigApplicationContext而言，功能没有AnnotationConfigApplicationContext强大，比如不能注册BeanDefinition 国际化 创建两个国际化文件 一个设置为test &#x3D; a 一个设置为test &#x3D; b 先定义一个MessageSource: 123456@Beanpublic MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); messageSource.setBasename(&quot;messages&quot;); return messageSource;&#125; 有了这个Bean，你可以在你任意想要进行国际化的地方使用该MessageSource。同时，因为ApplicationContext也拥有国家化的功能，所以可以直接这么用： 1context.getMessage(&quot;test&quot;, null, new Locale(&quot;en&quot;)) 输出 b 实际使用 就是一个类实现ApplicationContextAware 来回调进行使用 资源加载ApplicationContext还拥有资源加载的功能，比如，可以直接利用ApplicationContext获取某个文件的内容： 1234AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);// 获取一个文件Resource resource = context.getResource(&quot;file://D:\\\\IdeaProjects\\\\spring-framework\\\\luban\\\\src\\\\main\\\\java\\\\com\\\\luban\\\\entity\\\\User.java&quot;);System.out.println(resource.contentLength()); // 获得字符长度 你可以想想，如果你不使用ApplicationContext，而是自己来实现这个功能，就比较费时间了。 还比如你可以： 12345678910111213AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);Resource resource = context.getResource(&quot;file://D:\\\\IdeaProjects\\\\spring-framework-5.3.10\\\\tuling\\\\src\\\\main\\\\java\\\\com\\\\zhouyu\\\\service\\\\UserService.java&quot;);System.out.println(resource.contentLength());System.out.println(resource.getFilename());Resource resource1 = context.getResource(&quot;https://www.baidu.com&quot;);System.out.println(resource1.contentLength());System.out.println(resource1.getURL());Resource resource2 = context.getResource(&quot;classpath:spring.xml&quot;);System.out.println(resource2.contentLength());System.out.println(resource2.getURL()); 还可以一次性获取多个： 12345Resource[] resources = context.getResources(&quot;classpath:com/zhouyu/*.class&quot;);for (Resource resource : resources) &#123; System.out.println(resource.contentLength()); System.out.println(resource.getFilename());&#125; 获取运行时环境1234567891011121314151617181920212223AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);Map&lt;String, Object&gt; systemEnvironment = context.getEnvironment().getSystemEnvironment();// 系统环境变量System.out.println(systemEnvironment);System.out.println(&quot;=======&quot;);Map&lt;String, Object&gt; systemProperties = context.getEnvironment().getSystemProperties();//java环境变量System.out.println(systemProperties);System.out.println(&quot;=======&quot;);MutablePropertySources propertySources = context.getEnvironment().getPropertySources();// 包含前两者和加的配置文件System.out.println(propertySources);System.out.println(&quot;=======&quot;);// 具体的获取值System.out.println(context.getEnvironment().getProperty(&quot;NO_PROXY&quot;));System.out.println(context.getEnvironment().getProperty(&quot;sun.jnu.encoding&quot;));System.out.println(context.getEnvironment().getProperty(&quot;zhouyu&quot;)); 注意，可以利用 123456加载配置类上面@PropertySource(&quot;classpath:spring.properties&quot;) //创建对应的配置文件MutablePropertySources propertySources = context.getEnvironment().getPropertySources();System.out.println(propertySources); 来使得某个properties文件中的参数添加到运行时环境中 第十三章 实践Spring的使用 与 真正实现的逻辑代码(增强代码&#x2F;业务代码) Bean生命周期(重要紧急)理解各个生命周期的作用与记忆, 依赖注入实现通过Spring提供的组件(解析器等)实现具体Bean后置处理器的逻辑,解析注解等 整合Mybatis其他框架注册Bean到容器中并有些定制处理的实现(BeanDefinition,BeanFacory的增强),解析配置类等等 逻辑: AOP与事务(重要紧急)可涉及到aop,事务,对Bean进行增强 aop: AbstractAdvisorAutoProxyCreator实际上就是一个BeanPostProcessor在初始化后进行增强 逻辑: 使用自带的ProxyFactory生成代理类替换需要增强的类","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"https://gouguoqiang.github.io/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"微服务","slug":"all/9MicroService","date":"2022-10-09T03:36:23.000Z","updated":"2022-10-09T13:57:51.033Z","comments":true,"path":"2022/10/09/all/9MicroService/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/09/all/9MicroService/","excerpt":"","text":"微服务架构1. 服务组件化 1. 服务间交互采用restful 风格 1. 去中心化 :每个服务有自己的私有数据库持久化系统 1. 自动化部署:把应用拆分为一个一个独立的单个服务,方便自动化部署,测试,运维 1.传统集中式架构 ​ 开发速度快 ​ 并发能力差 ​ 代码耦合度高,维护困难 ​ 容错率低 2.垂直拆分 ​ 一个数据库,多个系统模块 ​ 拆分实现了流量分担,解决并发 ​ 可针对不同模块进行优化 ​ 方便水平扩展(集群化),负载均衡,容错率高 ​ 系统间相互独立,会有很多重复开发,影响开发效率 3.分布式服务 ​ 垂直应用越来越多,应用交互不可避免 ​ 系统间相互调用,调高代码复用和效率 ​ 系统间耦合度高,调用关系错综复杂,难以维护 ​ 服务提供方一旦产生变更,所有消费方都需要变更 4.面向服务架构(SOA) ​ 中间增加一层ESB,用来连接各个服务结点,集成不同系统,不同协议的服务 ​ 做消息的转化解释和路由工作 ​ ESB产品实现复杂,服务粒度较大, ESB包含的功能如:负载均衡,流量控制 ​ 加密处理,服务监控,异常处理等等 ​ 集成整合所有服务,数据转换使运维,测试部署困难 ​ 所有服务通过一个通路通信,降低通信速度 ​ 通常松耦合 基于socket工作在会话层,自定义数据格式,速度快,效率高 5.微服务架构 ​ 基于TCP工作在应用层,规定了数据传输格式 ​ 服务粒度小,使用轻量级通信,通常是HTTP API ​ 各服务可使用不同的编程语言实现,以及不同的数据存储技术 ​ 服务间相互独立 ​ 并保持最低限度的集中式管理 ​ 网关给用户提供统一的方式接入微服务,在网关层处理所有的非业务功能,例如身份验证,监控,负载均衡,缓存,请求分片与管理,静态响应处理,服务端通过服务注册中心进行服务注册和管理 dubbo1-今日内容 分布式系统中的相关概念 dubbo 概述 dubbo快速入门 dubbo的高级特性 2-相关概念2.1-互联网项目架构-特点互联网项目架构-特点 用户多 流量大，并发高 海量数据 易受攻击 功能繁琐 变更快 传统项目和互联网项目的不同 ![1581310475046](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581310475046.png) 用户体验： 美观、功能、速度、稳定性 衡量一个网站速度是否快: 打开一个新页面一瞬间完成;页面内跳转，-刹那间完成。 根据佛经《僧衹律》记载:一 刹那者为-念,二十念为-瞬,二十瞬为-弹 指，二十弹指为-罗预， 二十罗预为-须臾，一日一夜有三十须臾。 2.2-互联网项目架构-目标衡量网站的性能指标: **响应时间:**指执行一个请求从开始到最后收到响应数据所花费的总体时间。 **并发数:**指系统同时能处理的请求数量。 并发连接数: 指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器连接的总TCP数量 **请求数:**也称为QPS(Query Per Second)指每秒多少请求. **并发用户数:**单位时间内有多少用户 **吞吐量:**指单位时间内系统能处理的请求数量。 ●QPS: Query Per Second每秒查询数。 ●TPS: Transactions Per Second每秒事务数。 ●一个事务是指一 个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束 计时，以此来计算使用的时间和完成的事务个数。 ●一个页面的一次访问，只会形成一 个TPS; 但-次页面请求，可能产生多次对服务器的请求，就会有多个QPS QPS&gt;=并发连接数&gt;= TPS 大型互联网项目架构目标: ​ ●**高性能:提供快速的访问体验。​ ●高可用:**网站服务- 可以正常访问 2.3-集群和分布式集群和分布式，●集群:很多“人”一起，干一样的事。●一个业务模块，部署在多台服务器上。●分布式:很多”人”一起，干不样的事。这些不一样的事， 合起来是一件大事。 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;集群和分布式-1581325224087.png) 2.4-架构演进单体架构： 优点: 简单:开发部署都很方便，小型项目首选缺点:●项目启动慢●可靠性差 ![1581313584459](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581313584459.png) 垂直架构：垂直架构是指将单体架构中的多个模块拆分为多个独立的项目。形成多个独立的单体架构。 单体架构存在的问题: 项目启动慢 可靠性差 可伸缩性差 扩展性和可维护性差 性能低 垂直架构存在的问题: 重复功能太多 ![1581313910427](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581313910427.png) 分布式架构：是指在垂直架构的基础上,将公共业务模块抽取出来,作为独立的服务供其他调用者消费，以实现服务的共享和重用。底层通过RPC（远程过程调用实现） RPC: Remote Procedure Call远程过程调用。有非常多的协议和技术来都实现了RPC的过程。比如: HTTP REST风格，Java RMI规范、WebService SOAP协议Hession等等。垂直架构存在的问题: ●重复功能太多 分布式架构存在的问题:​ ●服务提供方- -旦产生变更,所有消费方都需要变更。 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;分布式架构.png) **SOA: (Service- Oriented Architecture,面向服务的架构)**：是一个组件模型,它将应用程序的不同功能单元(称为服务)进行拆分，并通过这些服务之间定义良好的接口和契约联系起来。 **ESB: (Enterparise Servce Bus)**：企业服务总线,服务中介。主要是提供了一一个服务于服务之间的交互。ESB包含的功能如:负载均衡，流量控制，加密处理，服务的监控，异常处理，监控告急等等。 ![1581314362523](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581314362523.png) 微服务架构： ●微服务架构是在SOA上做的升华,微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。 ●微服务架构&#x3D; 80%的SOA服务架构思想+ 100%的组件化架构思想+ 80%的领域建模思想 特点:●服务实现组件化:开发者可以自由选择开发技术。也不需要协调其他团队●服务之间交互一 般使用REST API●去中心化:每个微服务有自己私有的数据库持久化业务数据●自动化部署:把应用拆分成为一 个-个独立的单个服务,方便自动化部署、测试、运维 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;微服务架构图.png) 3-dubbo 概述Dubbo概念 ●Dubbo是阿里巴巴公司开源的一个高性能、轻量级的Java RPC框架。●致力于提供高性能和透明化的RPC远程服务调用方案,以及SOA服务治理方案。●官网: htp:&#x2F;&#x2F;ubbo.apache.orgo ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;Dubbo架构图.png) 节点角色说明: .●Provider: 暴露服务的服务提供方●Container: 服务运行容器●Consumer: 调用远程服务的服务消费方●Registry: 服务注册与发现的注册中心●Monitor:统计服务的调用次数和调用时间的监控中心 4-dubbo快速入门4.1zookeeper安装安装步骤： 第一步：安装 jdk（略）第二步：把 zookeeper 的压缩包（zookeeper-3.4.6.tar.gz）上传到 linux 系统第三步：解压缩压缩包 1tar -zxvf zookeeper-3.4.6.tar.gz 第四步：进入zookeeper-3.4.6目录，创建data目录 1mkdir data 第五步：进入conf目录 ，把zoo_sample.cfg 改名为zoo.cfg 12cd confmv zoo_sample.cfg zoo.cfg 第六步：打开zoo.cfg文件, 修改data属性： 1dataDir=/root/zookeeper-3.4.6/data 进入Zookeeper的bin目录，启动服务命令 1./zkServer.sh start ![1581315609244](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581315609244.png) 停止服务命令 1./zkServer.sh stop 查看服务状态：standalone 单节点 1./zkServer.sh status ![1581315645227](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581315645227.png) 4.2spring和springmvc整合实施步骤： 1.创建服务提供者Provider模块2.创建服务消费者Consumer模块3.在服务提供者模块编写UserServicelmpl提供服务4.在服务消费者中的UserC ontroller远程调用5.UserServicelmpl提供的服务6.分别启动两个服务，测试 Dubbo作为一个RPC框架，其最核心的功能就是要实现跨网络的远程调用。本小节就是要创建两个应用，一个作为服务的提供方，一个作为服务的消费方。通过Dubbo来实现服务消费方远程调用服务提供方的方法。 1 服务提供方开发 开发步骤： （1）创建maven工程（打包方式为war）dubbodemo_provider，在pom.xml文件中导入如下坐标 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.5.RELEASE&lt;/spring.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.12.1.GA&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 指定端口 --&gt; &lt;port&gt;8081&lt;/port&gt; &lt;!-- 请求路径 --&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; （2）配置web.xml文件 1234567891011121314&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;/web-app&gt; （3）创建服务接口 1234package com.itheima.service;public interface HelloService &#123; public String sayHello(String name);&#125; （4）创建服务实现类 注意：服务实现类上使用的Service注解是Dubbo提供的，用于对外发布服务 12345678910package com.itheima.service.impl;import com.alibaba.dubbo.config.annotation.Service;import com.itheima.service.HelloService;@Servicepublic class HelloServiceImpl implements HelloService &#123; public String sayHello(String name) &#123; return &quot;hello &quot; + name; &#125;&#125; tomcat7:run 2 服务消费方开发 开发步骤： （1）创建maven工程（打包方式为war）dubbodemo_consumer，pom.xml配置和上面服务提供者相同，只需要将Tomcat插件的端口号改为8082即可 （2）配置web.xml文件 1234567891011121314151617181920&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 指定加载的配置文件 ，通过参数contextConfigLocation加载 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext-web.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; （3）将服务提供者工程中的HelloService接口复制到当前工程 （4）编写Controller 1234567891011121314151617181920package com.itheima.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.itheima.service.HelloService;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controller@RequestMapping(&quot;/demo&quot;)public class HelloController &#123; @Reference private HelloService helloService; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String getName(String name)&#123; //远程调用 String result = helloService.sayHello(name); System.out.println(result); return result; &#125;&#125; 注意：Controller中注入HelloService使用的是Dubbo提供的@Reference注解 4.3服务提供者在dubbodemo_provider工程中src&#x2F;main&#x2F;resources下创建applicationContext-service.xml 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo_provider&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 注册 协议和port 端口默认是20880 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20881&quot;&gt;&lt;/dubbo:protocol&gt; &lt;!-- 扫描指定包，加上@Service注解的类会被发布为服务 --&gt; &lt;dubbo:annotation package=&quot;com.itheima.service.impl&quot; /&gt;&lt;/beans&gt; 4.4服务消费者在dubbodemo_consumer工程中src&#x2F;main&#x2F;resources下创建applicationContext-web.xml 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo-consumer&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 包扫描的方式 引用服务 扫描@Reference --&gt; &lt;dubbo:annotation package=&quot;com.itheima.controller&quot; /&gt;&lt;/beans&gt; 运行测试 tomcat7:run启动 在浏览器输入http://localhost:8082/demo/hello.do?name=Jack，查看浏览器输出结果 5-dubbo高级特性5.1dubbo-admin安装dubbo- admin ●dubbo-admin管理平台，是图形化的服务管理页面 ●从注册中心中获取到所有的提供者 &#x2F;消费者进行配置管理 ●路由规则、动态配置、服务降级、访问控制、权重调整、负载均衡等管理功能 ●dubbo- admin是一个前后端分离的项目。前端使用vue，后端使用springboot ●安装dubbo-admin其实就是部署该项目 具体安装参见：dubbo-admin.md 5.2-dubbo-admin使用具体安装参见：dubbo-admin.md 5.3序列化 dubbo 内部已经将序列化和反序列化的过程内部封装了 我们只需要在定义pojo类时实现seriali zable接口即可 一般会定义一 个公共的pojo模块,让生产者和消费者都依赖该模块。 ![1581317650919](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581317650919.png) User对象未实现seriali zable接口 错误信息： ![1581317583708](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581317583708.png) 解决办法： 1User implements Serializable 5.4地址缓存注册中心挂了，服务是否可以正常访问？ 可以，因为dubbo服务消费者在第一-次调用时，会将服务提供方地址缓存到本地，以后在调用则不会访问注册中心。 当服务提供者地址发生变化时，注册中心会通知服务消费者。 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;Dubbo架构图-1581318103917.png) 5.5 超时![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;超时图片.png) 服务消费者在调用服务提供者的时候发生了阻塞、等待的情形,这个时候,服务消费者会直等待下去。 在某个峰值时刻，大量的请求都在同时请求服务消费者,会造成线程的大量堆积，势必会造成雪崩。 dubbo利用超时机制来解决这个问题，设置-个超时时间, 在这个时间段内，无法完成服务访问,则自动断开连接。 使用timeout属性配置超时时间，默认值1000，单位毫秒 12//timeout 超时时间 单位毫秒 retries 重试次数@Service(timeout = 3000,retries=0) 5.6重试![1581322543136](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581322543136.png) 设置了超时时间，在这个时间段内，无法完成服务访问,则自动断开连接。 如果出现网络抖动,则这一-次请求就会失败。 Dubbo提供重试机制来避免类似问题的发生。 通过retries属性来设置重试次数。默认为2次 12//timeout 超时时间 单位毫秒 retries 重试次数@Service(timeout = 3000,retries=0) 5.7多版本![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;多版本图片.png) **灰度发布:**当出现新功能时,会让一部分用户先使用新功能，用户反馈没问题时，再将所有用户迁移到新功能。 dubbo中使用version属性来设置和调用同一个接口的不同版本 生产者配置 12@Service(version=&quot;v2.0&quot;)public class UserServiceImp12 implements UserService &#123;...&#125; 消费者配置 12@Reference(version = &quot;v2.0&quot;)//远程注入private UserService userService; 5.8负载均衡负载均衡策略(4种) :**Random:**按权重随机，默认值。按权重设置随机概率。 RoundRobin: 按权重轮询。 LeastActive: 最少活跃调用数,相同活跃数的随机。 **ConsistentHash:**一 致性Hash,相同参数的请求总是发到同一提供者。 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;负载均衡图.png) 服务提供者配置 12@Service(weight = 100)public class UserServiceImp12 implements UserService &#123;...&#125; application.xml 配置parameter key ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;负载均衡-配置文件.png) 消费者配置 12345//@Reference(loadbalance = &quot;roundrobin&quot;)//@Reference(loadbalance = &quot;leastactive&quot;)//@Reference(loadbalance = &quot;consistenthash&quot;)@Reference(loadbalance = &quot;random&quot;)//默认 按权重随机private UserService userService; 5.9集群容错![1581324308044](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;1581324308044.png) 集群容错模式: **Failover Cluster:**失败重试。默认值。当出现失败，重试其它服务器，默认重试2次，使用retries配置。一般用于读操作 **Failfast Cluster :**快速失败,发起-次调用，失败立即报错。通常用于写操作。 **Failsafe Cluster:**失败安全，出现异常时，直接忽略。返回一个空结果。 **Failback Cluster:**失败自动恢复,后台记录失败请求,定时重发。 **Forking Cluster :**并行调用多个服务器，只要一个成功即返回。 Broadcast Cluster: 广播调用所有提供者,逐个调用，任意一台报错则报错。 消费者配置 12@Reference(cluster = &quot;failover&quot;)//远程注入private UserService userService; 5.10服务降级服务降级：当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作 服务降级方式:mock&#x3D; force:return null：表示消费方对该服务的方法调用都直接返回null值,不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 mock&#x3D;fail:return null：表示消费方对该服务的方法调用在失败后，再返回null值,不抛异常。用来容忍不重要服务不稳定时对调用方的影响 ![](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;4.Dubbo【海量资源尽在 】&#x2F;20-Dubbo&#x2F;笔记&#x2F;img&#x2F;服务降级图片.png) 消费方配置 123//远程注入@Reference(mock =“ force :return null&quot;)//不再调用userService的服务private UserService userService; 总结概述SOA,RPC框架 用Zookeeper作为注册中心 快速入门快速开始提供者 123456789&lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo_provider&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 注册 协议和port 端口默认是20880 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20881&quot;&gt;&lt;/dubbo:protocol&gt; &lt;!-- 扫描指定包，加上@Service注解的类会被发布为服务 --&gt; &lt;dubbo:annotation package=&quot;com.itheima.service.impl&quot; /&gt; 消费者 12345&lt;dubbo:application name=&quot;dubbodemo-consumer&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 包扫描的方式 引用服务 扫描@Reference --&gt; &lt;dubbo:annotation package=&quot;com.itheima.controller&quot; /&gt; 超时,重试,负载均衡,灰度发布(多版本)@Service(timeout &#x3D; ,retries &#x3D; ,version&#x3D;””) 同spring @service一致采用dubbo包 用于服务发布 @Reference(loadbalance &#x3D; “”,version &#x3D; “”)) 类似Autowire 用于服务发现 &#x2F;&#x2F;@Reference(loadbalance &#x3D; “roundrobin”)&#x2F;&#x2F;@Reference(loadbalance &#x3D; “leastactive”)&#x2F;&#x2F;@Reference(loadbalance &#x3D; “consistenthash”)@Reference(loadbalance &#x3D; “random”)&#x2F;&#x2F;默认 按权重随机 @Service(timeout &#x3D; 3000,retries&#x3D;0) @Reference(version &#x3D; “v2.0”)&#x2F;&#x2F;远程注入 private UserService userService; 集群容错**Failover Cluster:**失败重试。默认值。当出现失败，重试其它服务器，默认重试2次，使用retries配置。一般用于读操作 **Failfast Cluster :**快速失败,发起-次调用，失败立即报错。通常用于写操作。 **Failsafe Cluster:**失败安全，出现异常时，直接忽略。返回一个空结果。 **Failback Cluster:**失败自动恢复,后台记录失败请求,定时重发。 **Forking Cluster :**并行调用多个服务器，只要一个成功即返回。 Broadcast Cluster: 广播调用所有提供者,逐个调用，任意一台报错则报错。 消费者配置 12@Reference(cluster = &quot;failover&quot;)//远程注入private UserService userService; 服务降级服务降级：当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作 服务降级方式:mock&#x3D; force:return null：表示消费方对该服务的方法调用都直接返回null值,不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。 mock&#x3D;fail:return null：表示消费方对该服务的方法调用在失败后，再返回null值,不抛异常。用来容忍不重要服务不稳定时对调用方的影响 消费方配置 123//远程注入@Reference(mock =“ force :return null&quot;)//不再调用userService的服务private UserService userService; 分布式 很多人一起干不一样的事 合起来是一件大事 0-5 共六步 图片 todo 功能 一个RPC框架 远程过程调用,能够将单体上的应用的各个模块变成分布式,关键是call过程,通过zookeeper注册中心(服务治理) zookeepper 是一个树结构,结点可以存储信息 &#x2F; 根节点 分布式锁的实现 临时有序结点,选取顺序最小的 每个线程申请都会生成一结点, 集群治理 其他高级特性 心跳 负载均衡 容灾 服务注册&#x2F;发现4. 配置管理 服务提供者将服务信息注册到服务中心,消费者对生产者进行调用,会在本地存有地址和端口缓存,如果服务提供者的地址端口信息等进行更新,zookeepper会通知消费者更新缓存 (在下次调用时更新还是一更改就更新?思考:一更改就更新,会有缓存的嗅探()好处是只要缓存命中就能保证服务的可靠性,如果调用时更新,缓存的意义就不大了,) 还有 monitor (sentinel(或duboo-admin)对rpc进行监控) 特性 序列化 地址缓存 超时与重试 消费者的请求阻塞,等待的时候,dubbo设置了超时机制,无法完成服务访问则自动断开连接(基于TCP的连接?) 如果出现网络抖动,请求失败,通过retries设置重传次数 默认2 多版本 用version属性来调用同一个接口的不同版本 负载均衡选用哪个服务 random :按权重随机,每个默认都为100 roundRobin权重轮询 LeastActive最少活跃调用,相同活跃随机 ConsistentHash 一致性hash,相同参数的请求总是发到同一提供者 6)集群容错 实验1 通过Dubbo实现远程调用启动 zookeepper 生产者 编写service 在Impl上增加dubbo service注解 用于对外发布服务 123456@Servicepublic class HelloServiceImpl implements HelloService &#123; public String sayHello(String name) &#123; return &quot;hello &quot; + name; &#125;&#125; 12345678910&lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo_provider&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 注册 协议和port 端口默认是20880 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20881&quot;&gt;&lt;/dubbo:protocol&gt; &lt;!-- 扫描指定包，加上@Service注解的类会被发布为服务 --&gt; &lt;dubbo:annotation package=&quot;com.itheima.service.impl&quot; /&gt;&lt;/beans&gt; 消费者编写 controller 远程调用 service 1234567891011121314151617181920package com.itheima.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.itheima.service.HelloService;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controller@RequestMapping(&quot;/demo&quot;)public class HelloController &#123; @Reference private HelloService helloService; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String getName(String name)&#123; //远程调用 String result = helloService.sayHello(name); System.out.println(result); return result; &#125;&#125; 123456&lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo-consumer&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 包扫描的方式 引用服务 扫描@Reference --&gt; &lt;dubbo:annotation package=&quot;com.itheima.controller&quot; /&gt; Zookeeper1)初识 Zookeeper1.1)Zookeeper概念•Zookeeper 是 Apache Hadoop 项目下的一个子项目，是一个树形目录服务。 •Zookeeper 翻译过来就是 动物园管理员，他是用来管 Hadoop（大象）、Hive(蜜蜂)、Pig(小 猪)的管理员。简称zk •Zookeeper 是一个分布式的、开源的分布式应用程序的协调服务。 •Zookeeper 提供的主要功能包括： •配置管理 •分布式锁 •集群管理 ![1592054580488](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592054580488.png) ![1592054603167](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592054603167.png) 2)ZooKeeper 安装与配置2.1) 下载安装2.1.1、环境准备ZooKeeper服务器是用Java创建的，它运行在JVM之上。需要安装JDK 7或更高版本。 2.1.2、上传将下载的ZooKeeper放到&#x2F;opt&#x2F;ZooKeeper目录下 12345678#上传zookeeper alt+pput f:/setup/apache-zookeeper-3.5.6-bin.tar.gz#打开 opt目录cd /opt#创建zooKeeper目录mkdir zooKeeper#将zookeeper安装包移动到 /opt/zooKeepermv apache-zookeeper-3.5.6-bin.tar.gz /opt/zookeeper/ 2.1.3、解压将tar包解压到&#x2F;opt&#x2F;zookeeper目录下 1tar -zxvf apache-ZooKeeper-3.5.6-bin.tar.gz 2.2) 配置启动2.2.1、配置zoo.cfg进入到conf目录拷贝一个zoo_sample.cfg并完成配置 1234#进入到conf目录cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/#拷贝cp zoo_sample.cfg zoo.cfg 修改zoo.cfg 123456#打开目录cd /opt/zooKeeper/#创建zooKeeper存储目录mkdir zkdata#修改zoo.cfgvim /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/zoo.cfg ![1577548250377](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1577548250377.png) 修改存储目录：dataDir&#x3D;&#x2F;opt&#x2F;zookeeper&#x2F;zkdata 2.2.2、启动ZooKeeper123cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/bin/#启动 ./zkServer.sh start ![1577548052037](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1577548052037.png) 看到上图表示ZooKeeper成功启动 3、查看ZooKeeper状态 1./zkServer.sh status zookeeper启动成功。standalone代表zk没有搭建集群，现在是单节点 ![1577548175232](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1577548175232.png) zookeeper没有启动 ![1577548112773](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1577548112773.png) 3)ZooKeeper 命令操作3.1)Zookeeper命令操作数据模型•ZooKeeper 是一个树形目录服务,其数据模型和Unix的文件系统目录树很类似，拥有一个层次化结构。 •这里面的每一个节点都被称为： ZNode，每个节点上都会保存自己的数据和节点信息。 • 节点可以拥有子节点，同时也允许少量（1MB）数据存储在该节点之下。 •节点可以分为四大类： •PERSISTENT 持久化节点 •EPHEMERAL 临时节点 ：-e •PERSISTENT_SEQUENTIAL 持久化顺序节点 ：-s •EPHEMERAL_SEQUENTIAL 临时顺序节点 ：-es ![1592054828485](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592054828485.png) ![1592054844023](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592054844023.png) 3.2)Zookeeper命令操作服务端命令•启动 ZooKeeper 服务: .&#x2F;zkServer.sh start •查看 ZooKeeper 服务状态: .&#x2F;zkServer.sh status •停止 ZooKeeper 服务: .&#x2F;zkServer.sh stop •重启 ZooKeeper 服务: .&#x2F;zkServer.sh restart ![1592055088686](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592055088686.png) 3.3)Zookeeper客户端常用命令•连接ZooKeeper服务端 1./zkCli.sh –server ip:port •断开连接 1quit •查看命令帮助 1help •显示指定目录下节点 1ls 目录 •创建节点 1create /节点path value •获取节点值 1get /节点path •设置节点值 1set /节点path value •删除单个节点 1delete /节点path •删除带有子节点的节点 1deleteall /节点path ![1592055332198](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592055332198.png) ![1592055345400](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592055345400.png) 3.4)客户端命令-创建临时有序节点•创建临时节点 1create -e /节点path value •创建顺序节点 1create -s /节点path value •查询节点详细信息 1ls –s /节点path •czxid：节点被创建的事务ID •ctime: 创建时间 •mzxid: 最后一次被更新的事务ID •mtime: 修改时间 •pzxid：子节点列表最后一次被更新的事务ID •cversion：子节点的版本号 •dataversion：数据版本号 •aclversion：权限版本号 •ephemeralOwner：用于临时节点，代表临时节点的事务ID，如果为持久节点则为0 •dataLength：节点存储的数据的长度 •numChildren：当前节点的子节点个数 ![1592055462588](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592055462588.png) 4)ZooKeeper JavaAPI 操作4.1)urator介绍•Curator 是 Apache ZooKeeper 的Java客户端库。 •常见的ZooKeeper Java API ： •原生Java API •ZkClient •Curator •Curator 项目的目标是简化 ZooKeeper 客户端的使用。 •Curator 最初是 Netfix 研发的,后来捐献了 Apache 基金会,目前是 Apache 的顶级项目。 •官网：http://curator.apache.org/ 4.2)JavaAPI操作建立连接1，搭建项目 创建项目curator-zk 引入pom和日志文件 资料文件夹下pom.xml和log4j.properties ![1592055569716](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592055569716.png) 2、创建测试类，使用curator连接zookeeper 12345678910111213141516@Beforepublic void testConnect() &#123; //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); client = CuratorFrameworkFactory.builder() .connectString(&quot;192.168.200.130:2181&quot;) .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) .namespace(&quot;itheima&quot;) .build(); //开启连接 client.start();&#125; 4.3)Zookeeper JavaAPI操作-创建节点1234567891011121314/*** 创建节点：create 持久 临时 顺序 数据* 1. 基本创建 ：create().forPath(&quot;&quot;)* 2. 创建节点 带有数据:create().forPath(&quot;&quot;,data)* 3. 设置节点的类型：create().withMode().forPath(&quot;&quot;,data)* 4. 创建多级节点 /app1/p1 ：create().creatingParentsIfNeeded().forPath(&quot;&quot;,data)*/@Testpublic void testCreate() throws Exception &#123; //2. 创建节点 带有数据 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(&quot;/app2&quot;, &quot;hehe&quot;.getBytes()); System.out.println(path);&#125; 123456789101112131415161718192021@Testpublic void testCreate2() throws Exception &#123; //1. 基本创建 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(&quot;/app1&quot;); System.out.println(path);&#125;@Testpublic void testCreate3() throws Exception &#123; //3. 设置节点的类型 //默认类型：持久化 String path = client.create().withMode(CreateMode.EPHEMERAL).forPath(&quot;/app3&quot;); System.out.println(path);&#125;@Testpublic void testCreate4() throws Exception &#123; //4. 创建多级节点 /app1/p1 //creatingParentsIfNeeded():如果父节点不存在，则创建父节点 String path = client.create().creatingParentsIfNeeded().forPath(&quot;/app4/p1&quot;); System.out.println(path);&#125; 4.4)ZookeeperJavaAPI操作-查询节点123456789101112/*** 查询节点：* 1. 查询数据：get: getData().forPath()* 2. 查询子节点： ls: getChildren().forPath()* 3. 查询节点状态信息：ls -s:getData().storingStatIn(状态对象).forPath()*/@Testpublic void testGet1() throws Exception &#123; //1. 查询数据：get byte[] data = client.getData().forPath(&quot;/app1&quot;); System.out.println(new String(data));&#125; 1234567891011121314@Testpublic void testGet2() throws Exception &#123; // 2. 查询子节点： ls List&lt;String&gt; path = client.getChildren().forPath(&quot;/&quot;); System.out.println(path);&#125;@Testpublic void testGet3() throws Exception &#123; Stat status = new Stat(); System.out.println(status); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(&quot;/app1&quot;); System.out.println(status);&#125; 4.5)Zookeeper JavaAPI操作-修改节点123456789101112/*** 修改数据* 1. 基本修改数据：setData().forPath()* 2. 根据版本修改: setData().withVersion().forPath()* * version 是通过查询出来的。目的就是为了让其他客户端或者线程不干扰我。** @throws Exception*/@Testpublic void testSet() throws Exception &#123; client.setData().forPath(&quot;/app1&quot;, &quot;itcast&quot;.getBytes());&#125; 123456789@Testpublic void testSetForVersion() throws Exception &#123; Stat status = new Stat(); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(&quot;/app1&quot;); int version = status.getVersion();//查询出来的 3 System.out.println(version); client.setData().withVersion(version).forPath(&quot;/app1&quot;, &quot;hehe&quot;.getBytes());&#125; 4.6)Zookeeper JavaAPI操作-删除节点123456789101112131415161718/*** 删除节点： delete deleteall* 1. 删除单个节点:delete().forPath(&quot;/app1&quot;);* 2. 删除带有子节点的节点:delete().deletingChildrenIfNeeded().forPath(&quot;/app1&quot;);* 3. 必须成功的删除:为了防止网络抖动。本质就是重试。 client.delete().guaranteed().forPath(&quot;/app2&quot;);* 4. 回调：inBackground* @throws Exception*/@Testpublic void testDelete() throws Exception &#123; // 1. 删除单个节点 client.delete().forPath(&quot;/app1&quot;);&#125;@Testpublic void testDelete2() throws Exception &#123; //2. 删除带有子节点的节点 client.delete().deletingChildrenIfNeeded().forPath(&quot;/app4&quot;);&#125; 12345678910111213141516@Testpublic void testDelete3() throws Exception &#123; //3. 必须成功的删除 client.delete().guaranteed().forPath(&quot;/app2&quot;);&#125;@Testpublic void testDelete4() throws Exception &#123; //4. 回调 client.delete().guaranteed().inBackground(new BackgroundCallback()&#123; @Override public void processResult(CuratorFramework client, CuratorEvent event) throws Exception &#123; System.out.println(&quot;我被删除了~&quot;); System.out.println(event); &#125; &#125;).forPath(&quot;/app1&quot;);&#125; 4.7)Zookeeper JavaAPI操作-Watch监听概述•ZooKeeper 允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。 •ZooKeeper 中引入了Watcher机制来实现了发布&#x2F;订阅功能能，能够让多个订阅者同时监听某一个对象，当一个对象自身状态变化时，会通知所有订阅者。 •ZooKeeper 原生支持通过注册Watcher来进行事件监听，但是其使用并不是特别方便 ​ 需要开发人员自己反复注册Watcher，比较繁琐。 •Curator引入了 Cache 来实现对 ZooKeeper 服务端事件的监听。 •ZooKeeper提供了三种Watcher： •NodeCache : 只是监听某一个特定的节点 •PathChildrenCache : 监控一个ZNode的子节点. •TreeCache : 可以监控整个树上的所有节点，类似于PathChildrenCache和NodeCache的组合 ![1592057429708](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592057429708.png) 4.8Zookeeper JavaAPI操作-Watch监听-NodeCache12345678910111213141516171819202122/*** 演示 NodeCache：给指定一个节点注册监听器*/@Testpublic void testNodeCache() throws Exception &#123; //1. 创建NodeCache对象 final NodeCache nodeCache = new NodeCache(client,&quot;/app1&quot;); //2. 注册监听 nodeCache.getListenable().addListener(new NodeCacheListener() &#123; @Override public void nodeChanged() throws Exception &#123; System.out.println(&quot;节点变化了~&quot;); //获取修改节点后的数据 byte[] data = nodeCache.getCurrentData().getData(); System.out.println(new String(data)); &#125; &#125;); //3. 开启监听.如果设置为true，则开启监听是，加载缓冲数据 nodeCache.start(true); while (true)&#123; &#125;&#125; 4.9)Zookeeper JavaAPI操作-Watch监听-PathChildrenCache12345678910111213141516171819202122232425@Testpublic void testPathChildrenCache() throws Exception &#123; //1.创建监听对象 PathChildrenCache pathChildrenCache = new PathChildrenCache(client,&quot;/app2&quot;,true); //2. 绑定监听器 pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123; System.out.println(&quot;子节点变化了~&quot;); System.out.println(event); //监听子节点的数据变更，并且拿到变更后的数据 //1.获取类型 PathChildrenCacheEvent.Type type = event.getType(); //2.判断类型是否是update if(type.equals(PathChildrenCacheEvent.Type.CHILD_UPDATED))&#123; System.out.println(&quot;数据变了！！！&quot;); byte[] data = event.getData().getData(); System.out.println(new String(data)); &#125; &#125; &#125;); //3. 开启 pathChildrenCache.start(); while (true)&#123; &#125;&#125; 4.10)Zookeeper JavaAPI操作-Watch监听-TreeCache1234567891011121314151617181920/*** 演示 TreeCache：监听某个节点自己和所有子节点们*/@Testpublic void testTreeCache() throws Exception &#123; //1. 创建监听器 TreeCache treeCache = new TreeCache(client,&quot;/app2&quot;); //2. 注册监听 treeCache.getListenable().addListener(new TreeCacheListener() &#123; @Override public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception &#123; System.out.println(&quot;节点变化了&quot;); System.out.println(event); &#125; &#125;); //3. 开启 treeCache.start(); while (true)&#123; &#125;&#125; 4.11)Zookeeper分布式锁-概念•在我们进行单机应用开发，涉及并发同步的时候，我们往往采用synchronized或者Lock的方式来解决多线程间的代码同步问题，这时多线程的运行都是在同一个JVM之下，没有任何问题。 •但当我们的应用是分布式集群工作的情况下，属于多JVM下的工作环境，跨JVM之间已经无法通过多线程的锁解决同步问题。 •那么就需要一种更加高级的锁机制，来处理种跨机器的进程之间的数据同步问题——这就是分布式锁。 ![1592057871141](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592057871141.png) 4.12)Zookeeper 分布式锁-zookeeper分布式锁原理•核心思想：当客户端要获取锁，则创建节点，使用完锁，则删除该节点。 1.客户端获取锁时，在lock节点下创建临时顺序节点。 2.然后获取lock下面的所有子节点，客户端获取到所有的子节点之后，如果发现自己创建的子节点序号最小，那么就认为该客户端获取到了锁。使用完锁后，将该节点删除。 3.如果发现自己创建的节点并非lock所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，同时对其注册事件监听器，监听删除事件。 4.如果发现比自己小的那个节点被删除，则客户端的 ​ Watcher会收到相应通知，此时再次判断自己创建的节点 ​ 是否是lock子节点中序号最小的，如果是则获取到了锁， ​ 如果不是则重复以上步骤继续获取到比自己小的一个节点 ​ 并注册监听。 ![1592057925831](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592057925831.png) 4.13)Zookeeper 分布式锁-模拟12306售票案例Curator实现分布式锁API 在Curator中有五种锁方案： InterProcessSemaphoreMutex：分布式排它锁（非可重入锁） InterProcessMutex：分布式可重入排它锁 InterProcessReadWriteLock：分布式读写锁 InterProcessMultiLock：将多个锁作为单个实体管理的容器 InterProcessSemaphoreV2：共享信号量 ![1592058017457](D:&#x2F;BaiduNetdiskDownload&#x2F;黑马微服务&#x2F;5.Zookeeper【海量资源尽在 】&#x2F;21-Zookeeper&#x2F;讲义&#x2F;assets&#x2F;1592058017457.png) 1,创建线程进行加锁设置 12345678910111213141516171819202122232425262728public class Ticket12306 implements Runnable&#123; private int tickets = 10;//数据库的票数 private InterProcessMutex lock ; @Override public void run() &#123; while(true)&#123; //获取锁 try &#123; lock.acquire(3, TimeUnit.SECONDS); if(tickets &gt; 0)&#123; System.out.println(Thread.currentThread()+&quot;:&quot;+tickets); Thread.sleep(100); tickets--; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; //释放锁 try &#123; lock.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 2,创建连接，并且初始化锁 123456789101112131415public Ticket12306()&#123; //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(&quot;192.168.149.135:2181&quot;) .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) .build(); //开启连接 client.start(); lock = new InterProcessMutex(client,&quot;/lock&quot;);&#125; 3,运行多个线程进行测试 12345678910public class LockTest &#123; public static void main(String[] args) &#123; Ticket12306 ticket12306 = new Ticket12306(); //创建客户端 Thread t1 = new Thread(ticket12306,&quot;携程&quot;); Thread t2 = new Thread(ticket12306,&quot;飞猪&quot;); t1.start(); t2.start(); &#125;&#125; 5)ZooKeeper 集群搭建5.1)Zookeeper集群介绍Leader选举： •Serverid：服务器ID 比如有三台服务器，编号分别是1,2,3。 编号越大在选择算法中的权重越大。 •Zxid：数据ID 服务器中存放的最大数据ID.值越大说明数据 越新，在选举算法中数据越新权重越大。 •在Leader选举的过程中，如果某台ZooKeeper ​ 获得了超过半数的选票， ​ 则此ZooKeeper就可以成为Leader了。 5.2)搭建要求真实的集群是需要部署在不同的服务器上的，但是在我们测试时同时启动很多个虚拟机内存会吃不消，所以我们通常会搭建伪集群，也就是把所有的服务都搭建在一台虚拟机上，用端口进行区分。 我们这里要求搭建一个三个节点的Zookeeper集群（伪集群）。 5.3)准备工作重新部署一台虚拟机作为我们搭建集群的测试服务器。 （1）安装JDK 【此步骤省略】。 （2）Zookeeper压缩包上传到服务器（3）将Zookeeper解压 ，建立&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster目录，将解压后的Zookeeper复制到以下三个目录 &#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-1 &#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-2 &#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-3 1234[root@localhost ~]# mkdir /usr/local/zookeeper-cluster[root@localhost ~]# cp -r apache-zookeeper-3.5.6-bin /usr/local/zookeeper-cluster/zookeeper-1[root@localhost ~]# cp -r apache-zookeeper-3.5.6-bin /usr/local/zookeeper-cluster/zookeeper-2[root@localhost ~]# cp -r apache-zookeeper-3.5.6-bin /usr/local/zookeeper-cluster/zookeeper-3 （4）创建data目录 ，并且将 conf下zoo_sample.cfg 文件改名为 zoo.cfg 1234567mkdir /usr/local/zookeeper-cluster/zookeeper-1/datamkdir /usr/local/zookeeper-cluster/zookeeper-2/datamkdir /usr/local/zookeeper-cluster/zookeeper-3/datamv /usr/local/zookeeper-cluster/zookeeper-1/conf/zoo_sample.cfg /usr/local/zookeeper-cluster/zookeeper-1/conf/zoo.cfgmv /usr/local/zookeeper-cluster/zookeeper-2/conf/zoo_sample.cfg /usr/local/zookeeper-cluster/zookeeper-2/conf/zoo.cfgmv /usr/local/zookeeper-cluster/zookeeper-3/conf/zoo_sample.cfg /usr/local/zookeeper-cluster/zookeeper-3/conf/zoo.cfg （5） 配置每一个Zookeeper 的dataDir 和 clientPort 分别为2181 2182 2183 修改&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-1&#x2F;conf&#x2F;zoo.cfg 1234vim /usr/local/zookeeper-cluster/zookeeper-1/conf/zoo.cfgclientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-1/data 修改&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-2&#x2F;conf&#x2F;zoo.cfg 1234vim /usr/local/zookeeper-cluster/zookeeper-2/conf/zoo.cfgclientPort=2182dataDir=/usr/local/zookeeper-cluster/zookeeper-2/data 修改&#x2F;usr&#x2F;local&#x2F;zookeeper-cluster&#x2F;zookeeper-3&#x2F;conf&#x2F;zoo.cfg 1234vim /usr/local/zookeeper-cluster/zookeeper-3/conf/zoo.cfgclientPort=2183dataDir=/usr/local/zookeeper-cluster/zookeeper-3/data 5.4)配置集群（1）在每个zookeeper的 data 目录下创建一个 myid 文件，内容分别是1、2、3 。这个文件就是记录每个服务器的ID 123echo 1 &gt;/usr/local/zookeeper-cluster/zookeeper-1/data/myidecho 2 &gt;/usr/local/zookeeper-cluster/zookeeper-2/data/myidecho 3 &gt;/usr/local/zookeeper-cluster/zookeeper-3/data/myid （2）在每一个zookeeper 的 zoo.cfg配置客户端访问端口（clientPort）和集群服务器IP列表。 集群服务器IP列表如下 1234567vim /usr/local/zookeeper-cluster/zookeeper-1/conf/zoo.cfgvim /usr/local/zookeeper-cluster/zookeeper-2/conf/zoo.cfgvim /usr/local/zookeeper-cluster/zookeeper-3/conf/zoo.cfgserver.1=192.168.149.135:2881:3881server.2=192.168.149.135:2882:3882server.3=192.168.149.135:2883:3883 解释：server.服务器ID&#x3D;服务器IP地址：服务器之间通信端口：服务器之间投票选举端口 5.5)启动集群启动集群就是分别启动每个实例。 123/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh start/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh start/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh start 启动后我们查询一下每个实例的运行状态 123/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh status/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh status/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh status 先查询第一个服务 Mode为follower表示是跟随者（从） 再查询第二个服务Mod 为leader表示是领导者（主） 查询第三个为跟随者（从） 5.6)模拟集群异常（1）首先我们先测试如果是从服务器挂掉，会怎么样 把3号服务器停掉，观察1号和2号，发现状态并没有变化 1234/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh stop/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh status/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh status 由此得出结论，3个节点的集群，从服务器挂掉，集群正常 （2）我们再把1号服务器（从服务器）也停掉，查看2号（主服务器）的状态，发现已经停止运行了。 123/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh stop/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh status 由此得出结论，3个节点的集群，2个从服务器都挂掉，主服务器也无法运行。因为可运行的机器没有超过集群总数量的半数。 （3）我们再次把1号服务器启动起来，发现2号服务器又开始正常工作了。而且依然是领导者。 123/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh start/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh status （4）我们把3号服务器也启动起来，把2号服务器停掉,停掉后观察1号和3号的状态。 12345/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh start/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh stop/usr/local/zookeeper-cluster/zookeeper-1/bin/zkServer.sh status/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh status 发现新的leader产生了~ 由此我们得出结论，当集群中的主服务器挂了，集群中的其他服务器会自动进行选举状态，然后产生新得leader （5）我们再次测试，当我们把2号服务器重新启动起来启动后，会发生什么？2号服务器会再次成为新的领导吗？我们看结果 1234/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh start/usr/local/zookeeper-cluster/zookeeper-2/bin/zkServer.sh status/usr/local/zookeeper-cluster/zookeeper-3/bin/zkServer.sh status 我们会发现，2号服务器启动后依然是跟随者（从服务器），3号服务器依然是领导者（主服务器），没有撼动3号服务器的领导地位。 由此我们得出结论，当领导者产生后，再次有新服务器加入集群，不会影响到现任领导者。 6)Zookeeper 核心理论Zookeepe集群角色 在ZooKeeper集群服中务中有三个角色： •Leader 领导者 ： ​ 1. 处理事务请求 ​ 2. 集群内部各服务器的调度者 •Follower 跟随者 ： ​ 1. 处理客户端非事务请求，转发事务请求给Leader服务器 ​ 2. 参与Leader选举投票 •Observer 观察者： 1. 处理客户端非事务请求，转发事务请求给Leader服务器 Spring Cloud高级特性 Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和 反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持： HttpClient OkHttp JDK原生的URLConnection（默认的） RestTemplate的使用1234567import org.springframework.web.client.RestTemplate;//注册bean//使用方法 发动请求,接收响应,并且帮我们对响应结果进行反序列化String url = &quot;http://localhost/user/8&quot;;User user = restTemplate.getForObject(url, User.class);System.out.println(user); Spring Cloud 实践1 编写消费者和生产者(无注册中心)生产者:常规后端 ​ spring boot应用, entity,service实现增删改查业务,controller接收请求调用业务进行处理,返回给请求者 消费者:简单controller使用restT请求生产者 网页访问消费者,消费者通过resttemplate(硬编码)请求生产者 存在的问题 url硬编码 如果变更,得不到通知地址将失效,不清楚服务状态,服务宕机也不知道 (采用注册中心对服务进行治理 ​ 自动注册和发现 ​ 服务注册到注册中心(服务类型,联系方式) ​ 消费者向服务中心订阅服务,选择服务类型,注册中心自动安排一个符合需求的服务 ​ 状态监管 “心跳(续约)机制” 定期通过http向Eureka刷新自己的状态 ​ 动态路由 一台生产者不具备高可用(集群解决,如何实现负载均衡) 容灾问题 服务如何实现统一配置 实践2 搭建Eureka-server工程Eureka注册中心EurekaServer主要功能:检查那些没有定期发送心跳的,记录服务, 自我保护机制(todo) EurekaClient主要功能: 从Server拉取服务列表,基于负载均衡算法对远程服务进行调用,定时续约, 设置剔除时间(?) 搭建 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; 添加Eureka的服务注解 @EnableEurekaServer 开启服务发现功能 编写配置 服务名,服务端口号 eureka客户端配置 service-url: defaultZone register-with-eureka: 是否注册 默认true fetch-registry: 是否拉取服务 默认true 123456789101112131415server: port: 10086spring: application: name: eureka-servereureka: client: service-url: # eureka 服务地址，如果是集群的话；需要指定其它集群eureka地址 defaultZone: http://127.0.0.1:10086/eureka # 不注册自己 register-with-eureka: false # 不拉取服务 fetch-registry: false 启动测试 依赖是~client 客户端的注解是@EnableDiscoveryClient 客户端常用配置: 续约间隔 服务失效时间 获取服务地址列表间隔时间 Eureka配置123456789101112131415import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;//在启动类添加 @EnableEurekaServer*** //编写配置文件 //网页端口 //应用名称 eureka-server(作为服务的id表示 serviceID) eureka:client:service-url: # EurekaServer的地址，现在是自己的地址，如果是集群，需要写其它Server的地址。defaultZone: http://127.0.0.1:10086/eurekaregister-with-eureka: false # 不注册自己fetch-registry: false #不拉取启动服务 服务注册生产者添加eureka依赖 123456启动类添加@EnabeDiscoveryClient开启Eureka客户端功能 //修改配置 eureka:client:service-url:defaultZone: http://localhost:10086/eureka 服务发现消费者 添加依赖 修改启动类和配置(同生产者) 修改处理器 123456789String url = &quot;http://localhost:9091/user/&quot; + id;//获取eureka中注册的user-service实例列表List&lt;ServiceInstance&gt; serviceInstanceList =discoveryClient.getInstances(&quot;user-service&quot;);ServiceInstance serviceInstance = serviceInstanceList.get(0);url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort()+ &quot;/user/&quot; + id;return restTemplate.getForObject(url, User.class); 服务者从注册中心获取服务列表,从而得知每个服务方的信息, Eureka可以是集群,形成高可用 多个之间互相注册服务,有注册时,会同步到每个节点 三个的集群注册规则 ​ 10086要注册到10087和10088上 ​ 10087要注册到10086和10088上 ​ 10088要注册到10086和10087上 实践3 搭建Eureka集群多机集群 只需要区分IP 端口号可相同 在本机模拟 在启动时修改VM options defaultzone复制个项目 修改端口号启动多个服务 客户端注册 添加注册(???不应该还是注册到一个中心,中心间相互数据同步吗) 1234eureka:client:service-url: # EurekaServer地址,多个地址以&#x27;,&#x27;隔开defaultZone: http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eureka 生产者会向Eureka服务发起一个Rest请求,并携带自己的元数据信息,Eureka 将信息保存到双层map 1Map&lt;name(服务ID),Map&lt;localhost:user-service:8081(实例ID), &gt; &gt; 默认注册使用主机名或localHost 如果想用ip注册 12345//生产者中eureka:instance:ip-address: 127.0.0.1 # ip地址prefer-ip-address: true # 更倾向于使用ip，而不是host名 服务续约 1234eureka:instance:lease-expiration-duration-in-seconds: 90 lease-renewal-interval-in-seconds: 30 服务失效 默认 90s 认为服务宕机 从服务列表中移除 心跳 30s一次 获取服务列表 当服务消费者启动时，会检测 eureka.client.fetch-registry&#x3D;true 参数的值，如果为true，则会从Eureka Server服务的列表拉取只读备份，然后缓存在本地。并且 每隔30秒 会重新拉取并更新数据。可以在 consumer-demo 项目中通过下面的参数来修改： 123eureka:client:registry-fetch-interval-seconds: 30 失效剔除和自我保护 服务下线 当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线 了”。服务中心接受到请求之后，将该服务置为下线状态 失效剔除 有时我们的服务可能由于内存溢出或网络故障等原因使得服务不能正常的工作，而服务注册中心并未收到“服务下 线”的请求。相对于服务提供者的“服务续约”操作，服务注册中心在启动时会创建一个定时任务，默认每隔一段时间 （默认为60秒）将当前清单中超时（默认为90秒）没有续约的服务剔除，这个操作被称为失效剔除。 可以通过 eureka.server.eviction-interval-timer-in-ms 参数对其进行修改，单位是毫秒。 自我保护 当服务未按时进行心跳续约时，Eureka会统计服务实例最近15分钟心跳续约的 比例是否低于了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务 剔除列表并不妥当，因为服务可能没有宕机。Eureka在这段时间内不会剔除任何服务实例，直到网络恢复正常。生 产环境下这很有效，保证了大多数服务依然可用，不过也有可能获取到失败的服务实例，因此服务调用者必须做好服 务的失败容错。 可以通过下面的配置来关停自我保护： 123eureka:server:enable-self-preservation: false # 关闭自我保护模式（缺省为打开） 实践4 负载均衡Ribbon在实际环境中往往会开启很多个 user-service的集群,此时discoveryClient 获取的服务列表有多个,到底该访问哪一个呢 ​ 负载均衡算法就是在多个实例列表中进行选择 Eureka中集成了 ribbon 简单修改代码即可(提供例如轮询(默认),随机等) 1.首先 配置两个 user-service实例 启动两个,动态设置启动端口号 2.在RestTemplate的bean方法上添加 @LoadBalanced注解 3.不再手动获取IP和端口 而是直接通过服务名称调用 123456@GetMapping(&quot;&#123;id&#125;&quot;)public User queryById(@PathVariable(&quot;id&quot;) Long id)&#123;String url = &quot;http://user-service/user/&quot; + id;User user = restTemplate.getForObject(url, User.class);return user;&#125; 默认轮询,boot提供修改负载均衡配置入口 在消费者中加 1234user-service:ribbon:NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 实验5 熔断器Hystrix 服务降级延迟和容错库,用于隔离访问远程访问,第三方库,防止出现级联失败 雪崩问题:微服务间一个请求可能需要调用多个微服务接口才能实现 如果某个服务异常,请求不会得到响应,则tomcat的这个线程不会释放,于是越来越多的用户到来,越来越多的线程阻塞,导致服务器资源耗尽,其他所有服务都不可用,形成雪崩效应,一个微服务的阻塞导致整个服务的瘫痪 熔断器Hystrix的解决手段: 线程隔离 为每个依赖服务调用分配一个小的线程池 如果线程池已满调用将被立即拒绝,默认不采用排队,加速失败判定时间 服务降级 如果线程池满,或请求超时会进行服务降级:优先保证核心服务,非核心不可用或弱可用 服务熔断 断开服务,防止整个系统被拖垮 1.添加依赖 2.启动类开启熔断 @EnableCircuitBreaker 123456组合注解@SpringCloudApplication @SpringBootApplication @EnableDiscoveryClient @EnableCircuitBreaker 3.编写降级逻辑 1234567891011121314151617181920212223242526272829303132333435363738394041package com.itheima.consumer.controller;import com.itheima.consumer.pojo.User;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.discovery.DiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import java.util.List;@RestController@RequestMapping(&quot;/consumer&quot;)@Slf4jpublic class ConsumerController &#123;@Autowiredprivate RestTemplate restTemplate;@Autowiredprivate DiscoveryClient discoveryClient;@GetMapping(&quot;&#123;id&#125;&quot;)@HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;)public String queryById(@PathVariable Long id)&#123;String url = &quot;http://localhost:9091/user/&quot; + id;//获取eureka中注册的user-service实例列表/*List&lt;ServiceInstance&gt; serviceInstanceList =discoveryClient.getInstances(&quot;user-service&quot;);ServiceInstance serviceInstance = serviceInstanceList.get(0);url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort()+ &quot;/user/&quot; + id;*/url = &quot;http://user-service/user/&quot; + id;return restTemplate.getForObject(url, String.class);&#125;public String queryByIdFallback(Long id)&#123;log.error(&quot;查询用户信息失败。id：&#123;&#125;&quot;, id);return &quot;对不起，网络太拥挤了！&quot;; //相同的参数列表和返回值声明&#125;&#125; 不写方法 默认fallbcak 实践6 服务熔断熔断器三个状态 关闭 所有请求正常访问 打开 所有请求都会被降级 ,请求次数不低于20次 失败比例 到达一半 触发熔断 半开 熔断器打开后会计时5s转为此状态(半开),释放部分请求,若都是健康的则关闭,否则保持打开,再次进行5s计时 源码阅读 配置 todo 实践7 Feigh(伪装)把rest的请求进行隐藏,伪装成类似springMVC的controller一样 不用自己拼接url参数等等,一切交给Feign 1234567891011package com.itheima.consumer.client;import com.itheima.consumer.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(&quot;user-service&quot;)public interface UserClient &#123;@GetMapping(&quot;/user/&#123;id&#125;&quot;)User queryById(@PathVariable(&quot;id&quot;) Long id);&#125; 首先这是一个接口 feign会通过动态代理,帮我们生成实现类,跟mybatis的mapper很像 编写新的控制器类 1234567891011121314151617181920package com.itheima.consumer.controller;import com.itheima.consumer.client.UserClient;import com.itheima.consumer.pojo.User;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(&quot;/cf&quot;)public class ConsumerFeignController &#123;@Autowiredprivate UserClient userClient;@GetMapping(&quot;/&#123;id&#125;&quot;)public User queryById(@PathVariable Long id)&#123;return userClient.queryById(id);&#125;&#125; 在启动类开启feign功能 @EnableFeignClients 可以开启请求压缩 gzip减少通信过程中的性能损耗 123456feign:compression:request:enabled: true # 开启请求压缩response:enabled: true # 开启响应压缩 1234567feign:compression:request:enabled: true # 开启请求压缩mime-types: text/html,application/xml,application/json # 设置压缩的数据类型min-request-size: 2048 # 设置触发压缩的大小下限//默认 日志级别(了解)123logging:level:com.itheima: debug 12345678910111213141516package com.itheima.consumer.config;import feign.Logger;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FeignConfig &#123;@BeanLogger.Level feignLoggerLevel()&#123;//记录所有请求和响应的明细，包括头信息、请求体、元数据return Logger.Level.FULL; /*NONE：不记录任何日志信息，这是默认值。BASIC：仅记录请求的方法，URL以及响应状态码和执行时间HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。*/&#125;&#125; 观察日志 实践8 Gateway替代 netflix zuul核心是一系列的过滤器,通过这些过滤器可以将客户端发送的请求转发(路由)到对应微服务,是加在整个微服务最前沿的防火墙和代理器,隐藏微服务结点IP端口信息,从而加强安全保护,本身也是一个微服务,需要注册到中心 核心功能: ​ 路由:路由信息的组成:由一个ID,一个目的URL,一组断言工厂,一组Filter组成 如果路由断言为真,说明请求URL和配置路由匹配 ​ 断言: 网关中的断言函数输入类型是Spring5.0中的 ServerWebExchange,断言函数允许开发者去定义匹配来自于Http request中的任何信息比如请求头和参数 ​ 过滤器: 标准 spring WebFilter 网关中有两种filter 分别是 网关过滤器和 全局过滤器,过滤器将会对请求和响应进行修改处理 快速入门 创建项目(模块Maven) 1.引入依赖123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;&lt;parent&gt;&lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;&lt;groupId&gt;com.itheima&lt;/groupId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.itheima&lt;/groupId&gt;&lt;artifactId&gt;heima-gateway&lt;/artifactId&gt;&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt; 2.编写启动类123456789101112package com.itheima.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class GatewayApplication &#123;public static void main(String[] args) &#123;SpringApplication.run(GatewayApplication.class, args);&#125;&#125; 3.编写配置1234567891011server:port: 10010spring:application:name: api-gatewayeureka:client:service-url:defaultZone: http://127.0.0.1:10086/eurekainstance:prefer-ip-address: true 4.编写路由规则需要用网关来代理 User-service 看下当前 状态 修改网关配置 123456789101112131415161718192021server:port: 10010spring:application:name: api-gatewaycloud:gateway:routes:# 路由id，可以随意写- id: user-service-route# 代理的服务地址uri: http://127.0.0.1:9091# 路由断言，可以配置映射路径predicates:- Path=/user/** #将符合Path规则的一切请求都代理到uri参数指定的地址eureka:client:service-url:defaultZone: http://127.0.0.1:10086/eurekainstance:prefer-ip-address: true 5.启动测试 spring cloud config通过修改git中的配置文件实现所有微服务的配置文件的修改 添加配置中心依赖 配置 1234567891011121314server: port: 12000spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/goheima/heima-config.giteureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 修改service 删除application 创建 bootstrap.yml 12345678910111213141516171819spring: cloud: config: # 要与仓库中的配置文件的application保持一致 name: user # 要与仓库中的配置文件的profile保持一致 profile: dev # 要与仓库中的配置文件所属的版本（分支）一样 label: master discovery: # 使用配置中心 enabled: true # 配置中心服务名 service-id: config-servereureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka BusSpring Cloud Bus作用：将git仓库的配置文件更新，在不重启系统的情况下实现及时同步到各个微服务 Spring Cloud AlibabaSpring Cloud Alibaba 官方文档note 弹簧靴 &#x3D;&#x3D; spring boot 春云 &#x3D;&#x3D; spring cloud 概述Spring Cloud Alibaba 提供分布式应用开发的一站式解决方案。它包含开发分布式应用程序所需的所有组件，使您可以轻松地使用 Spring Cloud 开发应用程序。 使用 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，即可将 Spring Cloud 应用连接到阿里巴巴的分布式解决方案，并通过阿里巴巴中间件构建分布式应用系统。 特征春云 流量控制和服务降级： Alibaba Sentinel的流量控制、断路和系统自适应保护 服务注册与发现：实例可以注册到阿里巴巴的 Nacos，客户端可以通过 Spring 管理的 bean 发现实例。通过 Spring Cloud Netflix 支持客户端负载均衡器 Ribbon 分布式配置：使用阿里巴巴Nacos作为数据存储 事件驱动：构建与Spring Cloud Stream RocketMQ Binder连接的高度可扩展的事件驱动微服务 Message Bus : 用 Spring Cloud Bus RocketMQ 链接分布式系统的节点 Distributed Transaction ：支持Seata高性能、易用的分布式事务解决方案 Dubbo RPC ：通过Apache Dubbo RPC扩展Spring Cloud service-to-service调用的通信协议 弹簧靴所有的 Spring Boot Starter 都在阿里云 Spring Boot Project中维护。 阿里云对象存储服务Spring Boot Starter 阿里云短信服务Spring Boot Starter 阿里云 Redis的 Spring Boot Starter 阿里云RDS MySQL的Spring Boot Starter 阿里云 SchedulerX的 Spring Boot Starter 入门最简单的入门方法是包含 Spring Cloud BOM，然后添加spring-cloud-alibaba-dependencies到应用程序的类路径中。如果您不想包含所有 Spring Cloud Alibaba 功能，您可以为您想要的功能添加单独的启动器。 spring-cloud-alibaba-dependenciespom中的依赖： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;&#123;project-version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;复制 如果你想为阿里云服务使用 Spring Boot Starters，你应该将 Aliyun Spring Boot BOM 添加到你的 pom.xml 中： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;aliyun-spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;&#123;project-version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; nacossentinelseataNginx","categories":[{"name":"微服务","slug":"微服务","permalink":"https://gouguoqiang.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://gouguoqiang.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"JUC","slug":"all/8JUC","date":"2022-10-09T03:36:23.000Z","updated":"2022-10-09T13:57:11.071Z","comments":true,"path":"2022/10/09/all/8JUC/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/09/all/8JUC/","excerpt":"","text":"多线程一创建Thread类（子类）的对象1 定义Thread类的子类123456789101112131415161718Public class MyThread extends Thread&#123;@Overridepublic void run()&#123; System.out.println(&quot;重写Thread父类中的run（）&quot;);&#125;public class Test &#123; public static void main(String[] args)&#123; System.out.println(&quot;JVM启动main线程，main线程执行main方法&quot;); MyThread thread = new MyThread(); thread.start(); //启动线程的实质是请求将JVM运行相应的线程，这个线程具体在什么时候运行由（Scheduler）线程调度器来决定 //start（）方法调用结束不意味着子线程开始运行 //新开启的线程会执行run（）方法 &#125;&#125; 2，当Thread已经有子类了，就不能用第一种方式了 可以使用实现Runnable接口的形式123456789101112131415161718192021222324public class MyRunnable implements Runnable&#123; //重写Runnable接口中的抽象方法 run（），run()方法就是子线程要执行的代码 @Override public void run()&#123; System.out.println(&quot;必须通过线程start开启&quot;); &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; MyRunnable runnable = new MyRunnable(); Thread thread = new Thread(runnable); thread.start(); // Thread(Runnable) 实参可以是匿名内部类对象（不需要变量名） Thread tread2 = new Thread(new Runnable()&#123; @Override public void run()&#123; //.... &#125; &#125;); thread2.start(); &#125; &#125; 线程常用方法1.Thread.currentThread() 类方法 获得当前进程， Java中任何一段代码都是执行在某个线程中的，执行当前代码的线程就是当前线程 ，返回的是在代码实际运行时候的线程 2.thread.setName(线程名称） 设置线程名称 对象方法thread.getName() 返回线程名称通过设置线程名称有助于程序调试，提高可读性 3.thread.isAlive() 判断线程是否处于活动状态 活动状态就是线程以启动且尚未终止 4.Thread.sleep(millis) 让当前线程休眠指定的毫秒数（currentThread返回的线程） 5.thread.getId()可以活的线程的唯一标识，某个编号的现成运行结束后，该编号可能被后续创建的线程使用，重启JVM后同一个线程的编号可能不一样 6.Thread.yield()方法的作用是放弃当前的CPU资源 7.thread.setPriority(num) ;设置线程的优先级Java的线程优先级取值范围是1~10 如果超出这个范围会抛出异常8.illegalArgumentException(非法参数异常）线程优先具有继承性，在线程A创建了线程B 则B线程的优先级与A线程是一样的 9.thread.interrupt() &#x2F;&#x2F;仅是给线程标记中断 线程有thread.isInterrupted()方法，该方法返回线程的中断标志 true or false 10.thread.setDaemon()设置守护线程 守护线程是为其他线程提供服务的线程，如GC就是一个典型的守护线程，守护线程不能单独运行，当JVM中没有其他用户线程，只有守护线程，守护线程会自动销毁，JVM会退出 设置守护线程应该在线程启动之前 12345678public class Test&#123; public static void main(String[] args)&#123; SubDaemonThread thread = new SubDaemonThread(); thread.setDaemon(true); //设置守护线程的代码应该在线程启动之前否则会报非法线程状态异常 thread.start(); //当main线程结束，守护线程thread也销毁了 &#125;&#125; 11.Thread.state 枚举类型可通过getState()方法获得 Java中的线程的生命周期1 NEW新建状态 在调用start（）启动之前的状态2 RUNNABLE 可运行状态 包含READY和RUNNING yield方法将RUNNABLE转为READY3 BLOCKED 线程发起阻塞的IO操作或者申请由其他线程占用的独占资源 转为阻塞满足条件转换为RUNNABLE4WAITING 等待状态 线程执行了object.wait()(可以使执行当前代码的线程等待，暂停执行，直到接到通知或被中断为止，只能由锁对象调用，调用wait（）方法当前线程会释放锁),thread.join方法（挂起调用线程的执行，直到被调用的对象完成他的执行，T1，T2，T3三个线程怎么保证按一定顺序执行， 按顺序try join 例如1-2-3 则在2中try T1.join,3中try T2.join）然后依次（代码）启动三个线程） 会把看成转为WAITING等待状态，执行object.notify() 方法 或者加入的线程执行完毕，当前线程都会转换为RUNNABLE状态5TIMED_WAITING状态，与WAITING类似 区别在于不会无限等待 如果线程没有在指定的时间范围内完成期望的操作，该线程自动转化为RUNNABLE 如sleep(long)wait(long) 6TERMINATED 终止状态 线程结束处于终止状态 多线程二CPU 内存 IO设备速度严重差异 提高效率的方式：（1）CPU增加了缓存（2）操作系统增加了进程，线程以分时复用CPU 进而均衡CPU 与iO设备的速度差异 Java采用抢占式线程调度：如果一个线程申请IO 或者申请一个被其他线程占用的资源 就会进入阻塞状态 让出CPU 待准备完成OS会把这个休眠的线程唤醒，唤醒后就有机会重新获得CPU使用权（3）编译程序优化指令顺序 这三种方式也带来了问题可见性：工作区和共享区数据更新应该立刻能被看到原子性：该操作要么已经执行完成要么尚未发生，其他线程不能得到操作的中间结果有序性：重排序可能会导致多线程程序出现非预期操作 （重排序）是对内存访问有序操作的一种优化 ：1 指令重排序 ：主要是由JIT编译器，处理器引起的，指程序顺序与执行顺序不一致 2存储子系统重排序：由高速缓存（是CPU中为了匹配与主内存处理速度不匹配而舍设计一个高速缓存），写缓冲器（用来提高高速缓存操作的效率）引起的，感知顺序与执行顺序不一致 重排序要保证单线程程序的正确性（貌似串行语义） 所以有数据依赖关系的指令不会重排 如果两个指令（操作）访问同一个变量，其中一个有写操作这两个指令就存在数据依赖关系 volatile synchronizevolatilevolatile 修饰变量关键字可以保证可见性与有序性（1）当对volatile变量执行写操作后JMM会把工作内存中的最新变量值强行刷新到主内存，写操作会导致其他线程里的缓存无效（CPU嗅探总线，主存中更改的数据地址与自己缓存对比，若一致则失效）（2） 防止指令重排 在volatile前后加上内存屏障 （各种屏障都是保证同步，简单来说在屏障之后的写操作必须等待屏障之前的写操作完成才可以执行，读操作则不受影响）缺点不具有原子性volatile的实现是轻量级的 性能优于 synchronized synchronize1 synchronized 隐性锁 依赖monitor2 每个对象会与一个monitor相关联 （1）当监视器被占用时，就会处于锁定状态，监视器的获得过程是排他的。如果某线程已经占用了监视器，则其他线程会进入阻塞状态等待锁的释放 （2）执行完成退出监视器修饰实例方法 修饰类方法 修饰代码块 （注意锁粒度） 同步器AQS底层CAS（抽象队列同步器）定义了一套多线程访问共享资源的同步器框架利用CLH队列锁实现 将获取不到线程的进程放入 JMM（Java内存模型)JVM中的共享数据可能被分配到CPU中的寄存器中，主内存RAM中若分配到寄存器中，每个CPU都有自己的 一个CPU不能读取其他CPU上的内容，如果两个线程分别运行在不同CPU上，无法看到数据的变化 CPU不直接从主存读取数据，先把RAM中数据读到Cache缓存中再把Cache的数据读到寄存器中，CPU中线程对数据更新，可能只是更新到写缓冲器，还没有到达Cache更不用说主存 分配到主存中 运行在另一个CPU中的线程无法看到共享数据的更新 CPU具有缓存同步 共享数据的更新必须被写入cache 这个过程就是冲刷处理缓存 JMM对这些进行规定 ：每个线程之间的共享数据都存储在主内存中 每个线程都有一个私有的工作内存（是一个抽象的概念，他涵盖寄存器，写缓冲器，其他硬件的优化） 每个线程从主内存中把数据读取到本地工作内存中，在工作内存中保存共享数据的副本，工作内存仅对当前线程可见 程序、进程、线程的理解 1、程序(programm)概念：是为完成特定任务、用某种语言编写的一组指令的集合。即指一段静态的代码。 2、进程(process)概念：程序的一次执行过程，或是正在运行的一个程序。说明：进程作为资源分配的单位，系统在运行时会为每个进程分配不同的内存区域 3、线程(thread)概念：进程可进一步细化为线程，是一个程序内部的一条执行路径。说明：线程作为CPU调度和执行的单位，每个线程拥独立的运行栈和程序计数器(pc)，线程切换的开销小。 补充： 进程可以细化为多个线程。每个线程，拥有自己独立的：栈、程序计数器多个线程，共享同一个进程中的结构：方法区、堆。 并行与并发单核CPU与多核CPU的理解 单核CPU，其实是一种假的多线程，因为在一个时间单元内，也只能执行一个线程的任务。例如：虽然有多车道，但是收费站只有一个工作人员在收费，只有收了费才能通过，那么CPU就好比收费人员。如果某个人不想交钱，那么收费人员可以把他“挂起”（晾着他，等他想通了，准备好了钱，再去收费。）但是因为CPU时间单元特别短，因此感觉不出来。 如果是多核的话，才能更好的发挥多线程的效率。（现在的服务器都是多核的） 一个Java应用程序java.exe，其实至少三个线程：main()主线程，gc()垃圾回收线程，异常处理线程。当然如果发生异常，会影响主线程。 并行与并发的理解并行：多个CPU同时执行多个任务。比如：多个人同时做不同的事。并发：一个CPU(采用时间片)同时执行多个任务。比如：秒杀、多个人做同一件事 创建线程的几种方法继承Thread类创建线程多线程的创建，方式一：继承于Thread类 创建一个继承于Thread类的子类 重写Thread类的run() –&gt; 将此线程执行的操作声明在run()中 创建Thread类的子类的对象 通过此对象调用start() 例子：遍历100以内的所有的偶数 123456789101112131415161718192021222324252627282930313233343536373839404142434445JAVA//1. 创建一个继承于Thread类的子类class MyThread extends Thread &#123; //2. 重写Thread类的run() @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; if(i % 2 == 0)&#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + i); &#125; &#125; &#125;&#125;public class ThreadTest &#123; public static void main(String[] args) &#123; //3. 创建Thread类的子类的对象 MyThread t1 = new MyThread(); //4.通过此对象调用start():①启动当前线程 ② 调用当前线程的run() t1.start(); //问题一：我们不能通过直接调用run()的方式启动线程。// t1.run(); /* 问题二：再启动一个线程，遍历100以内的偶数。不可以还让已经start()的线程去执行。 会报IllegalThreadStateException */ // t1.start(); //我们需要重新创建一个线程的对象 MyThread t2 = new MyThread(); t2.start(); //如下操作仍然是在main线程中执行的。 for (int i = 0; i &lt; 100; i++) &#123; if(i % 2 == 0)&#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + i + &quot;***********main()************&quot;); &#125; &#125; &#125;&#125; 实现Runnable接口创建线程1、创建多线程的方式二：实现Runnable接口 创建一个实现了Runnable接口的类 实现类去实现Runnable中的抽象方法：run() 创建实现类的对象 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象 通过Thread类的对象调用start() 2、 比较创建线程的两种方式。开发中：优先选择：实现Runnable接口的方式原因：实现的方式没有类的单继承性的局限性，实现的方式更适合来处理多个线程有共享数据的情况。 123456789101112131415161718192021222324252627282930313233343536373839JAVA//1. 创建一个实现了Runnable接口的类class MThread implements Runnable&#123; //2. 实现类去实现Runnable中的抽象方法：run() @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; if(i % 2 == 0)&#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + i); &#125; &#125; &#125;&#125;public class ThreadTest1 &#123; public static void main(String[] args) &#123; //3. 创建实现类的对象 MThread mThread = new MThread(); //4. 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象 Thread t1 = new Thread(mThread); t1.setName(&quot;线程1&quot;); /* 5. 通过Thread类的对象调用start():① 启动线程 ②调用当前线程的run()--&gt; 调用了Runnable类型的target的run() */ t1.start(); //再启动一个线程，遍历100以内的偶数 Thread t2 = new Thread(mThread); t2.setName(&quot;线程2&quot;); t2.start(); &#125;&#125; Thread和Runnable的关系联系：public class Thread implements Runnable相同点：两种方式都需要重写run(),将线程要执行的逻辑声明在run()中。 Runnable接口构造线程源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788JAVA/*下面是Thread类的部分源码*///1.用Runnable接口创建线程时会进入这个方法public Thread(Runnable target) &#123; init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0); &#125;//2.接着调用这个方法private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true); &#125;//3.再调用这个方法private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; /* Determine if it&#x27;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security doesn&#x27;t have a strong opinion of the matter use the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; /* checkAccess regardless of whether or not threadgroup is explicitly passed in. */ g.checkAccess(); /* * Do we have the required permissions? */ if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); //4.最后在这里将Runnable接口(target)赋值给Thread自己的target成员属性 this.target = target; setPriority(priority); if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); &#125;/*如果你是实现了runnable接口，那么在上面的代码中target便不会为null，那么最终就会通过重写的规则去调用真正实现了Runnable接口(你之前传进来的那个Runnable接口实现类)的类里的run方法*/@Override public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 1、多线程的设计之中，使用了代理设计模式的结构，用户自定义的线程主体只是负责项目核心功能的实现，而所有的辅助实现全部交由Thread类来处理。2、在进行Thread启动多线程的时候调用的是start()方法，而后找到的是run()方法，但通过Thread类的构造方法传递了一个Runnable接口对象的时候，那么该接口对象将被Thread类中的target属性所保存，在start()方法执行的时候会调用Thread类中的run()方法。而这个run()方法去调用实现了Runnable接口的那个类所重写过run()方法，进而执行相应的逻辑。多线程开发的本质实质上是在于多个线程可以进行同一资源的抢占，那么Thread主要描述的是线程，而资源的描述是通过Runnable完成的。如下图所示： Thread类构造线程源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384JAVAMyThread t2 = new MyThread(); //这个构造函数会默认调用Super();也就是Thread类的无参构造JAVA//代码从上往下顺序执行public Thread() &#123; init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true); &#125; private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; /* Determine if it&#x27;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security doesn&#x27;t have a strong opinion of the matter use the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; /* checkAccess regardless of whether or not threadgroup is explicitly passed in. */ g.checkAccess(); /* * Do we have the required permissions? */ if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); &#125;/*由于这里是通过继承Thread类来实现的线程，那么target这个东西就是Null。但是因为你继承了Runnable接口并且重写了run()，所以最终还是调用子类的run()*/ @Override public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 最直观的代码描述1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677JAVAclass Window extends Thread&#123; private int ticket = 100; @Override public void run() &#123; while(true)&#123; if(ticket &gt; 0)&#123; System.out.println(getName() + &quot;：卖票，票号为：&quot; + ticket); ticket--; &#125;else&#123; break; &#125; &#125; &#125;&#125;public class WindowTest &#123; public static void main(String[] args) &#123; Window t1 = new Window(); Window t2 = new Window(); Window t3 = new Window(); t1.setName(&quot;窗口1&quot;); t2.setName(&quot;窗口2&quot;); t3.setName(&quot;窗口3&quot;); t1.start(); t2.start(); t3.start(); &#125;&#125;JAVAclass Window1 implements Runnable&#123; private int ticket = 100; @Override public void run() &#123; while(true)&#123; if(ticket &gt; 0)&#123; System.out.println(Thread.currentThread().getName() + &quot;:卖票，票号为：&quot; + ticket); ticket--; &#125;else&#123; break; &#125; &#125; &#125;&#125;public class WindowTest1 &#123; public static void main(String[] args) &#123; Window1 w = new Window1(); Thread t1 = new Thread(w); Thread t2 = new Thread(w); Thread t3 = new Thread(w); t1.setName(&quot;窗口1&quot;); t2.setName(&quot;窗口2&quot;); t3.setName(&quot;窗口3&quot;); t1.start(); t2.start(); t3.start(); &#125;&#125; 1、继承Thread类的方式，new了三个Thread，实际上是有300张票。 2、实现Runnable接口的方式，new了三个Thread，实际上是有100张票。 3、也就是说实现Runnable接口的线程中，成员属性是所有线程共有的。但是继承Thread类的线程中，成员属性是各个线程独有的，其它线程看不到，除非采用static的方式才能使各个线程都能看到。 4、就像上面说的Runnable相当于资源，Thread才是线程。用Runnable创建线程时，new了多个Thread，但是传进去的参数都是同一个Runnable（资源）。用Thread创建线程时，就直接new了多个线程，每个线程都有自己的Runnable（资源）。在Thread源码中就是用target变量（这是一个Runnable类型的变量）来表示这个资源。 5、同时因为这两个的区别，在并发编程中，继承了Thread的子类在进行线程同步时不能将成员变量当做锁，因为多个线程拿到的不是同一把锁，不过用static变量可以解决这个问题。而实现了Runnable接口的类在进行线程同步时没有这个问题。 实现Callable接口创建线程123456789101112131415161718192021JAVA//Callable实现多线程class MyThread implements Callable&lt;String&gt; &#123;//线程的主体类 @Override public String call() throws Exception &#123; for (int x = 0; x &lt; 10; x++) &#123; System.out.println(&quot;*******线程执行，x=&quot; + x + &quot;********&quot;); &#125; return &quot;线程执行完毕&quot;; &#125;&#125;public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(new MyThread()); new Thread(task).start(); System.out.println(&quot;线程返回数据&quot; + task.get()); &#125;&#125; Callable最主要的就是提供带有返回值的call方法来创建线程。不过Callable要和Future实现类连着用，关于Future的一系列知识会在后面几个系列讲到。 策略模式在Thread和Runnable中的应用Runnable接口最重要的方法—–run方法，使用了策略者模式将执行的逻辑(run方法)和程序的执行单元(start0方法)分离出来，使用户可以定义自己的程序处理逻辑，更符合面向对象的思想。 Thread的构造方法 创建线程对象Thread，默认有一个线程名，以Thread-开头，从0开始计数，如“Thread-0、Thread-1、Thread-2 …” 如果没有传递Runnable或者没有覆写Thread的run方法，该Thread不会调用任何方法 如果传递Runnable接口的实例或者覆写run方法，则会执行该方法的逻辑单元（逻辑代码） 如果构造线程对象时，未传入ThreadGroup，Thread会默认获取父线程的ThreadGroup作为该线程的ThreadGroup，此时子线程和父线程会在同一个ThreadGroup中 stackSize可以提高线程栈的深度，放更多栈帧，但是会减少能创建的线程数目 stackSize默认是0，如果是0，代表着被忽略，该参数会被JNI函数调用，但是注意某些平台可能会失效，可以通过“-Xss10m”设置 具体的介绍可以看Java的API文档 123456789101112131415161718192021222324252627282930313233343536JAVA/*下面是Thread 的部分源码*/public Thread(Runnable target) &#123; init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(String name) &#123; init(null, null, name, 0);&#125; ↓ ↓ ↓ ↓ ↓ ↓ private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true);&#125; ↓ ↓ ↓ ↓ ↓ ↓ private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; //中间源码省略 this.target = target;//①&#125;/* What will be run. */private Runnable target; //Thread类中的target属性@Overridepublic void run() &#123; if (target != null) &#123; //② target.run(); &#125;&#125; 源码标记解读： 1、如果Thread类的构造方法传递了一个Runnable接口对象 ①那么该接口对象将被Thread类中的target属性所保存。 ②在start()方法执行的时候会调用Thread类中的run()方法。因为target不为null， target.run()就去调用实现Runnable接口的子类重写的run()。 2、如果Thread类的构造方传没传Runnable接口对象 ①Thread类中的target属性保存的就是null。 ②在start()方法执行的时候会调用Thread类中的run()方法。因为target为null，只能去调用继承Thread的子类所重写的run()。 JVM一旦启动，虚拟机栈的大小已经确定了。但是如果你创建Thread的时候传了stackSize（该线程占用的stack大小），该参数会被JNI函数去使用。如果没传这个参数，就默认为0，表示忽略这个参数。注：stackSize在有一些平台上是无效的。 start()源码12345678910111213141516171819202122232425262728293031323334JAVApublic synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException();//① group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125;&#125;private native void start0();@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 源码标记解读： ①当多次调用start()，会抛出throw new IllegalThreadStateException()异常。也就是每一个线程类的对象只允许启动一次，如果重复启动则就抛出此异常。 为什么线程的启动不直接使用run()而必须使用start()呢?1、如果直接调用run()方法，相当于就是简单的调用一个普通方法。 2、run()的调用是在start0()这个Native C++方法里调用的 线程生命周期Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态，这几个状态在Java源码中用枚举来表示。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示。 图中 wait到 runnable状态的转换中，join实际上是Thread类的方法，但这里写成了Object。 1、由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。 2、操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。 3、调用sleep()方法，会进入Blocked状态。sleep()结束之后，Blocked状态首先回到的是Runnable状态中的Ready（也就是可运行状态，但并未运行）。只有拿到了cpu的时间片才会进入Runnable中的Running状态。 Thread常用API 获取当前存活的线程数：public int activeCount() 获取当前线程组的线程的集合：public int enumerate(Thread[] list) 一个Java程序有哪些线程？1、当你调用一个线程start()方法的时候，此时至少有两个线程，一个是调用你的线程，还有一个是被你创建出来的线程。 例子： 12345678910JAVApublic static void main(String[] args) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; System.out.println(&quot;==========&quot;); &#125; &#125;; t1.start();&#125; 这里面就是一个调用你的线程（main线程），一个被你创建出来的线程（t1，名字可能是Thread-0） 2、当JVM启动后，实际有多个线程，但是至少有一个非守护线程（比如main线程）。 Finalizer：GC守护线程 RMI：Java自带的远程方法调用（秋招面试，有个面试官问过） Monitor ：是一个守护线程，负责监听一些操作，也在main线程组中 其它：我用的是IDEA，其它的应该是IDEA的线程，比如鼠标监听啥的。 守护线程12345678910111213141516171819202122JAVApublic static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread() &#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot; running&quot;); Thread.sleep(100000);//① System.out.println(Thread.currentThread().getName() + &quot; done.&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; //new t.setDaemon(true);//② t.start(); Thread.sleep(5_000); //JDK1.7 System.out.println(Thread.currentThread().getName());&#125; 源码标记解读： ①变量名为t的线程Thread-0，睡眠100秒。 ②但是在主函数里Thread-0设置成了main线程的守护线程。所以5秒之后main线程结束了，即使在①这里守护线程还是处于睡眠100秒的状态，但由于他是守护线程，非守护线程main结束了，守护线程也必须结束。 1、但是如果Thread-0线程不是守护线程，即使main线程结束了，Thread-0线程仍然会睡眠100秒再结束。 当主线程死亡后，守护线程会跟着死亡 可以帮助做一些辅助性的东西，如“心跳检测” 设置守护线程：public final void setDaemon(boolean on) 用处A和B之间有一条网络连接，可以用守护线程来进行发送心跳，一旦A和B连接断开，非守护线程就结束了，守护线程（也就是心跳没有必要再发送了）也刚好断开。 123456789101112131415161718192021222324252627282930313233JAVApublic static void main(String[] args) &#123; Thread t = new Thread(() -&gt; &#123; Thread innerThread = new Thread(() -&gt; &#123; try &#123; while (true) &#123; System.out.println(&quot;Do some thing for health check.&quot;); Thread.sleep(1_000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); // innerThread.setDaemon(true); innerThread.start(); try &#123; Thread.sleep(1_000); System.out.println(&quot;T thread finish done.&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); //t.setDaemon(true); t.start();&#125;/*设置该线程为守护线程必须在启动它之前。如果t.start()之后，再t.setDaemon(true);会抛出IllegalThreadStateException*/ 输出结果： Do some thing for health check.Do some thing for health check.T thread finish done. &#x2F;&#x2F;此时main线程已经结束，但是由于innerThread还在发送心跳，应用不会关闭Do some thing for health check.Do some thing for health check.Do some thing for health check.Do some thing for health check. 守护线程还有其它很多用处，在后面的文章里还会有出现。 join方法例子1 1234567891011121314151617181920JAVApublic static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i)); &#125;); Thread t2 = new Thread(() -&gt; &#123; IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i)); &#125;); t1.start(); t2.start(); t1.join(); t2.join(); Optional.of(&quot;All of tasks finish done.&quot;).ifPresent(System.out::println); IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i));&#125; 默认传入的数字为0，这里是在main线程里调用了两个线程的join()，所以main线程会等到Thread-0和Thread-1线程执行完再执行它自己。 join必须在start方法之后，并且join()是对wait()的封装。（源码中可以清楚的看到） 也就是说，t.join()方法阻塞调用此方法的线程(calling thread)进入 TIMED_WAITING或WAITING 状态。直到线程t完成，此线程再继续。 join也有人理解成插队，比如在main线程中调用t.join()，就是t线程要插main线程的队，main线程要去等待。 例子2 12345678910111213141516171819202122232425JAVApublic static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i)); &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; t1.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i)); &#125;); t1.start(); t2.start();// t1.join(); t2.join(); Optional.of(&quot;All of tasks finish done.&quot;).ifPresent(System.out::println); IntStream.range(1, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + &quot;-&gt;&quot; + i)); &#125; 这里是在t2（我们以后就都用变量名来称呼线程了）线程了。t1.join()了。所以t2线程会等待t1线程打印完，t2自己才会打印。然后t2.join()，main线程也要等待t2线程。总体执行顺序就是t1–&gt;t2–&gt;main 通过上方例子可以用join实现类似于CompletableFuture的异步任务编排。（后面会讲） 中断1、Java 中的中断和操作系统的中断还不一样，这里就按照状态来理解吧，不要和操作系统的中断联系在一起 2、记住中断只是一个状态，Java的方法可以选择对这个中断进行响应，也可以选择不响应。响应的意思就是写相对应的代码执行相对应的操作，不响应的意思就是什么代码都不写。 几个方法12345678910111213JAVA// Thread 类中的实例方法，持有线程实例引用即可检测线程中断状态public boolean isInterrupted() &#123;&#125;/*1、Thread 中的静态方法，检测调用这个方法的线程是否已经中断2、注意：这个方法返回中断状态的同时，会将此线程的中断状态重置为 false如果我们连续调用两次这个方法的话，第二次的返回值肯定就是 false 了*/public static boolean interrupted() &#123;&#125;// Thread 类中的实例方法，用于设置一个线程的中断状态为 truepublic void interrupt() &#123;&#125; 小tip1234JAVApublic static boolean interrupted()public boolean isInterrupted()//这个会清除中断状态 为什么要这么设置呢？原因在于： interrupted()是一个静态方法，可以在Runnable接口实例中使用 isInterrupted()是一个Thread的实例方法，在重写Thread的run方法时使用 12345678910111213141516JAVApublic class ThreadInterrupt &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; System.out.println(Thread.interrupted()); &#125;); //这个new Thread用的是runnable接口那个构造函数 Thread t2 = new Thread()&#123; @Override public void run() &#123; System.out.println(isInterrupted()); &#125; &#125;;//这个new Thread用的就是Thread的空参构造 &#125;&#125; 也就是说接口中不能调用Thread的实例方法，只能通过静态方法来判断是否发生中断 重难点当然，中断除了是线程状态外，还有其他含义，否则也不需要专门搞一个这个概念出来了。 初学者肯定以为 thread.interrupt() 方法是用来暂停线程的，主要是和它对应中文翻译的“中断”有关。中断在并发中是常用的手段，请大家一定好好掌握。可以将中断理解为线程的状态，它的特殊之处在于设置了中断状态为 true 后，这几个方法会感知到： wait(), wait(long), wait(long, int), join(), join(long), join(long, int), sleep(long), sleep(long, int) 这些方法都有一个共同之处，方法签名上都有throws InterruptedException，这个就是用来响应中断状态修改的。 如果线程阻塞在 InterruptibleChannel 类的 IO 操作中，那么这个 channel 会被关闭。 如果线程阻塞在一个 Selector 中，那么 select 方法会立即返回。 对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），并且在做出相应的操作后都会重置中断状态为 false。然后执行相应的操作（通常就是跳到 catch 异常处）。 如果不是以上3种情况，那么，线程的 interrupt() 方法被调用，会将线程的中断状态设置为 true。 那是不是只有以上 3 种方法能自动感知到中断呢？不是的，如果线程阻塞在 LockSupport.park(Object obj) 方法，也叫挂起，这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true。 并发编程中的三个问题可见性可见性概念可见性（Visibility）：是指一个线程对共享变量进行修改，另一个先立即得到修改后的新值。 可见性演示1234567891011121314151617181920212223242526272829303132333435363738JAVA/* 笔记 * 1.当没有加Volatile的时候,while循环会一直在里面循环转圈 * 2.当加了之后Volatile,由于可见性,一旦num改了之后,就会通知其他线程 * 3.还有注意的时候不能用if,if不会重新拉回来再判断一次。(也叫做虚假唤醒) * 4.案例演示:一个线程对共享变量的修改,另一个线程不能立即得到新值 * */public class Video04_01 &#123; public static void main(String[] args) &#123; MyData myData = new MyData(); new Thread(() -&gt;&#123; System.out.println(Thread.currentThread().getName() + &quot;\\t come in &quot;); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //睡3秒之后再修改num,防止A线程先修改了num,那么到while循环的时候就会直接跳出去了 myData.addTo60(); System.out.println(Thread.currentThread().getName() + &quot;\\t come out&quot;); &#125;,&quot;A&quot;).start(); while(myData.num == 0)&#123; //只有当num不等于0的时候,才会跳出循环 &#125; &#125;&#125;class MyData&#123; int num = 0; public void addTo60()&#123; this.num = 60; &#125;&#125; 由上面代码可以看出，并发编程时，会出现可见性问题，当一个线程对共享变量进行了修改，另外的线程并没有立即看到修改后的最新值。 原子性原子性概念原子性（Atomicity）：在一次或多次操作中，要么所有的操作都成功执行并且不会受其他因素干扰而中 断，要么所有的操作都不执行或全部执行失败。不会出现中间状态 原子性演示案例演示:5个线程各执行1000次 i++; 1234567891011121314151617181920212223242526272829303132333435363738JAVA/** * @Author: 吕 * @Date: 2019/9/23 15:50 * &lt;p&gt; * 功能描述: volatile不保证原子性的代码验证 */public class Video05_01 &#123; public static void main(String[] args) &#123; MyData03 myData03 = new MyData03(); for (int i = 0; i &lt; 20; i++) &#123; new Thread(() -&gt;&#123; for (int j = 0; j &lt; 1000; j++) &#123; myData03.increment(); &#125; &#125;,&quot;线程&quot; + String.valueOf(i)).start(); &#125; //需要等待上面的20个线程计算完之后再查看计算结果 while(Thread.activeCount() &gt; 2)&#123; Thread.yield(); &#125; System.out.println(&quot;20个线程执行完之后num:\\t&quot; + myData03.num); &#125;&#125;class MyData03&#123; static int num = 0; public void increment()&#123; num++; &#125;&#125; 1、控制台输出：（由于并发不安全，每次执行的结果都可能不一样） 20个线程执行完之后num: 19706 正常来说，如果保证原子性的话，20个线程执行完，结果应该是20000。控制台输出的值却不是这个，说明出现了原子性的问题。 2、使用javap反汇编class文件，对于num++可以得到下面的字节码指令： 12345CODE9: getstatic #12 // Field number:I 取值操作12: iconst_1 13: iadd 14: putstatic #12 // Field number:I 赋值操作 由此可见num++是由多条语句组成，以上多条指令在一个线程的情况下是不会出问题的，但是在多线程情况下就可能会出现问题。 比如num刚开始值是7。A线程在执行13: iadd时得到num值是8，B线程又执行9: getstatic得到前一个值是7。马上A线程就把8赋值给了num变量。但是B线程已经拿到了之前的值7，B线程是在A线程真正赋值前拿到的num值。即使A线程最终把值真正的赋给了num变量，但是B线程已经走过了getstaitc取值的这一步，B线程会继续在7的基础上进行++操作，最终的结果依然是8。本来两个线程对7进行分别进行++操作，得到的值应该是9，因为并发问题，导致结果是8。 3、并发编程时，会出现原子性问题，当一个线程对共享变量操作到一半时，另外的线程也有可能来操作共 享变量，干扰了前一个线程的操作。 有序性有序性概念有序性（Ordering）：是指程序中代码的执行顺序，Java在编译时和运行时会对代码进行优化（重排序）来加快速度，会导致程序终的执行顺序不一定就是我们编写代码时的顺序 12345JAVAinstance = new SingletonDemo() 是被分成以下 3 步完成 memory = allocate(); 分配对象内存空间 instance(memory); 初始化对象 instance = memory; 设置 instance 指向刚分配的内存地址，此时 instance != null 步骤2 和 步骤3 不存在数据依赖关系，重排与否的执行结果单线程中是一样的。这种指令重排是被 Java 允许的。当 3 在前时，instance 不为 null，但实际上初始化工作还没完成，会变成一个返回 null 的getInstance。这时候数据就出现了问题。 有序性演示jcstress是java并发压测工具。https://wiki.openjdk.java.net/display/CodeTools/jcstress 修改pom文件，添加依赖： 12345678910111213141516171819202122232425262728293031323334353637CODE&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jcstress&lt;/groupId&gt; &lt;artifactId&gt;jcstress-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jcstress.version&#125;&lt;/version&gt; &lt;/dependency&gt;JAVAimport org.openjdk.jcstress.annotations.*;import org.openjdk.jcstress.infra.results.I_Result; @JCStressTest // @Outcome: 如果输出结果是1或4，我们是接受的(ACCEPTABLE)，并打印ok @Outcome(id = &#123;&quot;1&quot;, &quot;4&quot;&#125;, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;) //如果输出结果是0，我们是接受的并且感兴趣的，并打印danger @Outcome(id = &quot;0&quot;, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;danger&quot;) @Statepublic class Test03Ordering &#123; int num = 0; boolean ready = false; // 线程1执行的代码 @Actor //@Actor：表示会有多个线程来执行这个方法 public void actor1(I_Result r) &#123; if (ready) &#123; r.r1 = num + num; &#125; else &#123; r.r1 = 1; &#125; &#125; // 线程2执行的代码 // @Actor public void actor2(I_Result r) &#123; num = 2; ready = true; &#125;&#125; 1、实际上上面两个方法会有很多线程来执行，为了讲解方便，我们只提出线程1和线程2来讲解。 2、I_Result 是一个保存int类型数据的对象，有一个属性 r1 用来保存结果，在多线程情况下可能出现几种结果？ 情况1：线 程1先执行actor1，这时ready &#x3D; false，所以进入else分支结果为1。 情况2：线程2执行到actor2，执行了num &#x3D; 2;和ready &#x3D; true，线程1执行，这回进入 if 分支，结果为 4。 情况3：线程2先执行actor2，只执行num &#x3D; 2；但没来得及执行 ready &#x3D; true，线程1执行，还是进入 else分支，结果为1。 情况4：0，发生了指令重排 12345678JAVA// 线程2执行的代码 // @Actor public void actor2(I_Result r) &#123; num = 2; //pos_1 ready = true;//pos_2 &#125; pos_1处代码和pos_2处代码没有什么数据依赖关系，或者说没有因果关系。Java可能对其进行指令重排，排成下面的顺序。 1234567JAVA// 线程2执行的代码 // @Actor public void actor2(I_Result r) &#123; ready = true;//pos_2 num = 2; //pos_1 &#125; 此时如果线程2先执行到ready = true;还没来得及执行 num = 2; 。线程1执行，直接进入if分支，此时num默认值为0。 得到的结果也就是0。 volatile 1、关于可见性，重排序等等的硬件原理，MESI缓存一致性，内存屏障，JMM等等这些，请看我的后面文章。第一阶段只是介绍下用法，不涉及原理。 2、如果你在第一篇文章没有找到你想要的内容，请看我后面的内容。并发的体系，我自认为讲的还是比较全面的。 volatile保证可见性代码 读者可以把两个代码运行一下，就能明显看到不加volatile的死循环（就是程序一直显示没结束） 1234567891011121314151617181920212223242526272829303132333435363738JAVA/* 笔记 * 1.当没有加Volatile的时候,while循环会一直在里面转圈 * 2.当加了之后Volatile,由于可见性,一旦num改了之后,就会通知其他线程 * 3.还有注意的时候不能用if,if不会重新拉回来再判断一次 * */public class Video04_02 &#123; public static void main(String[] args) &#123; MyData2 myData = new MyData2(); new Thread(() -&gt;&#123; System.out.println(Thread.currentThread().getName() + &quot;\\t come in &quot;); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //睡3秒之后再修改num,防止A线程先修改了num,那么到while循环的时候就会直接跳出去了 myData.addTo60(); System.out.println(Thread.currentThread().getName() + &quot;\\t come out&quot;); &#125;,&quot;A&quot;).start(); while(myData.num == 0)&#123; //只有当num不等于0的时候,才会跳出循环 &#125; &#125;&#125;class MyData2&#123; volatile int num = 0; public void addTo60()&#123; this.num = 60; &#125;&#125; volatile保证有序性代码12345678910111213141516171819202122232425262728293031JAVAimport org.openjdk.jcstress.annotations.*;import org.openjdk.jcstress.infra.results.I_Result; @JCStressTest // @Outcome: 如果输出结果是1或4，我们是接受的(ACCEPTABLE)，并打印ok @Outcome(id = &#123;&quot;1&quot;, &quot;4&quot;&#125;, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;) //如果输出结果是0，我们是接受的并且感兴趣的，并打印danger @Outcome(id = &quot;0&quot;, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;danger&quot;) @Statepublic class Test03Ordering &#123; volatile int num = 0; volatile boolean ready = false; // 线程1执行的代码 @Actor //@Actor：表示会有多个线程来执行这个方法 public void actor1(I_Result r) &#123; if (ready) &#123; r.r1 = num + num; &#125; else &#123; r.r1 = 1; &#125; &#125; // 线程2执行的代码 // @Actor public void actor2(I_Result r) &#123; num = 2; ready = true; &#125;&#125; 读者可以将运行结果对比着来看，就能发现区别。 volatile只能保证可见性和有序性（禁止指令重排），无法保证原子性。 CASvolatile自己虽然不能保证原子性，但是和CAS结合起来就可以保证原子性了。CAS+volatile一起用就可以同时解决并发编程中的三个问题了，保证并发安全。 CAS 是什么？ CAS：比较并交换compareAndSet,它是一条 CPU 并发原语，它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子性的。 例: AtomicInteger 的 compareAndSet(‘期望值’,’设置值’) 方法，期望值与目标值一致时，修改目标变量为设置值，期望值与目标值不一致时，返回 false 和最新主存的变量值 CAS 的底层原理 1234例: AtomicInteger.getAndIncrement() 调用 Unsafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令 这是一种完全依赖于硬件的功能，通过它实现原子操作。 原语的执行必须是连续的，在执行过程中不允许被中断，CAS 是 CPU 的一条原子指令。 CAS的思想就是乐观锁的思想 AtomicInteger在JUC并发包中，CAS和AtomicInteger（原子类的value值都被volatile修饰了）一起保证了并发安全。下面我们以AtomicInteger.getAndIncrement() 方法讲一下。 12345678910111213141516171819202122232425262728293031323334353637JAVA/** * unsafe: rt.jar/sun/misc/Unsafe.class * Unsafe 是 CAS 的核心类，由于 Java 无法直接访问底层系统，需要通过本地&lt;native&gt;方法来访问 * Unsafe 相当于一个后门，基于该类可以直接操作特定内存的数据 * Unsafe 其内部方法都是 native 修饰的，可以像 C 的指针一样直接操作内存 * Java 中的 CAS 操作执行依赖于 Unsafe 的方法，直接调用操作系统底层资源执行程序 * * this: 当前对象 * 变量 value 由 volatile 修饰，保证了多线程之间的内存可见性、禁止重排序 * * valueOffset: 内存地址 * 表示该变量值在内存中的偏移地址，因为 Unsafe 就是根据内存偏移地址获取数据 * * 1: 固定写死，原值加1 */public final int getAndIncrement()&#123; return unsafe.getAndAddInt(this,valueOffset,1);&#125;/** * Unsafe.getAndAddInt() * getIntVolatile: 通过内存地址去主存中取对应数据 * * while(!this.compareAndSwapInt(var1,var2,var5,var5 + var4)): * 将本地 value 与主存中取出的数据对比，如果相同，对其作运算， * 此时返回 true，取反后 while 结束，返回最终值。 * 如果不相同，此时返回 false，取反后 while 循环继续运行，此时为自旋锁&lt;重复尝试&gt; * 由于 value 是被 volatile 修饰的，所以拿到主存中最新值，再循环直至成功。 */public final int getAndAddInt(Object var1,long var2,int var4)&#123; int var5; do&#123; var5 = this.getIntVolatile(var1,var2); // 从主存中拷贝变量到本地内存 &#125; while(!this.compareAndSwapInt(var1,var2,var5,var5 + var4)); return var5;&#125; CAS 代码演示123456789JAVApublic class CASDemo &#123; public static void main(String[] args) &#123; AtomicInteger num = new AtomicInteger(5); // TODO System.out.println(num.compareAndSet(5, 1024) + &quot;\\t current num&quot; + num.get()); System.out.println(num.compareAndSet(5, 2019) + &quot;\\t current num&quot; + num.get()); &#125; CAS三大问题 如果 CAS 长时间一直不成功，会给 CPU 带来很大的开销，在Java的实现中是一直通过while循环自旋CAS获取锁。 只能保证一个共享变量的原子操作 引出了 ABA 问题 ABA问题什么是ABA问题？1234567891011121314151617181920212223242526272829JAVA/** * @Author: 吕 * @Date: 2019/9/24 16:43 * &lt;p&gt; * 功能描述: CAS引发的ABA问题 */public class Video19_01 &#123; static AtomicReference&lt;Integer&gt; num = new AtomicReference&lt;&gt;(100); public static void main(String[] args) &#123; new Thread(() -&gt;&#123; num.compareAndSet(100, 101); num.compareAndSet(101,100); &#125;,&quot;线程A&quot;).start(); new Thread(() -&gt;&#123; //保证A线程已经修改完 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean b = num.compareAndSet(100, 2019); System.out.println(b + &quot;\\t 当前最新值&quot; + num.get().toString()); &#125;,&quot;线程B&quot;).start(); &#125;&#125; CAS 会导致 ABA 问题： 例: A、B线程从主存取出变量 value -&gt; A 在 N次计算中改变 value 的值-&gt; A 最终计算结果还原 value 最初的值-&gt; B 计算后，比较主存值与自身 value 值一致，修改成功 尽管各个线程的 CAS 都操作成功，但是并不代表这个过程就是没有问题的。 ABA问题的解决123456789101112131415161718192021222324252627282930313233JAVA/** * @Author: 吕 * @Date: 2019/9/24 16:49 * &lt;p&gt; * 功能描述: ABA问题的解决 */public class Video19_02 &#123; static AtomicStampedReference&lt;Integer&gt; num = new AtomicStampedReference&lt;&gt;(100,1); public static void main(String[] args) &#123; int stamp = num.getStamp();//初始版本号 new Thread(() -&gt;&#123; num.compareAndSet(100,101,num.getStamp(),num.getStamp() + 1); System.out.println(Thread.currentThread().getName() + &quot;\\t 版本号&quot; + num.getStamp()); num.compareAndSet(101,100,num.getStamp(),num.getStamp() + 1); System.out.println(Thread.currentThread().getName() + &quot;\\t 版本号&quot; + num.getStamp()); &#125;,&quot;线程A&quot;).start(); new Thread(() -&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean b = num.compareAndSet(100, 209, stamp, num.getStamp() + 1); System.out.println(b + &quot;\\t 当前版本号: \\t&quot; + num.getStamp()); System.out.println(&quot;当前最新值 \\t&quot; + num.getReference().toString()); &#125;,&quot;线程B&quot;).start(); &#125;&#125; 思想很简单，可以很明显的看出来用版本号的方式解决了ABA的问题。 除了对象值，AtomicStampedReference内部还维护了一个“状态戳”。 状态戳可类比为时间戳，是一个整数值，每一次修改对象值的同时，也要修改状态戳，从而区分相同对象值的不同状态。 当AtomicStampedReference设置对象值时，对象值以及状态戳都必须满足期望值，写入才会成功。 只能保证一个共享变量的原子操作 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个方法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i&#x3D;2,j&#x3D;a合并一下ij&#x3D;2a，然后用CAS来操作ij。从java1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。 所以一般来说为了同时解决ABA问题和只能保证一个共享变量，原子类使用时大部分使用的是AtomicStampedReference UnSafeUnsafe类是在sun.misc包下，不属于Java标准。但是很多Java的基础类库，包括一些被广泛使用的高性能开发库都是基于Unsafe类开发的，比如Netty、Cassandra、Hadoop、Kafka等。Unsafe类在提升Java运行效率，增强Java语言底层操作能力方面起了很大的作用。 Java和C++语言的一个重要区别就是Java中我们无法直接操作一块内存区域，不能像C++中那样可以自己申请内存和释放内存。 Java中的Unsafe类为我们提供了类似C++手动管理内存的能力，同时也有了指针的问题。 首先，Unsafe类是”final”的，不允许继承。且构造函数是private的: 123456789101112JAVApublic final class Unsafe &#123; private static final Unsafe theUnsafe; public static final int INVALID_FIELD_OFFSET = -1; private static native void registerNatives(); private Unsafe() &#123; &#125; ...&#125; 因此我们无法在外部对Unsafe进行实例化。 获取UnsafeUnsafe无法实例化，那么怎么获取Unsafe呢？答案就是通过反射来获取Unsafe： 1234567JAVApublic Unsafe getUnsafe() throws IllegalAccessException &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); return unsafe;&#125; Unsafe的功能如下图： CAS相关JUC中大量运用了CAS操作，可以说CAS操作是JUC的基础，因此CAS操作是非常重要的。Unsafe中提供了int,long和Object的CAS操作： 123456JAVApublic final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 偏移量相关1234JAVApublic native long staticFieldOffset(Field var1);public native long objectFieldOffset(Field var1); staticFieldOffset方法用于获取静态属性Field在对象中的偏移量，读写静态属性时必须获取其偏移量。 objectFieldOffset方法用于获取非静态属性Field在对象实例中的偏移量，读写对象的非静态属性时会用到这个偏移量 类加载12345678910JAVApublic native Class&lt;?&gt; defineClass(String var1, byte[] var2, int var3, int var4, ClassLoader var5, ProtectionDomain var6);public native Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; var1, byte[] var2, Object[] var3);public native Object allocateInstance(Class&lt;?&gt; var1) throws InstantiationException;public native boolean shouldBeInitialized(Class&lt;?&gt; var1);public native void ensureClassInitialized(Class&lt;?&gt; var1); defineClass方法定义一个类，用于动态地创建类。 defineAnonymousClass用于动态的创建一个匿名内部类。 allocateInstance方法用于创建一个类的实例，但是不会调用这个实例的构造方法，如果这个类还未被初始化，则初始化这个类。 shouldBeInitialized方法用于判断是否需要初始化一个类。 ensureClassInitialized方法用于保证已经初始化过一个类。 举例 1234567891011121314151617181920212223242526272829303132333435363738JAVApublic class UnsafeFooTest &#123; private static Unsafe geUnsafe() &#123; try &#123; Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); return (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return null; &#125; static class Simple &#123; private long l = 0; public Simple() &#123; this.l = 1; System.out.println(&quot;我被初始化了&quot;); &#125; public long getL() &#123; return l; &#125; &#125; public static void main(String[] args) throws Exception &#123; Unsafe unsafe = geUnsafe(); Simple s = (Simple) unsafe.allocateInstance(Simple.class); System.out.println(s.getL()); &#125;&#125; 结果： 0 可以发现，利用Unsafe获取实例，不会调用构造方法 普通读写通过Unsafe可以读写一个类的属性，即使这个属性是私有的，也可以对这个属性进行读写。 读写一个Object属性的相关方法 1234JAVApublic native int getInt(Object var1, long var2);public native void putInt(Object var1, long var2, int var4); getInt用于从对象的指定偏移地址处读取一个int。 putInt用于在对象指定偏移地址处写入一个int。其他的primitive type也有对应的方法。 举例 123456789101112131415161718192021222324252627282930313233343536373839404142JAVApublic class UnsafeFooTest &#123; private static Unsafe geUnsafe() &#123; try &#123; Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); return (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return null; &#125; static class Guard&#123; private int ACCESS_ALLOWED = 1; private boolean allow()&#123; return 50 == ACCESS_ALLOWED; &#125; public void work()&#123; if (allow())&#123; System.out.println(&quot;我被允许工作....&quot;); &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; Unsafe unsafe = geUnsafe(); Guard guard = new Guard(); Field f = guard.getClass().getDeclaredField(&quot;ACCESS_ALLOWED&quot;); unsafe.putInt(guard,unsafe.objectFieldOffset(f),50); System.out.println(&quot;强行赋值...&quot;); guard.work(); &#125;&#125; 结果 强行赋值… 我被允许工作… 类加载12345678910JAVApublic native Class&lt;?&gt; defineClass(String var1, byte[] var2, int var3, int var4, ClassLoader var5, ProtectionDomain var6);public native Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; var1, byte[] var2, Object[] var3);public native Object allocateInstance(Class&lt;?&gt; var1) throws InstantiationException;public native boolean shouldBeInitialized(Class&lt;?&gt; var1);public native void ensureClassInitialized(Class&lt;?&gt; var1); defineClass方法定义一个类，用于动态地创建类。 defineAnonymousClass用于动态的创建一个匿名内部类。 allocateInstance方法用于创建一个类的实例，但是不会调用这个实例的构造方法，如果这个类还未被初始化，则初始化这个类。 shouldBeInitialized方法用于判断是否需要初始化一个类。 ensureClassInitialized方法用于保证已经初始化过一个类。 内存屏障123456JAVApublic native void loadFence();public native void storeFence();public native void fullFence(); loadFence：保证在这个屏障之前的所有读操作都已经完成。 storeFence：保证在这个屏障之前的所有写操作都已经完成。 fullFence：保证在这个屏障之前的所有读写操作都已经完成。 线程调度12345678910JAVApublic native void unpark(Object var1);public native void park(boolean var1, long var2);public native void monitorEnter(Object var1);public native void monitorExit(Object var1);public native boolean tryMonitorEnter(Object var1); park方法和unpark方法相信看过LockSupport类的都不会陌生，这两个方法主要用来挂起和唤醒线程。 LockSupport中的park和unpark方法正是通过Unsafe来实现的： 123456789101112JAVApublic static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null);&#125;public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125; monitorEnter方法和monitorExit方法用于加锁，Java中的synchronized锁就是通过这两个指令来实现的。 synchronized优化 synchronized可以同时保证可见性，有序性，原子性。这个东西就不讲了 从JDk 1.6开始，JVM就对synchronized锁进行了很多的优化。synchronized说是锁，但是他的底层加锁的方式可能不同，偏向锁的方式来加锁，自旋锁的方式来加锁，轻量级锁的方式来加锁 锁消除锁消除是JIT编译器对synchronized锁做的优化，在编译的时候，JIT会通过逃逸分析技术，来分析synchronized锁对象，是不是只可能被一个线程来加锁，没有其他的线程来竞争加锁，这个时候编译就不用加入monitorenter和monitorexit的指令。这就是，仅仅一个线程争用锁的时候，就可以消除这个锁了，提升这段代码的执行的效率，因为可能就只有一个线程会来加锁，不涉及到多个线程竞争锁 锁粗化12345678910111213141516JAVAsynchronized(this) &#123;&#125; synchronized(this) &#123; &#125; synchronized(this) &#123;&#125; 这个意思就是，JIT编译器如果发现有代码里连续多次加锁释放锁的代码，会给合并为一个锁，就是锁粗化，把一个锁给搞粗了，避免频繁多次加锁释放锁 偏向锁这个意思就是说，monitorenter和monitorexit是要使用CAS操作加锁和释放锁的，开销较大，因此如果发现大概率只有一个线程会主要竞争一个锁，那么会给这个锁维护一个偏好（Bias），后面他加锁和释放锁，基于Bias来执行，不需要通过CAS，性能会提升很多。但是如果有偏好之外的线程来竞争锁，就要收回之前分配的偏好。可能只有一个线程会来竞争一个锁，但是也有可能会有其他的线程来竞争这个锁，但是其他线程唉竞争锁的概率很小。如果有其他的线程来竞争这个锁，此时就会收回之前那个线程分配的那个Bias偏好 轻量级锁如果偏向锁没能成功实现，就是因为不同线程竞争锁太频繁了，此时就会尝试采用轻量级锁的方式来加锁，就是将对象头的Mark Word里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一下是不是自己加的锁，如果是自己加的锁，那就执行代码就好了。如果不是自己加的锁，那就是加锁失败，说明有其他人加了锁，这个时候就是升级为重量级锁 适应性锁这是JIT编译器对锁做的另外一个优化，如果各个线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。但是其他线程很快释放锁了，然后暂停的线程再次被唤醒。也就是说在这种情况下，线程会频繁的上下文切换，导致开销过大。所以对这种线程持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没竞争到锁，进入一个while循环不停等待，不会暂停不会发生线程上下文切换，等到机会获取锁就继续执行好了 指令重排计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。 为什么指令重排序可以提高性能？简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，流水线技术产生了，它的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。 但是，流水线技术最害怕中断，恢复中断的代价是比较大的，所以我们要想尽办法不让流水线中断。指令重排就是减少中断的一种技术。 我们分析一下下面这个代码的执行情况： 123JAVAa = b + c;d = e - f ; 先加载b、c（注意，即有可能先加载b，也有可能先加载c），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。 为了减少这个停顿，我们可以先加载e和f,然后再去加载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。 综上所述，指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。 指令重排一般分为以下三种： 编译器优化重排 编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令并行重排 现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。 内存系统重排 由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。 指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。 as-if-serial语义as-if-serial语义的意思是：不管编译器和CPU如何重排序，必须保证在单线程情况下程序的结果是正确的。 以下数据有依赖关系，不能重排序。 写后读： 123CODEint a = 1; int b = a; 写后写： 123CODEint a = 1; int a = 2; 读后写： 1234CODEint a = 1; int b = a; int a = 2; 编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。 1234CODEint a = 1; int b = 2; int c = a + b; Java内存模型(JMM)在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型。 计算机结构计算机结构简介冯诺依曼，提出计算机由五大组成部分，输入设备，输出设备存储器，控制器，运算器。 输入设备：鼠标，键盘等等 输出设备：显示器，打印机等等 存储器：内存条 运算器和控制器组成CPU CPU中央处理器，是计算机的控制和运算的核心，我们的程序终都会变成指令让CPU去执行，处理程序中 的数据。 内存我们的程序都是在内存中运行的，内存会保存程序运行时的数据，供CPU处理。 缓存CPU的运算速度和内存的访问速度相差比较大。这就导致CPU每次操作内存都要耗费很多等待时间。内 存的读写速度成为了计算机运行的瓶颈。于是就有了在CPU和主内存之间增加缓存的设计。靠近CPU 的缓存称为L1，然后依次是 L2，L3和主内存，CPU缓存模型如图下图所示。 CPU Cache分成了三个级别: L1， L2， L3。级别越小越接近CPU，速度也更快，同时也代表着容量越小。速度越快的价格越贵。 1、L1是接近CPU的，它容量小，例如32K，速度快，每个核上都有一个L1 Cache。 2、L2 Cache 更大一些，例如256K，速度要慢一些，一般情况下每个核上都有一个独立的L2 Cache。 3、L3 Cache是三级缓存中大的一级，例如12MB，同时也是缓存中慢的一级，在同一个CPU插槽 之间的核共享一个L3 Cache。 上面的图中有一个Latency指标。比如Memory这个指标为59.4ns，表示CPU在操作内存的时候有59.4ns的延迟，一级缓存最快只有1.2ns。 CPU处理数据的流程 Cache的出现是为了解决CPU直接访问内存效率低下问题的。 1、程序在运行的过程中，CPU接收到指令 后，它会先向CPU中的一级缓存（L1 Cache）去寻找相关的数据，如果命中缓存，CPU进行计算时就可以直接对CPU Cache中的数据进行读取和写人，当运算结束之后，再将CPUCache中的新数据刷新 到主内存当中，CPU通过直接访问Cache的方式替代直接访问主存的方式极大地提高了CPU 的吞吐能 力。 2、但是由于一级缓存（L1 Cache）容量较小，所以不可能每次都命中。这时CPU会继续向下一级的二 级缓存（L2 Cache）寻找，同样的道理，当所需要的数据在二级缓存中也没有的话，会继续转向L3 Cache、内存(主存)和硬盘。 Java内存模型1、Java Memory Molde (Java内存模型&#x2F;JMM)，千万不要和Java内存结构（JVM划分的那个堆，栈，方法区）混淆。关于“Java内存模型”的权威解释，参考 https://download.oracle.com/otn-pub/jcp/memory_model1.0-pfd-spec-oth-JSpec/memory_model-1_0-pfd-spec.pdf。 2、 Java内存模型，是Java虚拟机规范中所定义的一种内存模型，Java内存模型是标准化的，屏蔽掉了底层不同计算机的区别。 Java内存模型是一套规范，描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量存储到内存和从内存中读取变量这样的底层细节，具体如下。 3、Java内存模型根据官方的解释，主要是在说两个关键字，一个是volatile，一个是synchronized。 主内存 主内存是所有线程都共享的，都能访问的。所有的共享变量都存储于主内存。 工作内存 每一个线程有自己的工作内存，工作内存只存储该线程对共享变量的副本。线程对变量的所有的操 作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量，不同线程之间也不能直接 访问对方工作内存中的变量。 Java的线程不能直接在主内存中操作共享变量。而是首先将主内存中的共享变量赋值到自己的工作内存中，再进行操作，操作完成之后，刷回主内存。 Java内存模型的作用 Java内存模型是一套在多线程读写共享数据时，对共享数据的可见性、有序性、和原子性的规则和保障。 synchronized,volatile CPU缓存，内存与Java内存模型的关系 通过对前面的CPU硬件内存架构、Java内存模型以及Java多线程的实现原理的了解，我们应该已经意识到，多线程的执行终都会映射到硬件处理器上进行执行。 但Java内存模型和硬件内存架构并不完全一致。 对于硬件内存来说只有寄存器、缓存内存、主内存的概念，并没有工作内存和主内存之分，也就是说Java内存模型对内存的划分对硬件内存并没有任何影响， 因为JMM只是一种抽象的概念，是一组规则，不管是工作内存的数据还是主内存的数据，对于计算机硬 件来说都会存储在计算机主内存中，当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说， Java内存模型和计算机硬件内存架构是一个相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。 JMM内存模型与CPU硬件内存架构的关系： 工作内存：可能对应CPU寄存器，也可能对应CPU缓存，也可能对应内存。 Java内存模型是一套规范，描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量 存储到内存和从内存中读取变量这样的底层细节，Java内存模型是对共享数据的可见性、有序性、和原子性的规则和保障。 再谈可见性 1、图中所示是 个双核 CPU 系统架构 ，每个核有自己的控制器和运算器，其中控制器包含一组寄存器和操作控制器，运算器执行算术逻辅运算。每个核都有自己的1级缓存，在有些架构里面还有1个所有 CPU 共享的2级缓存。 那么 Java 内存模型里面的工作内存，就对应这里的 Ll 或者 L2 存或者 CPU 寄存器。 2、一个线程操作共享变量时，它首先从主内存复制共享变量到自己的工作内存，然后对工作内存里的变量进行处理，处理完后将变量值更新到主内存。 3、那么假如线程A和线程B同时处理一个共享变量，会出现什么情况?我们使用图所示CPU架构，假设线程A和线程B使用不同CPU执行，并且当前两级Cache都为空，那么这时候由于Cache的存在，将会导致内存不可见问题，具体看下面的分析。 线程A首先获取共享变量X的值，由于两级Cache都没有命中，所以加载主内存中X的值，假如为0。然后把X&#x3D;0的值缓存到两级缓存，线程A修改X的值为1，然后将其写入两级Cache，并且刷新到主内存。线程A操作完毕后，线程A所在的CPU的两级Cache 内和主内存里面的X的值都是1。 线程B获取X的值，首先一级缓存没有命中，然后看二级缓存，二级缓存命中了，所以返回X&#x3D;1;到这里一切都是正常的，因为这时候主内存中也是X&#x3D;1。然后线程B修改X的值为2，并将其存放到线程2所在的一级Cache和共享二级Cache中，最后更新主内存中X 的值为2;到这里一切都是好的。 线程A 这次又需要修改X的值，获取时一级缓存命中，并且X&#x3D;1，到这里问题就出现了，明明线程B已经把X的值修改为了2，为何线程A获取的还是1呢?这就是共享变量的内存不可见问题，也就是线程B写入的值对线程A不可见。那么如何解决共享变量内存不可见问题?使用Java中的volatile和synchronized关键字就可以解决这个问题，下面会有讲解。 主内存与工作内存之间的交互为了保证数据交互时数据的正确性，Java内存模型中定义了8种操作来完成这个交互过程，这8种操作本身都是原子性的。虚拟机实现时必须保证下面 提及的每一种操作都是原子的、不可再分的。 (1)lock:作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 (2)unlock:作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其它线程锁定。 (3)read:作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 (4)load:作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 (5)use:作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时都会执行这个操作。 (6)assign:作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 (7)store:作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write使用。 (8)write:作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 注意: 如果对一个变量执行lock操作，将会清空工作内存中此变量的值 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中 lock和unlock操作只有加锁才会有。synchronized就是通过这样来保证可见性的。 如果没有synchronized，那就是下面这样的 happens-before什么是happens-before?一方面，程序员需要JMM提供一个强的内存模型来编写代码；另一方面，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提高性能，希望的是一个弱的内存模型。 JMM考虑了这两种需求，并且找到了平衡点，对编译器和处理器来说，只要不改变程序的执行结果（单线程程序和正确同步了的多线程程序），编译器和处理器怎么优化都行。 而对于程序员，JMM提供了happens-before规则（JSR-133规范），满足了程序员的需求——简单易懂，并且提供了足够强的内存可见性保证。换言之，程序员只要遵循happens-before规则，那他写的程序就能保证在JMM中具有强的内存可见性。 JMM使用happens-before的概念来定制两个操作之间的执行顺序。这两个操作可以在一个线程以内，也可以是不同的线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证。 happens-before关系的定义如下： 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。 happens-before关系本质上和as-if-serial语义是一回事。 as-if-serial语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的，happens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。 总之，如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的，不管它们在不在一个线程。 天然的happens-before关系在Java中，有以下天然的happens-before关系： 1、程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 2、锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作，比如说在代码里有先对一个lock.lock()，lock.unlock()，lock.lock() 3、volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读 4、传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 5、线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作，thread.start()，thread.interrupt() 6、线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 7、线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 8、对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 上面这8条原则的意思很显而易见，就是程序中的代码如果满足这个条件，就一定会按照这个规则来保证指令的顺序。 举例1： 12345JAVAint a = 1; // A操作int b = 2; // B操作int sum = a + b;// C 操作System.out.println(sum); 上面这8条原则的意思很显而易见，就是程序中的代码如果满足这个条件，就一定会按照这个规则来保证指令的顺序。 举例1： 12345JAVAint a = 1; // A操作int b = 2; // B操作int sum = a + b;// C 操作System.out.println(sum); 根据以上介绍的happens-before规则，假如只有一个线程，那么不难得出： 1234CODE1&gt; A happens-before B 2&gt; B happens-before C 3&gt; A happens-before C 注意，真正在执行指令的时候，其实JVM有可能对操作A &amp; B进行重排序，因为无论先执行A还是B，他们都对对方是可见的，并且不影响执行结果。 如果这里发生了重排序，这在视觉上违背了happens-before原则，但是JMM是允许这样的重排序的。 所以，我们只关心happens-before规则，不用关心JVM到底是怎样执行的。只要确定操作A happens-before操作B就行了。 重排序有两类，JMM对这两类重排序有不同的策略： 会改变程序执行结果的重排序，比如 A -&gt; C，JMM要求编译器和处理器都禁止这种重排序。 不会改变程序执行结果的重排序，比如 A -&gt; B，JMM对编译器和处理器不做要求，允许这种重排序。 举例2： 123456789101112131415JAVA//伪代码volatile boolean flag = false; //线程1 prepare(); flag = false; //线程2 while(!flag)&#123; sleep(); &#125; //基于准备好的资源进行操作 execute(); 这8条原则是避免说出现乱七八糟扰乱秩序的指令重排，要求是这几个重要的场景下，比如是按照顺序来，但是8条规则之外，可以随意重排指令。 比如这个例子，如果用volatile来修饰flag变量，一定可以让prepare()指令在flag &#x3D; true之前先执行，这就禁止了指令重排。 因为volatile要求的是，volatile前面的代码一定不能指令重排到volatile变量操作后面，volatile后面的代码也不能指令重排到volatile前面。 volatilevolatile不保证原子性，只保证可见性和禁止指令重排 CPU术语介绍 123456789101112131415161718JAVAprivate static volatile SingletonDemo instance = null; private SingletonDemo() &#123; System.out.println(Thread.currentThread().getName() + &quot;\\t 执行单例构造函数&quot;); &#125; public static SingletonDemo getInstance()&#123; if(instance == null)&#123; synchronized (SingletonDemo.class)&#123; if(instance == null)&#123; instance = new SingletonDemo(); //pos_1 &#125; &#125; &#125; return instance; &#125; pos_1处的代码转换成汇编代码如下 123SHELL0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp); volatile保证可见性原理有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架 构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情。 1）将当前处理器缓存行的数据写回到系统内存。 2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和主内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的 变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现MESI缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 注意：lock前缀指令是同时保证可见性和有序性（也就是禁止指令重排）的 注意：lock前缀指令相当于一个内存屏障【后文讲】 volatile禁止指令重排的原理12345678910111213141516JAVApublic class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; // step 1 flag = true; // step 2 &#125; public void reader() &#123; if (flag) &#123; // step 3 System.out.println(a); // step 4 &#125; &#125;&#125; 在JSR-133之前的旧的Java内存模型中，是允许volatile变量与普通变量重排序的。那上面的案例中，可能就会被重排序成下列时序来执行： 线程A写volatile变量，step 2，设置flag为true； 线程B读同一个volatile，step 3，读取到flag为true； 线程B读普通变量，step 4，读取到 a &#x3D; 0； 线程A修改普通变量，step 1，设置 a &#x3D; 1； 可见，如果volatile变量与普通变量发生了重排序，虽然volatile变量能保证内存可见性，也可能导致普通变量读取错误。 所以在旧的内存模型中，volatile的写-读就不能与锁的释放-获取具有相同的内存语义了。为了提供一种比锁更轻量级的线程间的通信机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序。 编译器还好说，JVM是怎么还能限制处理器的重排序的呢？它是通过内存屏障来实现的。 什么是内存屏障？硬件层面，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。内存屏障有两个作用： 阻止屏障两侧的指令重排序； 强制把写缓冲区&#x2F;高速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。 注意这里的缓存主要指的是上文说的CPU缓存，如L1，L2等 保守策略下 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的前面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。编译器选择了一个比较保守的JMM内存屏障插入策略，但它可以保证在任意处理器平台，任意的程序中都能 得到正确的volatile内存语义。 再逐个解释一下这几个屏障。注：下述Load代表读操作，Store代表写操作 LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，这个屏障会吧Store1强制刷新到内存，保证Store1的写入操作对其它处理器可见。LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 对于连续多个volatile变量读或者连续多个volatile变量写，编译器做了一定的优化来提高性能，比如： 第一个volatile读; LoadLoad屏障； 第二个volatile读； LoadStore屏障 1、下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图 图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任 意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与 后面可能有的volatile读&#x2F;写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面 是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确 实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile 读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个 写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时， 选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率 2、下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图 图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。 LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。 优化举例： 123456789101112131415JAVAclass VolatileBarrierExample &#123; int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() &#123; int i = v1; // 第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; // 普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; // 第二个 volatile写 &#125; // 其他方法 &#125; &#125; 针对readAndWrite()方法，编译器在生成字节码时可以做如下的优化 注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器通常会在这里插入一个StoreLoad屏障。 上面的优化针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以X86处理器为例，图中除最后的StoreLoad屏障外，其他的屏障都会被省略。 X86处理器优化前面保守策略下的volatile读和写，在X86处理器平台可以优化成如下图所示。 X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写和写-写操作 做重排序，因此在X86处理器中会省略掉这3种操作类型对应的内存屏障。在X86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在X86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）。 volatile的用途 下面的代码在前面可能已经写过了，这里总结一下 从volatile的内存语义上来看，volatile可以保证内存可见性且禁止重排序。 在保证内存可见性这一点上，volatile有着与锁相同的内存语义，所以可以作为一个“轻量级”的锁来使用。但由于volatile仅仅保证对单个volatile变量的读&#x2F;写具有原子性，而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大；在性能上，volatile更有优势。 在禁止重排序这一点上，volatile也是非常有用的。比如我们熟悉的单例模式，其中有一种实现方式是“双重锁检查”，比如这样的代码： 1234567891011121314151617JAVApublic class Singleton &#123; private static Singleton instance; // 不使用volatile关键字 // 双重锁检验 public static Singleton getInstance() &#123; if (instance == null) &#123; // 第7行 synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); // 第10行 &#125; &#125; &#125; return instance; &#125;&#125; 如果这里的变量声明不使用volatile关键字，是可能会发生错误的。它可能会被重排序： 123456789101112JAVAinstance = new Singleton(); // 第10行// 可以分解为以下三个步骤1 memory=allocate();// 分配内存 相当于c的malloc2 ctorInstanc(memory) //初始化对象3 s=memory //设置s指向刚分配的地址// 上述三个步骤可能会被重排序为 1-3-2，也就是：1 memory=allocate();// 分配内存 相当于c的malloc3 s=memory //设置s指向刚分配的地址2 ctorInstanc(memory) //初始化对象 而一旦假设发生了这样的重排序，比如线程A在第10行执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候另一个线程B执行到了第7行，它会判定instance不为空，然后直接返回了一个未初始化完成的instance！ 所以JSR-133对volatile做了增强后，volatile的禁止重排序功能还是非常有用的。 中断什么是中断首先一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止。所以，Thread.stop, Thread.suspend, Thread.resume 都已经被废弃了。 其次在Java中没有办法立即停止一条线程，然而停止线程却显得尤为重要，如取消一个耗时操作。因此，Java提供了一种用于停止线程的机制——中断。 中断只是一种协作机制，Java没有给中断增加任何语法，中断的过程完全需要程序员自己实现。若要中断一个线程，你需要手动调用该线程的interrupt方法，该方法也仅仅是将线程对象的中断标识设成true；接着你需要自己写代码不断地检测当前线程的标识位，如果为true，表示别的线程要求这条线程中断，此时究竟该做什么需要你自己写代码实现。 每个线程对象中都有一个标识，用于表示线程是否被中断；该标识位为true表示中断，为false表示未中断；通过调用线程对象的interrupt方法将该线程的标识位设为true；可以在别的线程中调用，也可以在自己的线程中调用。 中断API 如何停止线程使用中断标志位12345678910111213141516171819202122232425262728293031323334package com.atguigu.ggq.juc.interrupt;import java.util.concurrent.TimeUnit;public class ThreeApi &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(()-&gt;&#123; while(true)&#123;// System.out.println(&quot;线程执行&quot;); if(Thread.currentThread().isInterrupted())&#123; // 线程自己实现中断 System.out.println(&quot;线程中断&quot;); break; &#125; System.out.println(&quot;线程执行&quot;);// try &#123;// TimeUnit.SECONDS.sleep(1);// &#125; catch (InterruptedException e) &#123; //Thread.currentThread().interrupt(); 错误1 不加这行, 错误2 加// e.printStackTrace();// 抛出(注意这里代码是catch 异常已抛出过了)这个异常时 标志位变为false了 // &#125; &#125; &#125;,&quot;t1&quot;); t1.start(); System.out.println(&quot;*************&quot;+t1.isInterrupted()); try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; t1.interrupt(); System.out.println(&quot;*************&quot;+t1.isInterrupted()); &#125;&#125; 12345678910111213正常结果*************false线程执行线程执行线程执行线程执行线程执行线程执行*************true线程中断Process finished with exit code 0 错误结果1(如果线程被block) + sleep 1抛出异常后 线程会一直执行 错误结果2 抛出异常 但线程关闭 添加捕获异常时的中断 12345678910111213141516171819202122232425262728//部分源码public boolean isInterrupted() &#123; return isInterrupted(false); &#125;private native boolean isInterrupted(boolean ClearInterrupted);public static boolean interrupted() &#123; return currentThread().isInterrupted(true); // 返回当前 状态 并设为 false&#125;// 此方法 若线程被处于阻塞 会抛出异常public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0();&#125; interrupt方法源码注释 sleep (优雅的关闭)使用 volatile Boolean12345678910111213public class Vol &#123; private static volatile boolean flag; public static void main(String[] args) &#123; Thread t1 = new Thread(()-&gt;&#123; while(!flag) &#123; //do &#125; &#125;,&quot;t1&quot;); t1.start(); flag = true; &#125;&#125; 使用AutomaticBoolean12345678910111213public class Ato &#123; private static final AtomicBoolean flag = new AtomicBoolean(true); public static void main(String[] args) &#123; Thread t1 = new Thread(()-&gt;&#123; while(flag.get()) &#123; //do &#125; &#125;,&quot;t1&quot;); t1.start(); flag.set(false); &#125;&#125; LockSupport是什么LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。 下面这句话，后面详细说LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程 3种让线程等待和唤醒的方法方式1：使用Object中的wait()方法让线程等待，使用Object中的notify()方法唤醒线程 创建一个对象作为锁对象 Object类中的wait、notify、notifyAll用于线程等待和唤醒的方法，都必须在synchronized内部执行（必须用到关键字synchronized）。 先wait后notify才OK 方式2：使用JUC包中Condition的await()方法让线程等待，使用signal()方法唤醒线程 Lock lock &#x3D; new ReentrantLock(); lock.lock(); lock.unlock(); 线程先要获得并持有锁，必须在锁块(synchronized或lock)中 必须要先等待后唤醒，线程才能够被唤醒 以上两种 使用不当 会有非法monitor状态异常 方式3：LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程 LockSupport类使用了一种名为Permit（许可）的概念来做到阻塞和唤醒线程的功能， 每个线程都有一个许可(permit)，permit只有两个值1和零，默认是零。可以把许可看成是一种(0,1)信号量（Semaphore），但与 Semaphore 不同的是，许可的累加上限是1。默认0 park 把什么搁置 设为0 不许可 阻塞当前线程 unpark(t) 设为1 可执行 唤醒 t 不会抛什么异常 \\ 123456789101112131415161718public class T1&#123; public static void main(String[] args) &#123; Thread t1 = new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+System.currentTimeMillis()); LockSupport.park(); //执行park无效 System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+System.currentTimeMillis()+&quot;---被叫醒&quot;); &#125;,&quot;t1&quot;); t1.start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LockSupport.unpark(t1); // 先执行 System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+System.currentTimeMillis()+&quot;---unpark over&quot;); &#125;&#125; 由浅入深Java多线程第一章 进程与线程的基本概念进程解决了批处理系统时只能存在一个程序问题 线程解决了进程在一段时间只能做一件事情 进程让操作系统的并发性成为了可能,线程让进程的并发成为了可能 多进程也可以实现并发,为什么我们要使用多线程 进程间通信比较复杂,通常我们需要共享资源,这些资源在线程间通信比较简单 进程是重量级 区别 进程间内存隔离,数据共享复杂,但是同步简单 线程则相反 一个进程出现问题不会影响其他进程,而线程则不同 进程创建不仅需要寄存器和栈信息,还需要资源的分配回收以及页调度,线程只需要保存寄存器和栈信息 另外一个重要区别是进程是操作系统进行资源分配的基本单位,而线程是os进行调度的基本单位即cpu分配时间的单位 第二章 Java多线程入门类和接口2.1 Thread类和Runnable接口2.2 Callable、Future与FutureTast第三章 线程组和线程优先级第四章 Java线程的状态及主要转换方法4.3.4线程中断第五章 Java线程间的通信线程的生命周期os五状态 新建 就绪 运行 等待 终止 java6状态 1. NEW 还未调用start方法 2. RUNABLE表示当前线程正在运行中. 线程在JVM运行,也有可能在等待其他系统资源如IO 包含了os的就绪与运行 3. BLOCKED 阻塞状态 等待锁的释放以进入同步区 4. WAITING 等待状态 被唤醒进入RUNABLE 5. TIMEED_WAITING 限定时间的等待,自动唤醒 6. 终止状态 线程执行完毕 第六章 Java内存模型基础知识第七章 重排序与happens-before第八章 volatile第九章 synchronized与锁synchronized为什么是重量级锁 第十章 乐观锁和悲观锁第十一章 AQS第十二章 线程池原理12.1为什么要使用线程池 创建&#x2F;销毁线程需要消耗系统资源,线程池可复用已创建的线程 控制并发数量(主要原因),并发数量过多可能会导致资源消耗过多导致服务器崩溃 可以对线程做统一管理 12.2 线程池原理线程池顶层接口是Executor,TreadPoolExecutor是实现类 12.2.1 ThreadPoolExecutor提供的构造方法一共四个构造方法 涉及到5~7个参数 都有的 5 个 核心线程数 最大线程数 非核心线程闲置超时时长 时长单位 阻塞队列,维护等待执行的Runnable任务对象 两个非必须参数 指定线程工厂 默认defaultThreadFactory 拒绝处理策略 线程数量大于最大线程数就会采用拒绝处理策略 默认AbortPolicy 丢弃任务并抛出异常 第十三章 阻塞队列第十四章 锁接口和类第十五章 并发集合容器简介第十六章 CopyOnwrite第十七章 通信工具类第十八章 Fork&#x2F;Join框架第十九章 Java8 Stream并行计算原理第二十章 计划任务","categories":[{"name":"多线程","slug":"多线程","permalink":"https://gouguoqiang.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://gouguoqiang.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"JVM","slug":"all/7JVM","date":"2022-10-09T03:36:23.000Z","updated":"2022-10-09T05:24:28.014Z","comments":true,"path":"2022/10/09/all/7JVM/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/09/all/7JVM/","excerpt":"","text":"第一章 字节码篇分析一个对象的创建字节码D:\\IDEA\\projects\\Pinduo&gt;javap -verbose -p out&#x2F;production&#x2F;Pinduo&#x2F;P1&#x2F;djp1&#x2F;Main.class 123456789101112131415//// Source code recreated from a .class file by IntelliJ IDEA// (powered by FernFlower decompiler)//package P1.djp1;public class Main &#123; public Main() &#123; &#125; public static void main(String[] args) &#123; new Object(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869D:\\IDEA\\projects\\Pinduo&gt;javap -verbose -p out/production/Pinduo/P1/djp1/Main.classClassfile /D:/IDEA/projects/Pinduo/out/production/Pinduo/P1/djp1/Main.class Last modified 2022年9月23日; size 418 bytes MD5 checksum 339314e49862fe3b31f3c66703efb5ca Compiled from &quot;Main.java&quot;public class P1.djp1.Main minor version: 0 major version: 52 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #3 // P1/djp1/Main super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1Constant pool: #1 = Methodref #2.#19 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Class #20 // java/lang/Object #3 = Class #21 // P1/djp1/Main #4 = Utf8 &lt;init&gt; #5 = Utf8 ()V #6 = Utf8 Code #7 = Utf8 LineNumberTable #8 = Utf8 LocalVariableTable #9 = Utf8 this #10 = Utf8 LP1/djp1/Main; #11 = Utf8 main #12 = Utf8 ([Ljava/lang/String;)V #13 = Utf8 args #14 = Utf8 [Ljava/lang/String; #15 = Utf8 o #16 = Utf8 Ljava/lang/Object; #17 = Utf8 SourceFile #18 = Utf8 Main.java #19 = NameAndType #4:#5 // &quot;&lt;init&gt;&quot;:()V #20 = Utf8 java/lang/Object #21 = Utf8 P1/djp1/Main&#123; public P1.djp1.Main(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 7: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LP1/djp1/Main; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: return LineNumberTable: line 11: 0 line 13: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 args [Ljava/lang/String; 8 1 1 o Ljava/lang/Object;&#125;SourceFile: &quot;Main.java&quot; 123456789101112131415161718D:\\IDEA\\projects\\Pinduo&gt;javap -c out/production/Pinduo/P1/djp1/Main.classCompiled from &quot;Main.java&quot;public class P1.djp1.Main &#123; public P1.djp1.Main(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: return&#125; NEW ：如果找不到Class对象，则进行类加载。加载成功后，则在堆中分配内存，从Object 开始到本类路径上的所有属性值都要分配内存。分配完毕之后，进行零值初始化。在分配过程中，注意引用是占据存储空间的，它是一个变量，占用4个字节。这个指令完毕后，将指向实例对象的引用变量压入虚拟机栈顶。DUP ：在栈顶复制该引用变量，这时的栈顶有两个指向堆内实例对象的引用变量。如果 方法有参数，还需要把参数压人操作栈中。两个引用变量的目的不同，其中压至底下的引用用于赋值，或者保存到局部变量表，另一个栈顶的引用变量作为句柄调用相关方法。INVOKESPECIAL ：调用对象实例方法，通过栈顶的引用变量调用＜init&gt; 方法。 第二章 类的加载1. 概述注意：方法区只有HotSpot虚拟机有，J9，JRockit都没有 如果自己想手写一个Java虚拟机的话，主要考虑哪些结构呢？ 类加载器 执行引擎 Bootstrap -&gt; Ext -&gt; App(也叫系统) 组合关系 但是 有一个GetParent方法 URLcl -&gt; Ext -&gt; App 1.1 类加载器子系统类加载器子系统作用： ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。 加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射） 1.2 类加载器ClassLoader角色 class file存在于本地硬盘上，可以理解为设计师画在纸上的模板，而最终这个模板在执行的时候是要加载到JVM当中来根据这个文件实例化出n个一模一样的实例。 class file加载到JVM中，被称为DNA元数据模板，放在方法区。 在.class文件–&gt;JVM–&gt;最终成为元数据模板，此过程就要一个运输工具（类装载器Class Loader），扮演一个快递员的角色。 2. 类加载过程(生命周期)面试题 Java 类加载过程?（苏宁） 描述一下 JVM 加载 Class 文件的原理机制?（国美） JVM底层怎么加载class文件的？（蚂蚁金服） 类加载过程 （蚂蚁金服） Java 类加载过程? （百度） 描述一下 JVM 加载 Class 文件的原理机制? （蚂蚁金服） Java类加载过程 （美团） 描述一下JVM加载class文件的原理机制 （美团） 什么是类的加载？ （京东） 讲一下JVM加载一个类的过程 （京东） 概述12345678JAVApublic class HelloLoader &#123; public static void main(String[] args) &#123; System.out.println(&quot;谢谢ClassLoader加载我....&quot;); System.out.println(&quot;你的大恩大德，我下辈子再报！&quot;); &#125;&#125; 它加载(与对象创建区分)是怎么样的呢? 执行 main() 方法（静态方法）就需要先加载main方法所在类 HelloLoader 加载成功，则进行链接、初始化等操作。完成后调用 HelloLoader 类中的静态方法 main 加载失败则抛出异常 &#96;&#96;&#96;javaclass A {static { System.out.println(“1”);}A() { System.out.println(“a”);}}class B extends A {static { System.out.println(“2”);}B() { System.out.println(“b”);}}public class Main { public static void main(String[] args) &#123; B b = new B(); A a = new A(); // 12aba &#125; } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#### 2.1. 加载阶段**加载：**1. 通过一个类的全限定名获取定义此类的二进制字节流2. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构3. **在内存中生成一个代表这个类的java.lang.Class对象**，作为方法区这个类的各种数据的访问入口**加载class文件的方式：**1. 从本地系统中直接加载2. 通过网络获取，典型场景：Web Applet3. 从zip压缩包中读取，成为日后jar、war格式的基础4. 运行时计算生成，使用最多的是：动态代理技术5. 由其他文件生成，典型场景：JSP应用从专有数据库中提取.class文件，比较少见6. 从加密文件中获取，典型的防Class文件被反编译的保护措施**数组类的加载**创建数组类的情况稍微有些特殊，因为数组类本身并不是由类加载器负责创建，而是由JVM在运行时根据需要而直接创建的，但数组的元素类型仍然需要依靠类加载器去创建。创建数组类（下述简称A）的过程：1. 如果数组的元素类型是引用类型，那么就遵循定义的加载过程递归加载和创建数组A的元素类型；2. JVM使用指定的元素类型和数组维度来创建新的数组类。3. 如果数组的元素类型是引用类型，数组类的可访问性就由元素类型的可访问性决定。否则数组类的可访问性将被缺省定义为public。int[] arrString[] arrObject[] arr#### 2.2. 链接阶段链接分为三个子阶段：验证 -&gt; 准备 -&gt; 解析##### 验证(Verify)1. 目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全2. 主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。链接过程之验证阶段(Verification)当类加载到系统后，就开始链接操作，验证是链接操作的第一步。它的目的是保证加载的字节码是合法、合理并符合规范的。验证的步骤比较复杂，实际要验证的项目也很繁多，大体上Java虚拟机需要做以下检査，如图所示。整体说明：验证的内容则涵盖了类数据信息的格式验证、语义检查、字节码验证，以及符号引用验证等。- 其中格式验证会和装载阶段一起执行。验证通过之后，类加载器才会成功将类的二进制数据信息加载到方法区中。- 格式验证之外的验证操作将会在方法区中进行。**举例**使用 BinaryViewer软件查看字节码文件，其开头均为 CAFE BABE ，如果出现不合法的字节码文件，那么将会验证不通过。##### 准备(Prepare)1. 为类变量（static变量）分配内存并且设置该类变量的默认初始值，即零值2. 这里不包含用final修饰的static，因为final在编译的时候就会分配好了默认值，准备阶段会显式初始化3. 注意：这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中链接过程之准备阶段(Preparation)简言之，为类的静态变量分配内存，并将其初始化为默认值。在这个阶段，虚拟机就会为这个类分配相应的内存空间，并设置默认初始值。Java虚拟机为各类型变量默认的初始值如表所示。注意：Java并不支持boolean类型，对于boolean类型，内部实现是int,由于int的默认值是0,故对应的，boolean的默认值就是false。**举例**代码：变量a在准备阶段会赋初始值，但不是1，而是0，在初始化阶段会被赋值为 1```javaJAVApublic class HelloApp &#123; private static int a = 1;//prepare：a = 0 ---&gt; initial : a = 1 public static void main(String[] args) &#123; System.out.println(a); &#125;&#125; 解析(Resolve) 将常量池内的符号引用转换为直接引用的过程 事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行 符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java虚拟机规范》的class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT Class info、CONSTANT Fieldref info、CONSTANT Methodref info等 符号引用 反编译 class 文件后可以查看符号引用，下面带# 的就是符号引用 链接过程之解析阶段(Resolution) 简言之，将类、接口、字段和方法的符号引用转为直接引用。 1.具体描述: 符号引用就是一些字面量的引用，和虚拟机的内部数据结构和和内存布局无关。比较容易理解的就是在Class类文件中，通过常量池进行了大量的符号引用。但是在程序实际运行时，只有符号引用是不够的，比如当如下println()方法被调用时，系统需要明确知道该方法的位置。 举例：输出操作System.out.println()对应的字节码： invokevirtual #24 以方法为例，Java虚拟机为每个类都准备了一张方法表，将其所有的方法都列在表中，当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法。通过解析操作，符号引用就可以转变为目标方法在类中方法表中的位置，从而使得方法被成功调用。 2.小结： 所谓解析就是将符号引用转为直接引用，也就是得到类、字段、方法在内存中的指针或者偏移量。因此，可以说，如果直接引用存在，那么可以肯定系统中存在该类、方法或者字段。但只存在符号引用，不能确定系统中一定存在该结构。 不过Java虚拟机规范并没有明确要求解析阶段一定要按照顺序执行。在HotSpot VM中，加载、验证、准备和初始化会按照顺序有条不紊地执行，但链接阶段中的解析操作往往会伴随着JVM在执行完初始化之后再执行。 2.3. 初始化阶段类的初始化时机 创建类的实例 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（比如：Class.forName(“com.atguigu.Test”)） 初始化一个类的子类 Java虚拟机启动时被标明为启动类的类 JDK7开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化 除了以上七种情况，其他使用Java类的方式都被看作是对类的被动使用，都不会导致类的初始化，即不会执行初始化阶段（不会调用 clinit() 方法和 init() 方法） clinit() 初始化阶段就是执行类构造器方法&lt;clinit&gt;()的过程 此方法不需定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。也就是说，当我们代码中包含static变量的时候，就会有clinit方法 &lt;clinit&gt;()方法中的指令按语句在源文件中出现的顺序执行 &lt;clinit&gt;()不同于类的构造器。（关联：构造器是虚拟机视角下的&lt;init&gt;()） 若该类具有父类，JVM会保证子类的&lt;clinit&gt;()执行前，父类的&lt;clinit&gt;()已经执行完毕 虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁 IDEA 中安装 JClassLib Bytecode viewer 插件，可以很方便的看字节码。安装过程可以自行百度 Java编译器并不会为所有的类都产生clinit()初始化方法。哪些类在编译为字节码后，字节码文件中将不会包含()方法？ 一个类中并没有声明任何的类变量，也没有静态代码块时 一个类中声明类变量，但是没有明确使用类变量的初始化语句以及静态代码块来执行初始化操作时 一个类中包含static final修饰的基本数据类型的字段，这些类字段初始化语句采用编译时常量表达式 查看下面这个代码的字节码，可以发现有一个&lt;clinit&gt;()方法。 123456789101112131415161718192021222324JAVApublic class ClassInitTest &#123; private static int num = 1; static&#123; num = 2; number = 20; System.out.println(num); //System.out.println(number);//报错：非法的前向引用。即在定义之前使用 &#125; /** * 1、linking之prepare: number = 0 --&gt; initial: 20 --&gt; 10 * 2、这里因为静态代码块出现在声明变量语句前面，所以之前被准备阶段为0的number变量会 * 首先被初始化为20，再接着被初始化成10（这也是面试时常考的问题哦） * */ private static int number = 10; public static void main(String[] args) &#123; System.out.println(ClassInitTest.num);//2 System.out.println(ClassInitTest.number);//10 &#125;&#125; 虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁 类的初始化情况：主动使用vs被动使用Java程序对类的使用分为两种：主动使用 和 被动使用。 主动使用的说明：Class只有在必须要首次使用的时候才会被装载，Java虚拟机不会无条件地装载Class类型。Java虚拟机规定，一个类或接口在初次使用前，必须要进行初始化。这里指的“使用”，是指主动使用。 主动使用只有下列几种情况：（即：如果出现如下的情况，则会对类进行初始化操作。而初始化操作之前的加载、验证、准备已经完成。） 当创建一个类的实例时，比如使用new关键字，或者通过反射、克隆、反序列化。 当调用类的静态方法时，即当使用了字节码invokestatic指令。 当使用类、接口的静态字段时(final修饰特殊考虑)，比如，使用getstatic或者putstatic指令。 当使用java.lang.reflect包中的方法反射类的方法时。比如：Class.forName(“com.atguigu.java.Test”) todo 当初始化子类时，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 如果一个接口定义了default方法，那么直接实现或者间接实现该接口的类的初始化，该接口要在其之前被初始化。 todo 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。（涉及解析REF_getStatic、REF_putStatic、REF_invokeStatic方法句柄对应的类） todo 被动使用的情况除了以上的情况属于主动使用，其他的情况均属于被动使用。被动使用不会引起类的初始化。 也就是说：并不是在代码中出现的类，就一定会被加载或者初始化。如果不符合主动使用的条件，类就不会初始化。 当访问一个静态字段时，只有真正声明这个字段的类才会被初始化。 当通过子类引用父类的静态变量，不会导致子类初始化 通过数组定义类引用，不会触发此类的初始化 引用常量不会触发此类或接口的初始化。因为常量在链接阶段就已经被显式赋值了。 调用ClassLoader类的loadClass()方法加载一个类，并不是对类的主动使用，不会导致类的初始化。 被动的使用，意味着不需要执行初始化环节，意味着没有()的调用。 2.4. 类的使用任何一个类型在使用之前都必须经历过完整的加载、链接和初始化3个类加载步骤。一旦一个类型成功经历过这3个步骤之后，便“万事俱备，只欠东风”，就等着开发者使用了。 开发人员可以在程序中访问和调用它的静态类成员信息（比如：静态字段、静态方法），或者使用new关键字为其创建对象实例。 2.5. 类的卸载任何一个类型在使用之前都必须经历过完整的加载、链接和初始化3个类加载步骤。一旦一个类型成功经历过这3个步骤之后，便“万事俱备，只欠东风”，就等着开发者使用了。 开发人员可以在程序中访问和调用它的静态类成员信息（比如：静态字段、静态方法），或者使用new关键字为其创建对象实例。 当Sample类被加载、链接和初始化后，它的生命周期就开始了。当代表Sample类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，Sample类在方法区内的数据也会被卸载，从而结束Sample类的生命周期。(因为双向引用所以除非类加载器被卸载) 类的卸载 (1) 启动类加载器加载的类型在整个运行期间是不可能被卸载的(jvm和jls规范) (2) 被系统类加载器和扩展类加载器加载的类型在运行期间不太可能被卸载，因为系统类加载器实例或者扩展类的实例基本上在整个运行期间总能直接或者间接的访问的到，其达到unreachable的可能性极小。 (3) 被开发者自定义的类加载器实例加载的类型只有在很简单的上下文环境中才能被卸载，而且一般还要借助于强制调用虚拟机的垃圾收集功能才可以做到。可以预想，稍微复杂点的应用场景中(比如：很多时候用户在开发自定义类加载器实例的时候采用缓存的策略以提高系统性能)，被加载的类型在运行期间也是几乎不太可能被卸载的(至少卸载的时间是不确定的)。 综合以上三点，一个已经加载的类型被卸载的几率很小至少被卸载的时间是不确定的。同时我们可以看的出来，开发者在开发代码时候，不应该对虚拟机的类型卸载做任何假设的前提下，来实现系统中的特定功能。 方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。 HotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。 判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件： 该类所有的实例都已经被回收。也就是Java堆中不存在该类及其任何派生子类的实例。 加载该类的类加载器已经被回收。这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。 2.6. 总结1. 加载:将字节码静态数据装载到JVM中成为运行时数据 2. 链接阶段 1. 验证 1. 验证一些信息 2. 准备 1. 为类的静态变量分配内存，并将其初始化为默认值,final static 在编译时就初始化默认值了 在准备阶段直接赋予真正的值 3. 解析 1. 将符号引用转化为直接引用 3. 初始化 1. clinit()初始化.class 2. init()只是new时进行调用的方法与类加载无关 3. 类的加载器面试题 什么是类加载器，类加载器有哪些?（苏宁） 简单说说你了解的类加载器（拼多多） 类加载器都有哪些？（百度） 类加载器有哪些？ （腾讯） 什么是类加载器，类加载器有哪些？（字节跳动） 1. 类的加载分类：显式加载 vs 隐式加载class文件的显式加载与隐式加载的方式是指JVM加载class文件到内存的方式。 显式加载：指的是在代码中通过调用ClassLoader加载class对象，如直接使用Class.forName(name)或this.getClass().getClassLoader().loadClass()加载class对象。 隐式加载：则是不直接在代码中调用ClassLoader的方法加载class对象，而是通过虚拟机自动加载到内存中，如在加载某个类的class文件时，该类的class文件中引用了另外一个类的对象，此时额外引用的类将通过JVM自动加载到内存中。 在日常开发以上两种方式一般会混合使用。 2. 类加载机制的必要性一般情况下，Java开发人员并不需要在程序中显式地使用类加载器，但是了解类加载器的加载机制却显得至关重要。从以下几个方面说： 避免在开发中遇到 java.lang.ClassNotFoundException异常或java.lang.NoClassDefFoundError异常时，手足无措。只有了解类加载器的加载机制才能够在出现异常的时候快速地根据错误异常日志定位问题和解决问题 需要支持类的动态加载或需要对编译后的字节码文件进行加解密操作时，就需要与类加载器打交道了。 开发人员可以在程序中编写自定义类加载器来重新定义类的加载规则，以便实现一些自定义的处理逻辑。 3. 加载的类是唯一的吗?1.何为类的唯一性？ 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确认其在Java虚拟机中的唯一性。每一个类加载器，都拥有一个独立的类名称空间：比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义。否则，即使这两个类源自同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这两个类就必定不相等。 2.命名空间 每个类加载器都有自己的命名空间，命名空间由该加载器及所有的父加载器所加载的类组成 在同一命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类 在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 在大型应用中，我们往往借助这一特性，来运行同一个类的不同版本。 4. 类加载的特性通常类加载机制有三个基本特征： 双亲委派模型。但不是所有类加载都遵守这个模型，有的时候，启动类加载器所加载的类型，是可能要加载用户代码的，比如JDK内部的ServiceProvider&#x2F;ServiceLoader机制，用户可以在标准API框架上，提供自己的实现，JDK也需要提供些默认的参考实现。例如，Java 中JNDI、JDBC、文件系统、Cipher等很多方面，都是利用的这种机制，这种情况就不会用双亲委派模型去加载，而是利用所谓的上下文加载器。 todo 可见性。子类加载器可以访问父加载器加载的类型，但是反过来是不允许的。不然，因为缺少必要的隔离，我们就没有办法利用类加载器去实现容器的逻辑。 todo 单一性。由于父加载器的类型对于子加载器是可见的，所以父加载器中加载过的类型，就不会在子加载器中重复加载。但是注意，类加载器“邻居”间，同一类型仍然可以被加载多次，因为互相并不可见。 todo 5. 类加载器的分类说明JVM支持两种类型的类加载器，分别为引导类加载器（Bootstrap ClassLoader）和自定义类加载器（User-Defined ClassLoader）。 从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器。 子父类的关系 除了顶层的启动类加载器外，其余的类加载器都应当有自己的“父类”加载器。 不同类加载器看似是继承（Inheritance）关系，实际上是包含关系。在下层加载器中，包含着上层加载器的引用。 启动类加载器（引导类加载器，Bootstrap ClassLoader） 这个类加载使用C&#x2F;C++语言实现的，嵌套在JVM内部。 它用来加载Java的核心库（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar或sun.boot.class.path路径下的内容）。用于提供JVM自身需要的类。 并不继承自java.lang.ClassLoader，没有父加载器。 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类 加载扩展类和应用程序类加载器，并指定为他们的父类加载器。 扩展类加载器（Extension ClassLoader） Java语言编写，由sun.misc.Launcher$ExtClassLoader实现。 继承于ClassLoader类 父类加载器为启动类加载器 从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre&#x2F;lib&#x2F;ext子目录下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 应用程序类加载器（系统类加载器，AppClassLoader） java语言编写，由sun.misc.Launcher$AppClassLoader实现 继承于ClassLoader类 父类加载器为扩展类加载器 它负责加载环境变量classpath或系统属性 java.class.path 指定路径下的类库 应用程序中的类加载器默认是系统类加载器。 它是用户自定义类加载器的默认父加载器 通过ClassLoader的getSystemClassLoader()方法可以获取到该类加载器 用户自定义类加载器 在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的。在必要时，我们还可以自定义类加载器，来定制类的加载方式。 体现Java语言强大生命力和巨大魅力的关键因素之一便是,Java开发者可以自定义类加载器来实现类库的动态加载，加载源可以是本地的JAR包，也可以是网络上的远程资源。 通过类加载器可以实现非常绝妙的插件机制，这方面的实际应用案例举不胜举。例如，著名的OSGI组件框架，再如Eclipse的插件机制。类加载器为应用程序提供了一种动态增加新功能的机制，这种机制无须重新打包发布应用程序就能实现。 同时，自定义加载器能够实现应用隔离，例如 Tomcat，Spring等中间件和组件框架都在内部实现了自定义的加载器，并通过自定义加载器隔离不同的组件模块。这种机制比C&#x2F;C++程序要好太多，想不修改C&#x2F;C++程序就能为其新增功能，几乎是不可能的，仅仅一个兼容性便能阻挡住所有美好的设想。 所有用户自定义类加载器通常需要继承于抽象类java.lang.ClassLoader。 待复习tomcat机制 4. cl源码剖析及相关机制第三章 运行时数据区 面试题 说一说JVM的内存结构是什么样子的,每个区域放什么，各有什么特点？（快手、搜狐） JVM的内存结构，及各个结构的内容。（vivo） 详细介绍一下内存结构（墨迹天气） JVM内存模型有哪些？（龙湖地产） Java虚拟机中内存划分为哪些区域（高德地图） JVM内存模型（中国计算机研究院、亚信） JVM内存结构（花旗银行） JVM 内存分哪几个区，每个区的作用是什么?（唯品会） 详解JVM内存模型（360） JVM有那些组成，堆，栈各放了什么东西？（搜狐、万达集团） JVM的内存模型，线程独有的放在哪里？哪些是线程共享的？哪些是线程独占的？（万达集团） 讲一下为什么JVM要分为堆、方法区等？原理是什么？（小米、搜狐） JVM的内存模型，线程独有的放在哪里？哪些是线程共享的？哪些是线程独占的？（菜鸟） 简单说一下JVM内存结构（浪潮） 说一下JVM内存模型吧，有哪些区？分别干什么的？ (百度) JVM的内存结构划分是什么样子的？ (支付宝) JVM 内存分哪几个区，每个区的作用是什么? (蚂蚁金服) Java虚拟机内存模型能说说吗？ (蚂蚁金服) JVM内存分布&#x2F;内存结构？ (蚂蚁金服) 讲讲JVM分区 (携程) 讲一下JVM内存布局 (滴滴) Java的内存分区 (字节跳动) 讲讲JVM运行时数据库区 (字节跳动) JVM内存模型以及分区，需要详细到每个区放什么。 (天猫) JVM 内存分哪几个区，每个区的作用是什么? (拼多多) JVM的内存布局以及垃圾回收原理及过程讲一下 (京东) 1. 程序计数寄存器（Program Counter Register）每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。它是唯一一个在Java 虚拟机规范中没有规定任何OutOtMemoryError 情况的区域。 使用PC寄存器存储字节码指令地址有什么用呢？ （为什么使用PC寄存器记录当前线程的执行地址呢？）线程切换 因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。 JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。 PC寄存器为什么会被设定为线程私有？ 我们都知道所谓的多线程在一个特定的时间段内只会执行其中某一个线程的方法，CPU会不停地做任务切换，这样必然导致经常中断或恢复，如何保证分毫无差呢？为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PC寄存器，这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。 2. JVM栈概述不存在GC ; 存在OOM StackOverFlowError？OutOfMemoryError？ Java 虚拟机规范允许Java栈的大小是动态的或者是固定不变的。 如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将会抛出一个 StackOverflowError 异常。 如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出—个 OutOfMemoryError 异常。 如何设置栈内存的大小？ -Xss size (即：-XX:ThreadStackSize) 一般默认为512k-1024k，取决于操作系统。 栈的大小直接决定了函数调用的最大可达深度。 12345678910public class Main &#123; private static int count = 1; public static void main(String[] args) &#123; System.out.println(count++); main(args); &#125;&#125;SOF OOM: 死循环创建线程 方法和栈桢之间存在怎样的关系？ 在这个线程上正在执行的每个方法都各自对应一个栈帧（Stack Frame）。 栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。 栈帧内部结构0. 概述每个栈帧中存储着： 局部变量表（Local Variables） 操作数栈（Operand Stack）（或表达式栈） 动态链接(Dynamic Linking) （或指向运行时常量池的方法引用） 方法返回地址（Return Address）（或方法正常退出或者异常退出的定义） 一些附加信息 1. 局部变量表局部变量表（local variables) 局部变量表也被称之为局部变量数组或本地变量表 定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，这些数据类型包括各类基本数据类型(8种)、对象引用（reference），以及returnAddress类型。 局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。 方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。 局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。 slot 参数值的存放总是在局部变量数组的index为0开始，到数组长度-1的索引结束。 局部变量表，最基本的存储单元是Slot（变量槽） 在局部变量表里，32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double)占用两个slot。 byte 、short 、char 在存储前被转换为int，boolean 也被转换为int，0 表示false ，非0 表示true。 long 和double 则占据两个Slot。 JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值 当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个Slot上 如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。(比如：访问long或double类型变量） 如果当前帧是由构造方法或者实例方法创建的，那么该对象引用this将会存放在index为0的slot处，其余的参数按照参数表顺序继续排列。 栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。 参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。 我们知道类变量表有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。 和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。 public void test() {int i; System.out.println(i); } 这样的代码是错误的，没有赋值不能够使用。 局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。 2. 操作数栈操作数栈（Operand Stack） 我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。 每一个独立的栈帧中除了包含局部变量表以外，还包含一个后进先出（Last-In-First-Out）的操作数栈，也可以称之为表达式栈（Expression Stack）。 操作数栈就是JVM执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，这个方法的操作数栈是空的。 每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的Code属性中，为max_stack的值。 栈中的任何一个元素都是可以任意的Java数据类型。 32bit的类型占用一个栈单位深度 64bit的类型占用两个栈单位深度 操作数栈，在方法执行过程中，根据字节码指令，并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈（push）和出栈（pop）操作，往栈中写入数据或提取数据来完成一次数据访问。 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如：执行复制、交换、求和等操作 如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。 栈顶缓存技术 前面提过，基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读&#x2F;写次数。 由于操作数是存储在内存中的，因此频繁地执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存（ToS，Top-of-Stack Cashing）技术，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率。 3. 动态链接动态链接（或指向运行时常量池的方法引用） 每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接（Dynamic Linking）。比如：invokedynamic指令 在Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在class文件的常量池里。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用。 public void testGetSum(){**int i &#x3D; getSum();int j &#x3D; 10;} 4. 方法返回地址 存放调用该方法的pc寄存器的值。 一个方法的结束，有两种方式： 正常执行完成 出现未处理的异常，非正常退出 无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的pc计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。 5. 一些附加信息栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息。 面试扩展问题问题一：栈溢出的情况? 栈溢出:StackOverflowError; 举个简单的例子:在main方法中调用main方法,就会不断压栈执行,直到栈溢出; 栈的大小可以是固定大小的,也可以是动态变化（动态扩展）的。 如果是固定的,可以通过-Xss设置栈的大小; 如果是动态变化的,当栈大小到达了整个内存空间不足了,就是抛出OutOfMemory异常(java.lang.OutOfMemoryError) 问题二：调整栈大小,就能保证不出现溢出吗? 不能。因为调整栈大小,只会减少出现溢出的可能,栈大小不是可以无限扩大的,所以不能保证不出现溢出 问题三：分配的栈内存越大越好吗? 不是,因为增加栈大小，会造成每个线程的栈都变的很大,使得一定的栈空间下,能创建的线程数量会变小 问题四：垃圾回收是否会涉及到虚拟机栈? 不会;垃圾回收只会涉及到方法区和堆中,方法区和堆也会存在溢出的可能; 程序计数器,只记录运行下一行的地址,不存在溢出和垃圾回收; 虚拟机栈和本地方法栈,都是只涉及压栈和出栈,可能存在栈溢出,不存在垃圾回收。 问题五：方法中定义的局部变量是否线程安全? 具体问题具体分析,见分析代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344/**方法中定义的局部变量是否线程安全? 具体问题具体分析 * @author shkstart * @create 15:53 */public class LocalVariableThreadSafe &#123;//s1的声明方式是线程安全的,因为线程私有，在线程内创建的s1 ，不会被其它线程调用public static void method1() &#123;//StringBuilder:线程不安全StringBuilder s1 = new StringBuilder(); s1.append(&quot;a&quot;); s1.append(&quot;b&quot;);//...&#125;//stringBuilder的操作过程：是线程不安全的， // 因为stringBuilder是外面传进来的，有可能被多个线程调用public static void method2(StringBuilder stringBuilder) &#123; stringBuilder.append(&quot;a&quot;); stringBuilder.append(&quot;b&quot;);//...&#125;//stringBuilder的操作：是线程不安全的；因为返回了一个stringBuilder， // stringBuilder有可能被其他线程共享public static StringBuilder method3() &#123; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(&quot;a&quot;); stringBuilder.append(&quot;b&quot;);return stringBuilder; &#125;//stringBuilder的操作：是线程安全的；因为返回了一个stringBuilder.toString()相当于new了一个String， // 所以stringBuilder没有被其他线程共享的可能public static String method4() &#123; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(&quot;a&quot;); stringBuilder.append(&quot;b&quot;);return stringBuilder.toString();/** * 结论：如果局部变量在内部产生并在内部消亡的，那就是线程安全的 */&#125;&#125; 3. 本地方法接口与本地方法栈Java使用起来非常方便，然而有些层次的任务用Java实现起来不容易，或者我们对程序的效率很在意时，问题就来了。 与Java环境外交互： 有时Java应用需要与Java外面的环境交互，这是本地方法存在的主要原因。你可以想想Java需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐的细节。 与操作系统交互： JVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一些底层系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的。还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。 Sun’s Java Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用Java实现的，它也通过一些本地方法与外界交互。例如：类java.lang.Thread 的 setPriority()方法是用Java实现的，但是它实现调用的是该类里的本地方法setPriority0()。这个本地方法是用C实现的，并被植入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win32 SetPriority() API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。 4. 堆概述 《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。（The heap is the run-time data area from which memory for all class instances and arrays is allocated ) 数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。 我要说的是：“几乎”所有的对象实例都在这里分配内存。——从实际使用角度看的。 所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer, TLAB)。 堆的内部结构 几乎所有的Java对象都是在Eden区被new出来的。 绝大部分的Java对象的销毁都在新生代进行了。 IBM 公司的专门研究表明，新生代中 80% 的对象都是“朝生夕死”的。 如何设置堆内存大小？如何设置新生代与老年代比例？ 下面这参数开发中一般不会调： 配置新生代与老年代在堆结构的占比。 默认**-XX:NewRatio&#x3D;2**，表示新生代占1，老年代占2，新生代占整个堆的1&#x2F;3 可以修改-XX:NewRatio&#x3D;4，表示新生代占1，老年代占4，新生代占整个堆的1&#x2F;5 可以使用选项”**-Xmn**”设置新生代最大内存大小 这个参数一般使用默认值就可以了。 如何设置Eden、幸存者区比例？ 在HotSpot中，Eden空间和另外两个Survivor空间缺省所占的比例是8:1:1 当然开发人员可以通过选项“**-XX:SurvivorRatio”调整这个空间比例。比如-XX:SurvivorRatio&#x3D;8** OOM举例​ 参数设置小结 什么是空间分配担保策略？（渣打银行） 什么是空间分配担保策略？（顺丰） 什么是空间分配担保策略？（腾讯、百度） 1234567891011121314151617/** * 测试堆空间常用的jvm参数： * -XX:+PrintFlagsInitial : 查看所有的参数的默认初始值 * -XX:+PrintFlagsFinal ：查看所有的参数的最终值（可能会存在修改，不再是初始值） * 具体查看某个参数的指令： jps：查看当前运行中的进程 * jinfo -flag SurvivorRatio 进程id * * -Xms：初始堆空间内存 （默认为物理内存的1/64） * -Xmx：最大堆空间内存（默认为物理内存的1/4） * -Xmn：设置新生代的大小。(初始值及最大值) * -XX:NewRatio：配置新生代与老年代在堆结构的占比 * -XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例 * -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄 * -XX:+PrintGCDetails：输出详细的GC处理日志 * 打印gc简要信息：① -XX:+PrintGC ② -verbose:gc * -XX:HandlePromotionFailure：是否设置空间分配担保 */ 对象分配1.new的对象先放伊甸园区。此区有大小限制。 2.当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收(Minor GC&#x2F;YGC)，将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区 3.然后将伊甸园中的剩余对象移动到幸存者0区。 4**.如果再次触发垃圾回收，此时上次幸存下来的放到幸存者0区的，如果没有回收，就会放到幸存者1区**。 5.如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区。 6.啥时候能去养老区呢？可以设置次数。默认是15次。 可以设置参数：**-XX:MaxTenuringThreshold&#x3D;** 设置对象晋升老年代的年龄阈值。 7.在养老区，相对悠闲。当养老区内存不足时，再次触发GC：Major GC，进行养老区的内存清理。 8.若养老区执行了Major GC之后发现依然无法进行对象的保存，就会产生OOM异常 空间分配担保1、在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。 如果大于，则此次Minor GC是安全的 如果小于，则虚拟机会查看**-XX:HandlePromotionFailure**设置值是否允担保失败。 如果HandlePromotionFailure&#x3D;true，那么会继续检查 老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小 。 如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的； 如果小于，则进行一次Full GC。 如果HandlePromotionFailure&#x3D;false，则进行一次Full GC。 5. 方法区1. 栈、堆、方法区的关系 2. 什么是TLAB？ 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。 据我所知所有OpenJDK衍生出来的JVM都提供了TLAB的设计。 3. 方法区在哪里《Java虚拟机规范》中明确说明: “尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。” 但对于HotSpotJVM而言，方法区还有一个别名叫做Non-Heap(非堆)，目的就是要和堆分开。 所以，方法区看作是一块独立于Java 堆的内存空间。 4. 方法区的理解方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutOfMemoryError: PermGen space 或者 java.lang.OutOfMemoryError: Metaspace加载大量的第三方的jar包；Tomcat部署的工程过多（30-50个）；大量动态的生成反射类关闭JVM就会释放这个区域的内存。 5. 方法区的演进到了JDK 8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替￼元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存。永久代、元空间二者并不只是名字变了，内部结构也调整了。根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常。 6. 设置方法区内存的大小 方法区的大小不必是固定的，jvm可以根据应用的需要动态调整。 jdk7及以前： 通过-XX:PermSize来设置永久代初始分配空间。默认值是20.75M -XX:MaxPermSize来设定永久代最大可分配空间。32位机器默认是64M，64位机器模式是82M 当JVM加载的类信息容量超过了这个值，会报异常OutOfMemoryError:PermGen space 。 jdk8及以后： 元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定,替代上述原有的两个参数。 默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize 的值是-1，即没有限制。 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError: Metaspace -XX:MetaspaceSize：设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的-XX:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。 如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC ，建议将-XX:MetaspaceSize设置为一个相对较高的值。 在JDK8 及以上版本中，设定MaxPermSize 参数， JVM在启动时并不会报错，但是会提示： Java HotSpot 64Bit Server VM warning: ignoring option MaxPermSize&#x3D;2560m; support was removed in 8.0 。 第四章 对象的内存布局1. 对象的实例化1.1 有几种创建对象的方式 实操 todo new 变形1: Xxx静态方法的new 变形2: XxxBuilder&#x2F;XxxFactory的静态方法 Class的newInstance() Constructor的newInstance() clone() 反序列化 第三发库Objenesis,利用了asm字节码技术,动态生成Constructor 典型用途： 需要在不调用构造函数的情况下实例化对象是一项相当特殊的任务，但是在某些情况下这是有用的： 序列化，远程调用和持久化-对象需要被实例化并恢复到特定的状态，而不需要调用代码 代理、 AOP 库和 mock 对象-类可以被子类继承而子类不用担心父类的构造器 容器框架-对象可以以非标准的方式动态地实例化 Spring中的封装的元数据读取器等就是利用了asm,需要注意的是，SimpleMetadataReader去解析类时，使用的ASM技术。 并不是等Java类加载到JVM在解析,而是直接读取字节码文件 为什么要使用ASM技术，Spring启动的时候需要去扫描，如果指定的包路径比较宽泛，那么扫描的类是非常多的，那如果在Spring启动时就把这些类全部加载进JVM了，这样不太好，所以使用了ASM技术。 1.2 创建对象的过程1.2.1 从字节码角度看待对象创建过程 : 见字节码篇1.2.2 从执行步骤角度分析 判断对象对应的类是否加载,链接,初始化 虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。（即判断类元信息是否存在）。 如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader+包名+类名为Key进行查找对应的.class 文件。 如果没有找到文件，则抛出ClassNotFoundException 异常。 如果找到，则进行类加载，并生成对应的Class类对象。 为对象分配内存 指针碰撞 如果内存规整，使用指针碰撞 如果内存是规整的，那么虚拟机将采用的是指针碰撞法（Bump The Pointer）来为对象分配内存。意思是所有用过的内存在一边，空闲的内存在另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针向空闲那边挪动一段与对象大小相等的距离罢了。 如果垃圾收集器选择的是Serial、ParNew这种基于压缩算法的，虚拟机采用这种分配方式。 一般使用带有compact（整理）过程的收集器时，使用指针碰撞。 空闲列表 如果内存不规整，虚拟机需要维护一个列表，使用空闲列表分配 如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表法来为对象分配内存。意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式称为“空闲列表（Free List）”。 处理并发安全问题 在分配内存空间时，另外一个问题是及时保证new对象时候的线程安全性：创建对象是非常频繁的操作，虚拟机需要解决并发问题。 虚拟机采用了两种方式解决并发问题: CAS ( Compare And Swap ）失败重试、区域加锁：保证指针更新操作的原子性; TLAB 把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区，（TLAB ，Thread Local Allocation Buffer）虚拟机是否使用TLAB，可以通过-XX:+&#x2F;-UseTLAB参数来设定。 初始化分配到的空间 内存分配结束，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。这一步保证了对象的实例字段在Java代码中可以不用赋初始值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象的对象头 将对象的所属类（即类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。 执行init方法进行初始化 在Java程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量。 因此一般来说（由字节码中是否跟随有invokespecial指令所决定），new指令之后会接着就是执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全创建出来。 2. 对象的内存布局 对象头 对象头：它主要包括两部分。 一个是对象自身的运行时元数据(mark word)。 哈希值(hashcode)：对象在堆空间中都有一个首地址值，栈空间的引用根据这个地址指向堆中的对象，这就是哈希值起的作用 GC分代年龄：对象首先是在Eden中创建的，在经过多次GC后，如果没有被进行回收，就会在survivor中来回移动，其对应的年龄计数器会发生变化，达到阈值后会进入养老区 锁状态标志，在同步中判断该对象是否是锁 线程持有的锁 线程偏向ID 偏向时间戳 另一个是类型指针，指向元数据区的类元数据InstanceKlass，确定该对象所属的类型 此外，如果对象是一个数组，对象头中还必须有一块用于记录数组的长度的数据。 因为正常对象元数据就知道对象的确切大小。所以数组必须得知道长度。 实例数据 作用： 它是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段（包括从父类继承下来的和本身拥有的字段）。 这里需要遵循的一些规则： 相同宽度的字段总是被分配在一起 父类中定义的变量会出现在子类之前（因为父类的加载是优先于子类加载的） 如果CompactFields参数为true(默认为true)：子类的窄变量可能插入到父类变量的空隙 对齐填充 对齐填充：不是必须的，也没特别含义，仅仅起到占位符的作用 3. 对象的访问定位 句柄访问 实现：堆需要划分出一块内存来做句柄池，reference中存储对象的句柄池地址，句柄中包含对象实例与类型数据各自具体的地址信息。 好处：reference中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针，reference本身不需要被修改。 直接使用指针访问 实现：reference中存储的就是对象的地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销。 好处：速度更快，java中对象访问频繁，每次访问都节省了一次指针定位的时间开销。 HotSpot这里主要使用第2种方式：直接指针访问 JVM可以通过对象引用准确定位到Java堆区中的instanceOopDesc对象，这样既可成功访问到对象的实例信息，当需要访问目标对象的具体类型时，JVM则会通过存储在instanceOopDesc中的元数据指针定位到存储在方法区中的instanceKlass对象上。 第五章 执行引擎篇第六章 垃圾回收篇从次数上讲：频繁收集Young区较少收集Old区基本不动Perm区（或元空间） 1.垃圾回收算法1.1标记算法1.1.1引用计数法原理： 对于一个对象A，只要有任何一个对象引用了A ，则A 的引用计数器就加1，当引用失效时，引用计数器就减1。只要对象A 的引用计数器的值为0，即表示对象A不可能再被使用，可进行回收。 优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。 缺点： 缺点1：它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。 缺点2：每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。 缺点3：引用计数器有一个严重的问题，即无法处理循环引用的情况。这是一条致命缺陷，导致在Java 的垃圾回收器中没有使用这类算法。 引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的Python，它更是同时支持引用计数和垃圾收集机制。 具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。 Java并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。 Python如何解决循环引用？ 手动解除：很好理解，就是在合适的时机，解除引用关系。 使用弱引用weakref， weakref是Python提供的标准库，旨在解决循环引用。 1.1.2可达性分析算法原理： 其原理简单来说，就是将对象及其引用关系看作一个图，选定活动的对象作为 GC Roots，然后跟踪引用链条，如果一个对象和GC Roots之间不可达，也就是不存在引用链条，那么即可认为是可回收对象。 优点： 实现简单，执行高效 ，有效的解决循环引用的问题，防止内存泄漏。 GC root在Java 语言中， GC Roots 包括以下几类元素： 虚拟机栈中引用的对象 比如：各个线程被调用的方法中使用到的参数、局部变量等。 本地方法栈内JNI(通常说的本地方法)引用的对象 类静态属性引用的对象 比如：Java类的引用类型静态变量 方法区中常量引用的对象 比如：字符串常量池（String Table）里的引用 所有被同步锁synchronized持有的对象 Java虚拟机内部的引用。 基本数据类型对应的Class对象，一些常驻的异常对象（如：NullPointerException、OutOfMemoryError），系统类加载器。 反映java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。比如：分代收集和局部回收（Partial GC）。 不太了解细节 如果只针对Java堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，这个区域的对象完全有可能被其他区域的对象所引用，这时候就需要一并将关联的区域对象也加入GC Roots集合中去考虑，才能保证可达性分析的准确性。 小技巧： 由于Root 采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个Root 。 STW 如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。 这点也是导致GC进行时必须“Stop The World”的一个重要原因。 即使是号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。 1.2.清除算法标记清除标记-清除（Mark - Sweep）算法 背景： 标记 - 清除算法（ Mark-Sweep ）是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并并应用于Lisp语言。 执行过程： 当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。 标记：Collector从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的Header中记录为可达对象。 清除：Collector对堆内存从头到尾进行线性的遍历，如果发现某个对象在其Header中没有标记为可达对象，则将其回收。 （很多书、视频讲错了！说是标记的垃圾对象。这里要注意了！） 缺点： 1、效率比较低：递归与全堆对象遍历两次 2、在进行GC的时候，需要停止整个应用程序，导致用户体验差 3、这种方式清理出来的空闲内存是不连续的，产生内存碎片。 注意：何为清除? 这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放。 复制算法核心思想： 将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。 优点： 没有标记和清除过程，实现简单，运行高效 复制过去以后保证空间的连续性，不会出现“碎片”问题。 缺点： 此算法的缺点也是很明显的，就是需要两倍的内存空间。 对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小。 特别的： 如果系统中的存活对象很多，复制算法不会很理想。因为复制算法需要复制的存活对象数量并不会太大,或者说非常低才行。 应用场景： 在新生代，对常规应用的垃圾回收，一次通常可以回收70%-99%的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。 比如：IBM 公司的专门研究表明，新生代中 80% 的对象都是“朝生夕死”的。 标记压缩标记-压缩（或标记-整理、Mark - Compact）算法 背景： 复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，基于老年代垃圾回收的特性，需要使用其他的算法。 标记－清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以JVM 的设计者需要在此基础之上进行改进。标记 - 压缩（Mark - Compact）算法由此诞生。 执行过程： 第一阶段和标记-清除算法一样，从根节点开始标记所有被引用对象 第二阶段将所有的存活对象压缩到内存的一端，按顺序排放。 之后， 清理边界外所有的空间。 标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记-清除-压缩(Mark-Sweep-Compact)算法。 二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。 可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。 指针碰撞（Bump the Pointer） 如果内存空间以规整和有序的方式分布，即已用和未用的内存都各自一边，彼此之间维系着一个记录下一次分配起始点的标记指针，当为新对象分配内存时，只需要通过修改指针的偏移量将新对象分配在第一个空闲内存位置上，这种分配方式就叫做指针碰撞（Bump the Pointer）。 优点：（此算法消除了“标记-清除”和“复制”两个算法的弊端。） 消除了标记&#x2F;清除算法当中，内存区域分散的缺点，我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可。 消除了复制算法当中，内存减半的高额代价。 缺点： 从效率上来说，标记-压缩算法要低于复制算法。 效率不高，不仅要标记所有存活对象，还要整理所有存活对象的引用地址。 对于老年代每次都有大量对象存活的区域来说，极为负重。 移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址。 移动过程中，需要全程暂停用户应用程序。即：STW 分代收集算法 三种算法的对比： 效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存。 而为了尽量兼顾上面提到的三个指标，标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。 分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。 在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。 目前几乎所有的GC都是采用分代收集（Generational Collecting）算法执行垃圾回收的。 在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。 年轻代(Young Gen) 年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。 这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。 老年代(Tenured Gen) 老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。 这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。 Mark阶段的开销与存活对象的数量成正比。 Sweep阶段的开销与所管理区域的大小成正相关。 Compact阶段的开销与存活对象的数据成正比。 以HotSpot中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高。而对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器作为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial Old执行Full GC以达到对老年代内存的整理。 分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。 增量收集算法上述现有的算法，在垃圾回收过程中，应用软件将处于一种Stop the World 的状态。在Stop the World 状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting）算法的诞生。 基本思想 如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。 总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。 缺点： 使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 分区算法分区算法：—G1 GC使用的算法 分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。 每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。 一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。 2.相关概念System.gc()System.gc()和Runtime.getRunTime().gc()会做什么事情？ (字节跳动) 在默认情况下，通过System.gc()或者Runtime.getRuntime().gc()的调用，会显式触发Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。 然而System.gc()调用附带一个免责声明，无法保证对垃圾收集器的调用。 JVM实现者可以通过System.gc()调用来决定JVM的GC行为。而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太过于麻烦了。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用System.gc()。 finalize()方法详解finalize()方法详解，前言，finalize()是Object的protected方法，子类可以覆盖该方法以实现资源清理工作，GC在回收对象之前调用该方法。 finalize的作用 (1)finalize()与C++中的析构函数不是对应的。C++中的析构函数调用的时机是确定的（对象离开作用域或delete掉），但Java中的finalize的调用具有不确定性 (2)不建议用finalize方法完成“非内存资源”的清理工作，但建议用于：① **清理本地对象(通过JNI创建的对象)**；② 作为确保某些非内存资源(如Socket、文件等)释放的一个补充：在finalize方法中显式调用其他资源释放方法。 内存泄漏与内存溢出内存溢出 内存溢出相对于内存泄漏来说，尽管更容易被理解，但是同样的，内存溢出也是引发程序崩溃的罪魁祸首之一。 由于GC一直在发展，所有一般情况下，除非应用程序占用的内存增长速度非常快，造成垃圾回收已经跟不上内存消耗的速度，否则不太容易出现OOM的情况。 大多数情况下，GC会进行各种年龄段的垃圾回收，实在不行了就放大招，来一次独占式的Full GC操作，这时候会回收大量的内存，供应用程序继续使用。 javadoc中对OutOfMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。 OOM之前必回调用GC? 这里面隐含着一层意思是，在抛出OutOfMemoryError之前，通常垃圾收集器会被触发，尽其所能去清理出空间。 例如：在引用机制分析中，涉及到JVM会去尝试回收软引用指向的对象等。 在java.nio.BIts.reserveMemory()方法中，我们能清楚的看到，System.gc()会被调用，以清理空间。 当然，也不是在任何情况下垃圾收集器都会被触发的 比如，我们去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM可以判断出垃圾收集并不能解决这个问题，所以直接抛出OutOfMemoryError。 内存泄漏 何为内存泄漏（memory leak） 可达性分析算法来判断对象是否是不再使用的对象，本质都是判断一个对象是否还被引用。那么对于这种情况下，由于代码的实现不同就会出现很多种内存泄漏问题（让JVM误以为此对象还在引用中，无法回收，造成内存泄漏）。 是否还被使用？ 是 是否还被需要？ 否 内存泄漏（memory leak）的理解 严格来说，只有对象不会再被程序用到了，但是GC又不能回收他们的情况，才叫内存泄漏。 但实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致OOM，也可以叫做宽泛意义上的“内存泄漏”。 对象 X 引用对象 Y，X 的生命周期比 Y 的生命周期长； 那么当Y生命周期结束的时候，X依然引用着Y，这时候，垃圾回收期是不会回收对象Y的； 如果对象X还引用着生命周期比较短的A、B、C，对象A又引用着对象 a、b、c，这样就可能造成大量无用的对象不能被回收，进而占据了内存资源，造成内存泄漏，直到内存溢出。 内存泄漏与内存溢出的关系： 内存泄漏（memory leak ） 申请了内存用完了不释放，比如一共有 1024M 的内存，分配了 512M 的内存一直不回收，那么可以用的内存只有 512M 了，仿佛泄露掉了一部分； 通俗一点讲的话，内存泄漏就是【占着茅坑不拉shi】。 内存溢出（out of memory） 申请内存时，没有足够的内存可以使用； 通俗一点儿讲，一个厕所就三个坑，有两个站着茅坑不走的（内存泄漏），剩下最后一个坑，厕所表示接待压力很大，这时候一下子来了两个人，坑位（内存）就不够了，内存泄漏变成内存溢出了。 可见，内存泄漏和内存溢出的关系：内存泄漏的增多，最终会导致内存溢出。 泄漏的分类 经常发生：发生内存泄露的代码会被多次执行，每次执行，泄露一块内存； 偶然发生：在某些特定情况下才会发生； 一次性：发生内存泄露的方法只会执行一次； 隐式泄漏：一直占着内存不释放，直到执行结束；严格的说这个不算内存泄漏，因为最终释放掉了，但是如果执行时间特别长，也可能会导致内存耗尽。 Java中内存泄漏的8种情况 静态集合类，如HashMap、LinkedList等等。如果这些容器为静态的，那么它们的生命周期与JVM程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。简单而言，长生命周期的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。 12345678public class MemoryLeak &#123;static List *list* = new ArrayList();public void oomTests() &#123; Object obj = new Object();//局部变量*list*.add(obj); &#125;&#125; 单例模式 单例模式，和静态集合导致内存泄露的原因类似，因为单例的静态特性，它的生命周期和 JVM 的生命周期一样长，所以如果单例对象如果持有外部对象的引用，那么这个外部对象也不会被回收，那么就会造成内存泄漏。 内部类持有外部类 内部类持有外部类，如果一个外部类的实例对象的方法返回了一个内部类的实例对象。 这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄漏。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class HandlerDemoActivity extends Activity implements OnClickListener &#123; private static final int MESSAGE_INCRESE = 0; private static final int MESSAGE_DECRESE = 1; private TextView tv_demo_number; private Button btn_demo_increase; private Button btn_demo_decrease; private Button btn_demo_pause; private Handler handler = new Handler()&#123; //回调方法 public void handleMessage(android.os.Message msg) &#123; String strNum = tv_demo_number.getText().toString(); //转换为整型数据,获取当前显示的数值 int num = Integer.parseInt(strNum); switch(msg.what)&#123; case MESSAGE_INCRESE: num++; tv_demo_number.setText(num + &quot;&quot;); if(num == 20)&#123; Toast.makeText(HandlerDemoActivity.this, &quot;已达到最大值&quot;, 0).show(); btn_demo_pause.setEnabled(false); return; &#125; //发送延迟的+1的消息 sendEmptyMessageDelayed(MESSAGE_INCRESE, 300);//指的是延迟处理，而不是延迟发送 break; case MESSAGE_DECRESE: num--; tv_demo_number.setText(num + &quot;&quot;); if(num == 0)&#123; Toast.makeText(HandlerDemoActivity.this, &quot;已达到最小值&quot;, 0).show(); btn_demo_pause.setEnabled(false); return; &#125; //发送延迟的-1的消息 sendEmptyMessageDelayed(MESSAGE_DECRESE, 300);//指的是延迟处理，而不是延迟发送 break; &#125; &#125; &#125;; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_handler_demo); init(); &#125; private void init() &#123; tv_demo_number = (TextView) findViewById(R.id.tv_demo_number); btn_demo_increase = (Button) findViewById(R.id.btn_demo_increase); btn_demo_decrease = (Button) findViewById(R.id.btn_demo_decrease); btn_demo_pause = (Button) findViewById(R.id.btn_demo_pause); btn_demo_increase.setOnClickListener(this); btn_demo_decrease.setOnClickListener(this); btn_demo_pause.setOnClickListener(this); &#125; @Override public void onClick(View v) &#123; .... &#125;&#125; 各种连接，如数据库连接、网络连接和IO连接等 变量不合理的作用域 改变哈希值 缓存泄漏 监听器和回调 STW Stop-the-World ，简称STW，指的是GC事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为STW。 可达性分析算法中枚举根节点（GC Roots）会导致所有Java执行线程停顿。 分析工作必须在一个能确保一致性的快照中进行 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上 如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证 被STW中断的应用程序线程会在完成GC之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，所以我们需要减少STW的发生。 STW事件和采用哪款GC无关，所有的GC都有这个事件。 哪怕是G1也不能完全避免Stop-the-world 情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。 STW是JVM在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。 开发中不要用System.gc();会导致Stop-the-world的发生。 垃圾回收的并行与并发并发(Concurrent) 在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行。 并发不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间片段(时间区间)，然后在这几个时间区间之间来回切换，由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。 并行(Parallel) 当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，我们称之为并行(Parallel)。 其实决定并行的因素不是CPU的数量，而是CPU的核心数量，比如一个CPU多个核也可以并行。 适合科学计算，后台处理等弱交互场景 二者对比： 并发，指的是多个事情，在同一时间段内同时发生了。 并行，指的是多个事情，在同一时间点上同时发生了。 并发的多个任务之间是互相抢占资源的。 并行的多个任务之间是不互相抢占资源的。 只有在多CPU或者一个CPU多核的情况中，才会发生并行。 否则，看似同时发生的事情，其实都是并发执行的。 并发和并行，在谈论垃圾收集器的上下文语境中，它们可以解释如下： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 如ParNew、Parallel Scavenge、Parallel Old； 串行（Serial） 相较于并行的概念，单线程执行。 如果内存不够，则程序暂停，启动JVM垃圾回收器进行垃圾回收。回收完，再启动程序的线程。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时不会停顿用户程序的运行。 用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上； 如：CMS、G1 安全点与安全区域安全点(Safepoint) 程序执行时并非在所有地方都能停顿下来开始 GC，只有在特定的位置才能停顿下来开始GC，这些位置称为“安全点（Safepoint）”。 Safe Point的选择很重要，如果太少可能导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据“是否具有让程序长时间执行的特征”为标准。比如：选择一些执行时间较长的指令作为Safe Point，如方法调用、循环跳转和异常跳转等。 如何在GC发生时，检查所有线程都跑到最近的安全点停顿下来呢？ 抢先式中断：（目前没有虚拟机采用了） 首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。 主动式中断： 设置一个中断标志，各个线程运行到Safe Point的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。 安全区域(Safe Region) Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的 Safepoint 。但是，程序“不执行”的时候呢？例如线程处于 Sleep 状态或 Blocked 状态，这时候线程无法响应 JVM 的中断请求，“走”到安全点去中断挂起，JVM 也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。 安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的。我们也可以把 Safe Region 看做是被扩展了的 Safepoint。 实际执行时： 1、当线程运行到Safe Region的代码时，首先标识已经进入了Safe Region，如果这段时间内发生GC，JVM会忽略标识为Safe Region状态的线程； 2、当线程即将离开Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开Safe Region的信号为止； 5种引用强引用（Strong Reference）——不回收在Java程序中，最常见的引用类型是强引用（普通系统99%以上都是强引用），也就是我们最常见的普通对象引用，也是默认的引用类型。 当在Java语言中使用new操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。 强引用的对象是可触及的，垃圾收集器就永远不会回收掉被引用的对象。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。 相对的， 软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。 强引用例子： StringBuffer str &#x3D; new StringBuffer (“Hello,尚硅谷”); 局部变量str指向StringBuffer实例所在堆空间，通过str可以操作该实例， 那么str就是StringBuffer实例的强引用 对应内存结构： 此时，如果再运行一个赋值语句： StringBuffer str1 &#x3D; str; 对应内存结构： 本例中的两个引用，都是强引用，强引用具备以下特点： 强引用可以直接访问目标对象。 强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出OOM异常，也不会回收强引用所指向对象。 强引用可能导致内存泄漏。 软引用（Soft Reference）— 内存不足即回收软引用是用来描述一些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。 软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（Reference Queue）。 类似弱引用，只不过Java虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。 在JDK 1.2版之后提供了java.lang.ref.SoftReference类来实现软引用。 Object obj &#x3D; new Object(); &#x2F;&#x2F;声明强引用 SoftReference sf &#x3D; new SoftReference(obj); obj &#x3D; null; &#x2F;&#x2F;销毁强引用 弱引用（Weak Reference）—发现即回收弱引用也是用来描述那些非必需对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。 但是，由于垃圾回收器的线程通常优先级很低，因此, 并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。 弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。 弱引用非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。 在JDK 1.2版之后提供了java.lang.ref.WeakReference类来实现弱引用。 Object obj &#x3D; new Object(); &#x2F;&#x2F;声明强引用 WeakReference wr &#x3D; new WeakReference(obj); obj &#x3D; null; &#x2F;&#x2F;销毁强引用 弱引用对象与软引用对象的最大不同就在于，当GC在进行回收时，需要通过算法检查是否回收软引用对象，而对于弱引用对象，GC总是进行回收。弱引用对象更容易、更快被GC回收。 虚引用（Phantom Reference）—对象回收跟踪也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。 一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。 它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的get()方法取得对象时，总是null。 为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被收集器回收时收到一个系统通知。 虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。 由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。 在JDK 1.2版之后提供了PhantomReference类来实现虚引用。 Object obj &#x3D; new Object();ReferenceQueue phantomQueue &#x3D; new ReferenceQueue(); PhantomReference pf &#x3D; new PhantomReference(obj, phantomQueue); obj &#x3D; null; 终结器引用(Final reference) 不太懂 它用以实现对象的finalize()方法，也可以称为终结器引用。 无需手动编码，其内部配合引用队列使用。 在GC时，终结器引用入队。由Finalizer线程通过终结器引用找到被引用对象并调用它的finalize()方法，第二次GC时才能回收被引用对象。 3.垃圾回收器GC分类 按线程数分，可以分为串行垃圾回收器和并行垃圾回收器。 串行回收指的是在同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束。 在诸如单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合，串行回收器的性能表现可以超过并行回收器和并发回收器。所以，串行回收默认被应用在客户端的Client模式下的JVM中 在并发能力比较强的CPU上，并行回收器产生的停顿时间要短于串行回收器。 和串行回收相反，并行收集可以运用多个CPU同时执行垃圾回收，因此提升了应用的吞吐量，不过并行回收仍然与串行回收一样，采用独占式，使用了“Stop-the-world”机制。 按照工作模式分，可以分为并发式垃圾回收器和独占式垃圾回收器。 并发式垃圾回收器与应用程序线程交替工作，以尽可能减少应用程序的停顿时间。 独占式垃圾回收器(Stop the world)一旦运行，就停止应用程序中的所有用户线程，直到垃圾回收过程完全结束。 按碎片处理方式分，可分为压缩式垃圾回收器和非压缩式垃圾回收器。 压缩式垃圾回收器会在回收完成后，对存活对象进行压缩整理，消除回收后的碎片。 再分配对象空间使用：指针碰撞 非压缩式的垃圾回收器不进行这步操作。 再分配对象空间使用：空闲列表 按工作的内存区间分，又可分为年轻代垃圾回收器和老年代垃圾回收器。 GC评估指标评估GC的性能指标：吞吐量(throughput) 吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 &#x3D; 运行用户代码时间 &#x2F;（运行用户代码时间 + 垃圾收集时间）。 比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 这种情况下，应用程序能容忍较高的暂停时间。因此，高吞吐量的应用程序有更长的时间基准，快速响应是不必考虑的。 吞吐量优先，意味着在单位时间内，STW的时间最短：0.2 + 0.2 &#x3D; 0.4 评估GC的性能指标：暂停时间(pause time) “暂停时间”是指一个时间段内应用程序线程暂停，让GC线程执行的状态 例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。 暂停时间优先，意味着尽可能让单次STW的时间最短：0.1 + 0.1 + 0.1 + 0.1 + 0.1 &#x3D; 0.5 评估GC的性能指标：吞吐量vs暂停时间 高吞吐量较好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。 低暂停时间（低延迟）较好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。因此，具有低的较大暂停时间是非常重要的，特别是对于一个交互式应用程序。 不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾）。 因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。 相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。 在设计（或使用）GC算法时，我们必须确定我们的目标：一个GC算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折衷。 现在JVM调优标准：在最大吞吐量优先的情况下，降低停顿时间。 垃圾回收器都有哪些？各GC使用场景如何选择？GC新发展4.分析日志JVM面试Java内存区域说一下 JVM 的主要组成部分及其作用？ JVM包含两个子系统和两个组件，两个子系统为Class loader(类装载)、Execution engine(执行引擎)；两个组件为Runtime data area(运行时数据区)、Native Interface(本地接口)。 Class loader(类装载)：根据给定的全限定名类名(如：java.lang.Object)来装载class文件到运行时数据区中的方法区。 Execution engine（执行引擎）：执行字节码中的指令。 Native Interface(本地接口)：与native libraries交互，是与其它编程语言交互的接口。 Runtime data area(运行时数据区域)：这就是我们常说的JVM的内存。 作用 ：首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的解释器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 @$说一下 JVM 运行时数据区Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着虚拟机进程的启动而存在，有些区域则是依赖线程的启动和结束而建立和销毁。Java 虚拟机所管理的内存被划分为如下几个区域： 不同虚拟机的运行时数据区可能略微有所不同，但都会遵从 Java 虚拟机规范， Java 虚拟机规范规定的区域分为以下 5 个部分： Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里分配内存； 方法区（Method Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。 Java 虚拟机栈（Java Virtual Machine Stacks）：用于存储局部变量表、操作数栈、动态链接、方法出口等信息； 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； 程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，字节码解释器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成； 深拷贝和浅拷贝浅拷贝（shallowCopy）只是增加了一个指针指向已存在的内存地址 深拷贝（deepCopy）是增加了一个指针并且申请了一个新的内存，使这个增加的指针指向这个新的内存， 使用深拷贝的情况下，不会出现浅拷贝时释放同一个内存的错误。 说一下堆栈的区别？ 堆 栈 物理地址 物理地址分配是不连续的，因此性能慢些。在GC的时候需要考虑到不连续的分配，所以有各种垃圾回收算法。 栈使用的是数据结构中的栈，具有先进后出的规则，物理地址分配是连续的，因此性能快 分配内存时机 堆因为是不连续的，所以分配的内存是在运行期确认的，因此大小不固定。一般堆大小远远大于栈。 栈是连续的，所以分配的内存大小要在编译期就确认，大小是固定的。 存放的内容 堆存放的是对象的实例和数组。此区域更关注的是数据的存储 栈存放：局部变量，操作数栈，返回结果。此区域更关注的是程序方法的执行。 程序的可见度 堆对于整个应用程序都是共享的、可见的。 栈对当前线程是可见的，是线程私有。他的生命周期和线程相同。 HotSpot虚拟机对象探秘@$对象的创建说到对象的创建，首先让我们看看 Java 中提供的几种对象创建方式： Header 解释 使用new关键字 调用了构造函数 使用Class的newInstance方法 调用了构造函数 使用Constructor类的newInstance方法 调用了构造函数 使用clone方法 没有调用构造函数 使用反序列化 没有调用构造函数 下面是对象创建的主要流程： 虚拟机遇到一条new指令时，先检查常量池是否已经加载相应的类，如果没有，必须先执行相应的类加载。类加载通过后，接下来分配内存。若Java堆中内存是绝对规整的，使用“指针碰撞“方式分配内存；如果不是规整的，就从空闲列表中分配，叫做”空闲列表“方式。划分内存时还需要考虑一个问题-并发，也有两种方式：CAS同步处理，或者本地线程分配缓冲(Thread Local Allocation Buffer, TLAB)。然后将分配到的内存空间都初始化为零值，接着是做一些必要的对象设置(元信息、哈希码…)，最后执行&lt;init&gt;方法。 为对象分配内存类加载完成后，接着会在Java堆中划分一块内存分配给对象。内存分配根据Java堆是否规整，有两种方式： 指针碰撞：如果Java堆的内存是规整，即所有用过的内存放在一边，而空闲的的放在另一边。分配内存时将位于中间的指针指示器向空闲的内存移动一段与对象大小相等的距离，这样便完成分配内存工作。 空闲列表：如果Java堆的内存不是规整的，则需要由虚拟机维护一个列表来记录哪些内存是可用的，这样在分配的时候可以从列表中查询到足够大的内存分配给对象，并在分配后更新列表记录。 选择哪种分配方式是由 Java 堆是否规整来决定的，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 处理并发安全问题在虚拟机中对象的创建是一个非常频繁的行为，哪怕只是修改一个指针所指向的位置，在并发情况下也是不安全的，可能出现正在给对象 A 分配内存，指针还没来得及修改，对象 B 又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案： 对内存分配的动作进行同步处理（采用 CAS + 失败重试来保障更新操作的原子性）； 把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer, TLAB）。哪个线程要分配内存，就在哪个线程的 TLAB 上分配。只有 TLAB 用完并分配新的 TLAB 时，才需要同步锁。通过-XX:+UseTLAB参数来设定虚拟机是否使用TLAB。 对象的访问定位Java程序需要通过 JVM 栈上的引用访问堆中的具体对象。对象的访问方式取决于 JVM 虚拟机的实现。目前主流的访问方式有 句柄 和 直接指针 两种方式。 指针： 一种内存地址，代表一个对象在内存中的地址。 句柄： 可以理解为指向指针的指针，维护着对象的指针。句柄不直接指向对象，而是指向对象的指针（句柄不发生变化，指向固定内存地址），再由对象的指针指向对象的真实内存地址。 句柄访问Java堆中划分出一块内存来作为句柄池，引用中存储对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息，具体构造如下图所示： 优势：引用中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用本身不需要修改。 直接指针如果使用直接指针访问，引用 中存储的直接就是对象地址。 优势：速度更快，节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本。HotSpot 中采用的就是这种方式。 内存溢出异常@$Java会存在内存泄漏吗？请简单描述内存泄漏是指不再被使用的对象或者变量一直存在于内存中。理论上来说，Java是有GC垃圾回收机制的，也就是说，不再被使用的对象，会被GC自动回收掉，自动从内存中清除。 但是，即使这样，Java也还是存在着内存泄漏的情况，Java导致内存泄露的原因很明确：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是Java中内存泄露的发生场景。 垃圾收集器简述Java垃圾回收机制，GC是什么？垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？有什么办法主动通知虚拟机进行垃圾回收？Java垃圾回收机制：GC 是垃圾收集的意思（Gabage Collection），在java中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行，这就是垃圾回收机制，垃圾回收机制有效的防止了内存泄露 垃圾回收器的基本原理：在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫描那些没有被引用的对象，并将它们添加到要回收的集合中，进行回收。 垃圾回收器可以马上回收内存吗？：程序员不能实时的对某个对象或所有对象调用垃圾回收器进行垃圾回收。但可以手动执行System.gc()主动通知虚拟机进行垃圾回收，但是Java语言规范并不能保证GC一定会执行。 Java 中都有哪些引用类型？强引用、软引用、弱引用、幻象引用有什么区别？具体使用场景是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用，根据其生命周期的长短，将引用分为4类。 不同的引用类型，主要体现的是对象不同的可达性状态和对垃圾收集的影响。 强引用：最常见的普通对象引用，通过关键字new创建的对象所关联的引用就是强引用，发生 gc 的时候不会被回收。 软引用：软引用的生命周期比强引用短一些。有用但不是必须的对象，在发生内存溢出之前会被回收。应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 弱引用：弱引用的生命周期比软引用短。有用但不是必须的对象，在下一次GC时会被回收。应用场景：弱应用同样可用于内存敏感的缓存。 虚引用（幽灵引用&#x2F;幻象引用）：无法通过虚引用获得对象，用 PhantomReference 实现虚引用。应用场景：虚引用的用途是在这个对象被 gc 时返回一个系统通知。 怎么判断对象是否可以被回收？在Java中，对象什么时候可以被垃圾回收垃圾收集器在做垃圾回收的时候，首先需要判定的就是哪些内存是需要被回收的，哪些对象是「存活」的，是不可以被回收的；哪些对象已经「死掉」了，需要被回收。 一般有两种方法来判断： 引用计数器法：为每个对象创建一个引用计数器，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。它有一个缺点不能解决循环引用的问题； 可达性分析算法：当一个对象到GC Roots不可达时，在下一个垃圾回收周期中尝试回收该对象。定义一系列的 GC ROOT 为起点。从起点开始向下开始搜索，搜索走过的路径称为引用链。当一个对象到 GC ROOT没有任何引用链相连的话，则对象可以判定是可以被回收的。 可达性分析算法详答 当不能从GC Root寻找一条路径到达该对象时，将进行第一次标记。 第一次标记后检查对象是否重写了finalize() 和是否已经被调用了finalize()方法。若没有重写finalize()方法或已经被调用，则进行回收。 在已经重写finalize()方法且未调用的情况下，将对象加入一个F-Queue 的队列中，稍后进行第二次检查 在第二次标记之前，对象如果执行finalize()方法并完成自救，对象则不会被回收。否则完成第二次标记，进行回收。值得注意的是finalize()方法并不可靠。 虚拟机默认采用的是可达性分析算法。 可以作为 GC ROOT 的对象包括： 栈中引用的对象； 静态变量、常量引用的对象； 本地方法栈 native 方法引用的对象。 JVM中的永久代中会发生垃圾回收吗垃圾回收一般不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。通过查看垃圾收集器的输出信息，就会发现永久代也是被回收的。所以正确的设置永久代大小可以有效避免Full GC。 Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区，现在大多数的类元数据分配在本地化内存中。 @$说一下 JVM 有哪些垃圾回收算法？ 标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。 复制算法：按照容量划分两个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的那块内存空间清理掉。缺点：内存使用率不高，只有原来的一半。 标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后清除掉端边界以外的内存。 分代收集算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代采用复制算法，老年代采用标记整理算法。 标记-清除算法标记无用对象，然后进行清除回收。 标记-清除算法（Mark-Sweep）是一种常见的基础垃圾收集算法，它将垃圾收集分为两个阶段： 标记阶段：标记出可以回收的对象。 清除阶段：回收被标记的对象所占用的空间。 标记-清除算法之所以是基础的，是因为后面讲到的垃圾收集算法都是在此算法的基础上进行改进的。 优点：实现简单，不需要对象进行移动。 缺点：由于标记的过程需要遍历所有的 GC ROOT，清除的过程也要遍历堆中所有的对象，标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 标记-清除算法的执行的过程如下图所示 复制算法为了解决标记-清除算法的效率不高的问题，产生了复制算法。把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将已使用的内存空间一次清理掉。 优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 复制算法的执行过程如下图所示 标记-整理算法在新生代中可以使用复制算法，但是在老年代就不能选择复制算法了，因为老年代的对象存活率会较高，这样会有较多的复制操作，导致效率变低。标记-清除算法可以应用在老年代中，但是它效率不高，在内存回收后容易产生大量内存碎片。因此就出现了一种标记-整理算法（Mark-Compact）算法，与标记-清除算法不同的是，在标记可回收的对象后将所有存活的对象压缩到内存的一端，使他们紧凑的排列在一起，然后对端边界以外的内存进行回收。回收后，已用和未用的内存都各自一边。 优点：解决了标记-清除算法存在的内存碎片问题。 缺点：需要进行局部对象移动，一定程度上降低了效率。 标记-整理算法的执行过程如下图所示 分代收集算法当前商业虚拟机都采用分代收集的垃圾收集算法。分代收集算法，顾名思义是根据对象的存活周期将内存划分为几块。一般包括新生代、老年代，新生代采用复制算法，老年代采用标记-整理算法，注：Java8中已经移除了永久代，添加了元数据区。如图所示： 垃圾收集算法小结 @$说一下 JVM 有哪些垃圾回收器？如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图展示了7种作用于不同分代的收集器，其中用于回收新生代的收集器包括Serial、ParNew、Parallel Scavenge，回收老年代的收集器包括Serial Old、Parallel Old、CMS，还有用于回收整个Java堆的G1收集器。不同收集器之间的连线表示它们可以搭配使用。 Serial收集器(复制算法)：新生代单线程收集器，标记和清理都是单线程，优点是简单高效； ParNew收集器 (复制算法)：新生代并行收集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现； Parallel Scavenge收集器 (复制算法)：新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 &#x3D; 用户线程时间&#x2F;(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景； Serial Old收集器 (标记-整理算法)：老年代单线程收集器，Serial收集器的老年代版本； Parallel Old收集器 (标记-整理算法)：老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本； CMS(Concurrent Mark Sweep)收集器(标记-清除算法)：老年代并行收集器，追求最短GC回收停顿时间，具有高并发、低停顿的特点； G1(Garbage First)收集器 (标记-整理算法)：Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。 新生代垃圾回收器和老年代垃圾回收器都有哪些？有什么区别？ 新生代回收器：Serial、ParNew、Parallel Scavenge 老年代回收器：Serial Old、Parallel Old、CMS 整堆回收器：G1 新生代垃圾回收器一般采用的是复制算法 老年代垃圾回收器一般采用的是标记-整理的算法 详细介绍一下 CMS 垃圾回收器？CMS 是英文 Concurrent Mark-Sweep 的简称，是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。 在启动 JVM 的参数加上“-XX:+UseConcMarkSweepGC”来指定使用 CMS 垃圾回收器。 CMS 使用的是标记-清除的算法实现的，所以在 gc 的时候会产生大量的内存碎片，当剩余内存不能满足程序运行要求时，系统将会出现 Concurrent Mode Failure，临时 CMS 会采用 Serial Old 回收器进行垃圾清除，此时的性能将会被降低。 CMS 收集器是以获取最短停顿时间为目标的收集器。相对于其他的收集器 STW 的时间更短暂，可以并行收集是它的特点，同时它基于标记-清除算法。整个 GC 过程分为4步： 初始标记：标记 GC ROOT 能关联到的对象，需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，不需要 STW； 重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，需要 STW； 并发清除：清理删除掉标记阶段判断的已经死亡的对象，不需要 STW。 从整个过程来看，并发标记和并发清除的耗时最长，但是不需要停止用户线程。而初始标记和重新标记的耗时较短，但是需要停止用户线程。总体而言，整个过程造成的停顿时间较短，大部分时候是可以和用户线程一起工作的。 G1垃圾回收器的原理了解吗？ G1 作为 JDK9 之后的服务端默认收集器，不再区分年轻代和老年代进行垃圾回收。 把内存划分为多个 Region，每个 Region 的大小可以通过 -XX:G1HeapRegionSize 设置，大小为1~32M。 对于大对象的存储则衍生出 Humongous 的概念。超过 Region 大小一半的对象会被认为是大对象，而超过整个 Region 大小的对象被认为是超级大对象，将会被存储在连续的 N 个 Humongous Region 中。 G1 在进行回收的时候会在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间优先回收收益最大的 Region。 G1 的回收过程分为以下四个步骤： 初始标记：标记 GC ROOT 能关联到的对象，需要 STW； 并发标记：从 GCRoots 的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象； 最终标记：短暂暂停用户线程，再处理一次，需要 STW； 筛选回收：更新 Region 的统计数据，对每个 Region 的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把Region 中存活对象复制到空的 Region，同时清理旧的 Region。需要 STW。 总的来说除了并发标记之外，其他几个过程也还是需要短暂的 STW。G1 的目标是在停顿和延迟可控的情况下尽可能提高吞吐量。 简述分代垃圾回收器是怎么工作的？根据对象的存活周期将堆内存划分：老年代和新生代，新生代默认的空间占比总空间的 1&#x2F;3，老年代的默认占比是 2&#x2F;3。 新生代使用的是复制算法，新生代里有 3 个分区：Eden、From Survivor、To Survivor，它们的默认占比是 8:1:1，它的执行流程如下： 把 Eden + From Survivor 存活的对象放入 To Survivor 区； 清空 Eden 和 From Survivor 分区； From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。 每次在 From Survivor 到 To Survivor 移动存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老年代。大对象会直接进入老年代。 老年代当空间占用到达某个值之后就会触发全局垃圾回收，一般使用标记整理算法。 以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。 内存分配策略@$简述java内存分配与回收策略以及Minor GC和Major GC所谓自动内存管理，最终要解决的也就是内存分配和内存回收两个问题。前面我们介绍了内存回收，这里我们再来聊聊内存分配。 对象的内存分配通常是在 Java 堆上分配（随着虚拟机优化技术的诞生，某些场景下也会在栈上分配，后面会详细介绍），对象主要分配在新生代的 Eden 区，如果启动了本地线程缓冲，则线程优先在 TLAB 上分配。少数情况下也会直接在老年代上分配。总的来说分配规则不是百分百固定的，其细节取决于哪一种垃圾收集器组合以及虚拟机相关参数有关，但是虚拟机对于内存的分配还是会遵循以下几种「普世」规则： 对象优先在 Eden 区分配多数情况，对象都在新生代 Eden 区分配。当 Eden 区没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC。如果本次 GC 后还是没有足够的空间，则将启用分配担保机制在老年代中分配内存。 这里我们提到 Minor GC，如果你仔细观察过 GC 日常，通常我们还能从日志中发现 Major GC&#x2F;Full GC。 Minor GC 是指发生在新生代的 GC，因为 Java 对象大多都是朝生夕死，所以 Minor GC 非常频繁，一般回收速度也非常快； Major GC&#x2F;Full GC 是指发生在老年代的 GC，出现了 Major GC 通常会伴随至少一次 Minor GC。Major GC 的速度通常会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代所谓大对象是指需要大量连续内存空间的对象，频繁出现大对象是致命的，会导致在内存还有不少空间的情况下提前触发 GC，以获取足够的连续空间来安置新对象。 新生代使用的是复制算法，如果大对象直接在新生代分配，就会导致 Eden 区和两个 Survivor 区之间发生大量的内存复制，因此对于大对象都会直接在老年代进行分配。 长期存活对象将进入老年代虚拟机采用分代收集的思想来管理内存，会给每个对象定义了一个对象年龄的计数器，对象在 Eden 区出生，经过一次 Minor GC 对象年龄就会加 1，当年龄达到一定程度（默认 15） 就会被晋升到老年代，也就是长期存活对象将进入老年代。 虚拟机类加载机制简述Java类加载机制？类加载机制的原理Java中的所有类，都需要由类加载器装载到JVM中才能运行，同时对数据进行验证，准备，解析和初始化，最终形成可以被虚拟机直接使用的类型。 类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的需求，像是反射，就需要显式的加载所需要的类。 类装载方式，有两种 ： 隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中 显式装载， 通过class.forname()等方法，显式加载需要的类 Java中类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载，这是为了节省内存开销。 什么是类加载器，类加载器有哪些?类加载器负责将字节码文件的类加载到虚拟机内存中。 主要有一下四种类加载器: 启动类加载器（Bootstrap ClassLoader）：用来加载Java核心类库，无法被Java程序直接引用。即用来加载JAVA_HOME&#x2F;jre&#x2F;lib目录中的，或者被 -Xbootclasspath 参数所指定的路径中并且被虚拟机识别的类库； 扩展类加载器（Extension ClassLoader）：用来加载 Java 的扩展库。负责加载JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext目录或-Djava.ext.dir系统变量指定的路径中的所有类库； 应用程序类加载器（Application ClassLoader）：用来加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器，默认就是用这个加载器。 用户自定义类加载器：通过继承 java.lang.ClassLoader类的方式实现用户自定义类加载器。 说一下类装载的执行过程？ 类装载分为以下 5 个步骤： 加载：根据查找路径找到相应的 class 文件然后导入； 验证：检查加载的 class 文件的正确性； 准备：给类中的静态变量分配内存空间； 解析：虚拟机将常量池中的符号引用替换成直接引用的过程。符号引用可以理解为一个标识，而直接引用直接指向内存中的地址； 初始化：对静态变量和静态代码块执行初始化工作。 @$什么是双亲委派模型？双亲委派模型工作流程是怎样的？双亲委派模型的好处是什么？在介绍双亲委派模型之前先说下类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立在 JVM 中的唯一性，每一个类加载器，都有一个独立的类名称空间。类加载器就是根据指定全限定名称将 class 文件加载到 JVM 内存，然后再转化为 class 对象。 双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去加载，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载器无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载此类。 自下而上检查类是否已经被加载，自上而下尝试加载类 双亲委派模型工作流程： 当Application ClassLoader 收到一个类加载请求时，他首先不会自己去尝试加载这个类，而是将这个请求委派给父类加载器Extension ClassLoader去完成。 当Extension ClassLoader收到一个类加载请求时，他首先也不会自己去尝试加载这个类，而是将请求委派给父类加载器Bootstrap ClassLoader去完成。 Bootstrap ClassLoader尝试加载此类，如果Bootstrap ClassLoader加载失败，就会让Extension ClassLoader尝试加载。 Extension ClassLoader尝试加载此类，如果Extension ClassLoader也加载失败，就会让Application ClassLoader尝试加载。 Application ClassLoader尝试加载此类，如果Application ClassLoader也加载失败，就会让自定义加载器尝试加载。 如果均加载失败，就会抛出ClassNotFoundException异常。 双亲委派模型的好处：保证核心类库不被覆盖。如果没有使用双亲委派模型，由各个类加载器自行加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统将会出现多个不同的Object类， Java类型体系中最基础的行为就无法保证，应用程序也将会变得一片混乱。 JVM调优说一下 JVM 调优的工具？JDK 自带了很多监控工具，都位于 JDK 的 bin 目录下，其中最常用的是 jconsole 和 jvisualvm 这两款可视化监控工具。 jconsole：JDK 自带的可视化管理工具，用于对 JVM 中的内存、线程和类等进行监控，对垃圾回收算法有很详细的跟踪，功能简单； jvisualvm：JDK 自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc 变化等，功能强大。 常用的故障检测，监视，修理工具 工具名称 主要作用 jps (JVM Process Status Tool) 显示系统中所有的虚拟机进程 jstat (JVM Statistics Monitoring Tool) 收集虚拟机各方面的运行数据 jinfo (Configuration Info for Java) 显示虚拟机配置信息 jmap (Memory Map for Java) 生成虚拟机的内存转储快照 jhat (JVM Heap Dump Browser) 分析堆内存转储快照，不推荐使用，消耗资源而且慢 jstack (Stack Trace for Java） 显示线程堆栈快照 谈谈你的GC调优思路?谈到调优，这一定是针对特定场景、特定目的的事情， 对于 GC 调优来说，首先就需要清楚调优的目标是什么？从性能的角度看，通常关注三个方面，内存占用（footprint）、延时（latency）和吞吐量（throughput） 基本的调优思路可以总结为： 理解应用需求和问题，确定调优目标。假设，我们开发了一个应用服务，但发现偶尔会出现性能抖动，出现较长的服务停顿。评估用户可接受的响应时间和业务量，将目标简化为，希望 GC 暂停尽量控制在 200ms 以内，并且保证一定标准的吞吐量。 掌握 JVM 和 GC 的状态，定位具体问题，确定是否有 GC 调优的必要。具体有很多方法，比如，通过 jstat 等工具查看 GC 等相关状态，可以开启 GC 日志，或者是利用操作系统提供的诊断工具等。例如，通过追踪 GC 日志，就可以查找是不是 GC 在特定时间发生了长时间的暂停，进而导致了应用响应不及时。 接着需要思考选择的 GC 类型是否符合我们的应用特征，具体问题表现在哪里。是 Minor GC 过长，还是 Mixed GC 等出现异常停顿情况；如果不是，考虑切换到什么类型，如 CMS 和 G1 都是更侧重于低延迟的 GC 选项。 通过分析确定具体调整的参数或者软硬件配置。 验证是否达到调优目标，如果达到目标，即可以考虑结束调优；否则，重复进行分析、调整、验证。 @$常用的 JVM 调优的参数都有哪些？1、性能调优要做到有的放矢，根据实际业务系统的特点，以一定时间的JVM日志记录为依据，进行有针对性的调整、比较和观察。 2、性能调优是个无止境的过程，要综合权衡调优成本和更换硬件成本的大小，使用最经济的手段达到最好的效果。 3、性能调优不仅仅包括JVM的调优，还有服务器硬件配置、操作系统参数、中间件线程池、数据库连接池、数据库本身参数以及具体的数据库表、索引、分区等的调整和优化。 4、通过特定工具检查代码中存在的性能问题并加以修正是一种比较经济快捷的调优方法。 常用的 JVM 调优的参数 -Xms2g：初始化堆大小为 2g； -Xmx2g：堆最大内存为 2g； -Xmn1g：新生代内存大小为1g；-XX:NewSize 新生代大小，-XX:MaxNewSize 新生代最大值，-Xmn 则是相当于同时配置 -XX:NewSize 和 -XX:MaxNewSize 为一样的值； -XX:NewRatio&#x3D;2：设置新生代的和老年代的内存比例为 1:2，即新生代占堆内存的1&#x2F;3，老年代占堆内存的2&#x2F;3； -XX:SurvivorRatio&#x3D;8：设置新生代 Eden 和 两个Survivor 比例为 8:1:1； –XX:+UseParNewGC：对新生代使用并行垃圾回收器。 -XX:+UseParallelOldGC：对老年代并行垃圾回收器。 -XX:+UseConcMarkSweepGC：以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。 -XX:+PrintGC：开启打印 gc 信息； -XX:+PrintGCDetails：打印 gc 详细信息。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://gouguoqiang.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://gouguoqiang.github.io/tags/JVM/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://gouguoqiang.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"java","slug":"all/1java","date":"2022-10-08T10:49:25.000Z","updated":"2022-10-09T13:55:37.189Z","comments":true,"path":"2022/10/08/all/1java/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/08/all/1java/","excerpt":"","text":"todo this的理解 30道选择评测: 异常都继承自哪个类,Math.arround(-11.5),构造函数不能写void 写了就不是默认构造函数了 &#96;&#96;&#96;javaclass Test {private String name &#x3D; “person”;&#x2F;&#x2F; void Test() {&#x2F;&#x2F; System.out.println(“Test…”);&#x2F;&#x2F; } Test() { System.out.println(“Test…”); }}public class Main extends Test{&#x2F;&#x2F;学一下自己建树Main() { System.out.println(“MAain..”);}public static void main(String[] args) {&#x2F;&#x2F; new Test(); new Main();}}&#x2F;*Test…MAain.. *&#x2F; 123456789101112131415161718## A：静态方法是一个属于类而不属于对象(实例)的方法。（√）B：静态方法只能访问静态数据。无法访问非静态数据(实例变量)。（√）C：静态方法只能调用其他静态方法，不能从中调用非静态方法。（√）![img](http://uploadfiles.nowcoder.com/images/20150921/458054_1442766565525_E93E59ACFE1791E0A5503384BEBDC544)```javabyte b = 1;char c = 1;short s = 1;int i = 1; 123456789101112131415161718192021byte b = 1;char c = 1;short s = 1;int i = 1;// 三目，一边为byte另一边为char，结果为int// 其它情况结果为两边中范围大的。适用包装类型i = true? b : c;// intb = true? b : b; // bytes = true? b : s;// short// 表达式，两边为byte,short,char，结果为int型// 其它情况结果为两边中范围大的。适用包装类型i = b + c; // inti = b + b; // inti = b + s; // int// 当 a 为基本数据类型时，a += b，相当于 a = (a) (a + b)// 当 a 为包装类型时， a += b 就是 a = a + bb += s; // 没问题c += i; // 没问题// 常量任君搞，long以上不能越b = (char) 1+ (short) 1+ (int) 1; // 没问题// i = (long) 1 // 错误 第2章 Java 概述2.1 Java核心机制-JVM JVM 是一个虚拟的计算机，具有指令集并使用不同的存储区域。负责执行指令，管理数据、内存、寄存器，包含在 JDK 中. 对于不同的平台，有不同的虚拟机。 Java 虚拟机机制屏蔽了底层运行平台的差别，实现了“一次编译，到处运行 2.2JDK JRE JDK 的全称(Java Development Kit Java 开发工具包)JDK &#x3D; JRE + java 的开发工具 [java, javac,javadoc,javap 等] JDK 是提供给 Java 开发人员使用的，其中包含了 java 的开发工具，也包括了 JRE。所以安装了 JDK，就不用在单独安装 JRE 了。2.7.2JRE 基本介绍 JRE(Java Runtime Environment Java 运行环境)JRE &#x3D; JVM + Java 的核心类库[类] 包括 Java 虚拟机(JVM Java Virtual Machine)和 Java 程序所需的核心类库等，如果想要运行一个开发好的 Java 程序，计算机中只需要安装 JRE 即可。 JDK &#x3D; JRE + 开发工具集（例如 Javac,java 编译工具等) JRE &#x3D; JVM + Java SE 标准类库（java 核心类库） 如果只想运行开发好的 .class 文件，只需要JRE 2.3 java开发注意事项123456789101112131415161718192021222324252627282930//这是 java 的快速入门， 演示 java 的开发步骤//对代码的相关说明//1. public class Hello 表示 Hello 是一个类,是一个 public 公有的类//2. Hello&#123; &#125; 表示一个类的开始和结束//3. public static void main(String[] args) 表示一个主方法,即我们程序的入口//4. main() &#123;&#125; 表示方法的开始和结束//5. System.out.println(&quot;hello,world~&quot;); 表示输出&quot;hello,world~&quot;到屏幕//6. ;表示语句结束public class Hello &#123;//编写一个 main 方法public static void main(String[] args) &#123;System.out.println(&quot;韩顺平教育 hello&quot;);&#125;&#125;//一个源文件中最多只能有一个 public 类。其它类的个数不限。[演示]//Dog 是一个类//编译后，每一个类，都对于一个.classclass Dog &#123;//一个源文件中最多只能有一个 public 类。其它类的个数不限，也可以将 main 方法写在非 public 类中，//然后指定运行非 public 类，这样入口方法就是非 public 的 main 方法public static void main(String[] args) &#123;System.out.println(&quot;hello, 小狗狗~&quot;);&#125;&#125;class Tiger &#123;public static void main(String[] args) &#123;System.out.println(&quot;hello, 小老虎~&quot;);&#125;&#125; Java的所有都跟class相关 第3章 变量3.1数据类型与API JavaAPI（application program interface 应用程序编程接口）文档 中文 www.matools.com Java 提供了大量的类，API告诉开发者如何使用这些类 3.2Java类的组织形式 3.3 char+字符编码 3.4Unicode 3.5UTF-8 3.6基本数据类型转换精度小的类型自动转化为精度大的 有多种类型混合运算，系统首先自动将所有数据转换成容量最大的那种数据类型再计算 当把容量大的赋值给容量小的就会报错，反之自动类型转换 byte short 和char 不会自动转换 ，在计算式首先转换为int类型 boolen不参与转换 1234567891011121314151617181920212223242526272829303132333435363738int n1 = 10; //ok//float d1 = n1 + 1.1;//错误 n1 + 1.1 =&gt; 结果类型是 double//double d1 = n1 + 1.1;//对 n1 + 1.1 =&gt; 结果类型是 doublefloat d1 = n1 + 1.1F;//对 n1 + 1.1 =&gt; 结果类型是 float//细节 2: 当我们把精度(容量)大 的数据类型赋值给精度(容量)小 的数据类型时，//就会报错，反之就会进行自动类型转换。////int n2 = 1.1;//错误 double -&gt; int//细节 3: (byte, short) 和 char 之间不会相互自动转换//当把具体数赋给 byte 时，(1)先判断该数是否在 byte 范围内，如果是就可以byte b1 = 10; //对 , -128-127// int n2 = 1; //n2 是 int// byte b2 = n2; //错误，原因： 如果是变量赋值，判断类型//// char c1 = b1; //错误， 原因 byte 不能自动转成 char////韩顺平循序渐进学 Java 零基础第 48页//细节 4: byte，short，char 他们三者可以计算，在计算时首先转换为 int 类型byte b2 = 1;byte b3 = 2;short s1 = 1;//short s2 = b2 + s1;//错, b2 + s1 =&gt; intint s2 = b2 + s1;//对, b2 + s1 =&gt; int//byte b4 = b2 + b3; //错误: b2 + b3 =&gt; int////boolean 不参与转换boolean pass = true;//int num100 = pass;// boolean 不参与类型的自动转换//自动提升原则： 表达式结果的类型自动提升为 操作数中最大的类型//看一道题byte b4 = 1;short s3 = 100;int num200 = 1;float num300 = 1.1F;double num500 = b4 + s3 + num200 + num300; //float -&gt; double&#125; 3.7 强制类型转换自动类型转换的逆过程，将容量大的数据类型转换为容量小的数据类型。使用时要加上强制转换符 ( )，但可能造成精度降低或溢出,格外要注意 第4章 运算符4.1命名规范1.包名：多单词组成时所有字母都小写：aaa.bbb.ccc &#x2F;&#x2F;比如 com.hsp.crm 类名、接口名：多单词组成时，所有单词的首字母大写：XxxYyyZzz [大驼峰]比如： TankShotGame 变量名、方法名：多单词组成时，第一个单词首字母小写，第二个单词开始每个单词首字母大写：xxxYyyZzz [小驼峰， 简称 驼峰法]比如： tankShotGame 常量名：所有字母都大写。多单词时每个单词用下划线连接：XXX_YYY_ZZZ比如 ：定义一个所得税率 TAX_RATE 后面我们学习到 类，包，接口，等时，我们的命名规范要这样遵守,更加详细的看文档. 4.2键盘输入语句在编程中，需要接收用户输入的数据，就可以使用键盘输入语句来获取。Input.java , 需要一个 扫描器(对象), 就是 Scanner 步骤 ： 1) 导入该类的所在包, java.util.* 2) 创建该类对象（声明变量） 3) 调用里面的功能 &#96;&#96;&#96;javaimport java.util.Scanner;&#x2F;&#x2F;表示把 java.util 下的 Scanner 类导入public class Input {&#x2F;&#x2F;编写一个 main 方法public static void main(String[] args) {&#x2F;&#x2F;演示接受用户的输入&#x2F;&#x2F;步骤&#x2F;&#x2F;Scanner 类 表示 简单文本扫描器，在 java.util 包&#x2F;&#x2F;1. 引入&#x2F;导入 Scanner 类所在的包&#x2F;&#x2F;2. 创建 Scanner 对象 , new 创建一个对象,体会&#x2F;&#x2F; myScanner 就是 Scanner 类的对象Scanner myScanner &#x3D; new Scanner(System.in);&#x2F;&#x2F;3. 接收用户输入了， 使用 相关的方法System.out.println(“请输入名字”);&#x2F;&#x2F;当程序执行到 next 方法时，会等待用户输入~~~ String name &#x3D; myScanner.next(); &#x2F;&#x2F;接收用户输入字符串System.out.println(“请输入年龄”);int age &#x3D; myScanner.nextInt(); &#x2F;&#x2F;接收用户输入 intSystem.out.println(“请输入薪水”);double sal &#x3D; myScanner.nextDouble(); &#x2F;&#x2F;接收用户输入 doubleSystem.out.println(“人的信息如下:”);韩顺平循序渐进学 Java 零基础第 81页System.out.println(“名字&#x3D;” + name “ 年龄&#x3D;” + age + “ 薪水&#x3D;” + sal);}}123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233 # 第6章 数组## 6.1数组的使用### 使用方式1-动态初始化//(1) 第一种动态分配方式//double scores[] = new double[5];//(2) 第 2 种动态分配方式， 先声明数组，再 new 分配空间double scores[] ; //声明数组， 这时 scores 是 nullscores = new double[5]; // 分配内存空间，可以存放数据### 使用方式2-动态初始化### 使用方式3-静态初始化int[] a =&#123;2,3,5,6,9,41,2,1&#125;;## 6.2数组使用细节1) 数组是多个相同类型数据的组合，实现对这些数据的统一管理2) 数组中的元素可以是任何数据类型，包括基本类型和引用类型，但是不能混用。3) 数组创建后，如果没有赋值，有默认值int 0，short 0, byte 0, long 0, float 0.0,double 0.0，char \\u0000，boolean false，String null4) 使用数组的步骤 1. 声明数组并开辟空间 2 给数组各个元素赋值 3 使用数组5) 数组的下标是从 0 开始的。6) 数组下标必须在指定范围内使用，否则报：下标越界异常，比如韩顺平循序渐进学 Java 零基础第 148页int [] arr=new int[5]; 则有效下标为 0-47) 数组属引用类型，数组型数据是对象(object)## 6.3数组赋值机制[(141条消息) java堆，栈，常量池最通俗易懂的图文解释_我的博客-CSDN博客_堆栈常量池](https://blog.csdn.net/weixin_41804049/article/details/80393892)1）基本类型赋值，这个值就是具体的数据，而且互不影响2)数组在默认情况下是引用传递，赋的值是地址 栈存放基本数据类型的变量值 和对象的引用堆存放对象的具体实例 new出来的字符串常量对象存放在常量池中## 6.4数组拷贝//将 int[] arr1 = &#123;10,20,30&#125;; 拷贝到 arr2 数组, //要求数据空间是独立的. int[] arr1 = &#123;10,20,30&#125;;//创建一个新的数组 arr2,开辟新的数据空间//大小 arr1.length;int[] arr2 = new int[arr1.length];//遍历 arr1 ，把每个元素拷贝到 arr2 对应的元素位置for(int i = 0; i &lt; arr1.length; i++) &#123;arr2[i] = arr1[i];&#125;//老师修改 arr2， 不会对 arr1 有影响. arr2[0] = 100;//输出 arr1System.out.println(&quot;====arr1 的元素====&quot;);for(int i = 0; i &lt; arr1.length; i++) &#123;System.out.println(arr1[i]);//10,20,30&#125;## 6.5数组翻转方式 1：通过找规律反转 【思路分析】public class ArrayReverse &#123;//编写一个 main 方法public static void main(String[] args) &#123;//定义数组int[] arr = &#123;11, 22, 33, 44, 55, 66&#125;;//老韩思路//规律//1. 把 arr[0] 和 arr[5] 进行交换 &#123;66,22,33,44,55,11&#125;韩顺平循序渐进学 Java 零基础第 155页//2. 把 arr[1] 和 arr[4] 进行交换 &#123;66,55,33,44,22,11&#125;//3. 把 arr[2] 和 arr[3] 进行交换 &#123;66,55,44,33,22,11&#125;//4. 一共要交换 3 次 = arr.length / 2//5. 每次交换时，对应的下标 是 arr[i] 和 arr[arr.length - 1 -i]//代码//优化int temp = 0;int len = arr.length; //计算数组的长度for( int i = 0; i &lt; len / 2; i++) &#123;temp = arr[len - 1 - i];//保存arr[len - 1 - i] = arr[i];arr[i] = temp;&#125;System.out.println(&quot;===翻转后数组===&quot;);for(int i = 0; i &lt; arr.length; i++) &#123;System.out.print(arr[i] + &quot;\\t&quot;);//66,55,44,33,22,11&#125;&#125;&#125;方式 2：使用逆序赋值方式 【思路分析, 学员自己完成】 ArrayReverse02.javapublic class ArrayReverse02 &#123;//编写一个 main 方法public static void main(String[] args) &#123;//定义数组int[] arr = &#123;11, 22, 33, 44, 55, 66&#125;;//使用逆序赋值方式//老韩思路//1. 先创建一个新的数组 arr2 ,大小 arr.length//2. 逆序遍历 arr ,将 每个元素拷贝到 arr2 的元素中(顺序拷贝)//3. 建议增加一个循环变量 j -&gt; 0 -&gt; 5int[] arr2 = new int[arr.length];//逆序遍历 arrfor(int i = arr.length - 1, j = 0; i &gt;= 0; i--, j++) &#123;arr2[j] = arr[i];&#125;//4. 当 for 循环结束，arr2 就是一个逆序的数组 &#123;66, 55, 44,33, 22, 11&#125;//5. 让 arr 指向 arr2 数据空间, 此时 arr 原来的数据空间就没有变量引用// 会被当做垃圾，销毁arr = arr2;System.out.println(&quot;====arr 的元素情况=====&quot;);//6. 输出 arr 看看for(int i = 0; i &lt; arr.length; i++) &#123;韩顺平循序渐进学 Java 零基础第 157页System.out.print(arr[i] + &quot;\\t&quot;);&#125;## 6.6数组添加/扩容思路分析1. 定义初始数组 int[] arr = &#123;1,2,3&#125;//下标 0-22. 定义一个新的数组 int[] arrNew = new int[arr.length+1];3. 遍历 arr 数组，依次将 arr 的元素拷贝到 arrNew 数组4. 将 4 赋给 arrNew[arrNew.length - 1] = 4;把 4 赋给 arrNew 最后一个元素5. 让 arr 指向 arrNew ; arr = arrNew; 那么 原来 arr 数组就被销毁6. 创建一个 Scanner 可以接受用户输入## 补充1.&gt; 基本数据类型： 四类八种：1. 整数型：byte（1字节）、short（2字节） 、int（4字节）、long（8字节）long 类型要在后面加L，（可以省略，超出int 的范围时需要加L）2. 浮点型：float（4字节）、double（8字节）float 类型 要在数字后面加f3. 字符型：char（2字节）4. 布尔型：boolean（1位）是非对错&gt; 引用数据类型：除了基本数据类型之外的、都叫引用类型。1. 类2. 接口3. 数组4. 枚举## 4.什么是字节1. 位（bit）： 是计算机 内部数据 存储的最小单位，11001100是一个八位二进制数。2. 字节（byte） 是计算机中 数据处理 的基本单位，习惯上用大写B来表示；1B（byte字节）1B（byte字节） = 8bit （位）3. 字符： 是指计算机中使用的字母、数字、和符号&gt; 常见单位换算 1bit 表示 1位 1byte 表示一个字节 1B=8b 1024b = 1kb 1024kb = 1M 1024M = 1G 1024G = 1TB## 5.进制问题&gt; 进制说明二进制：0b十进制：默认八进制：0 逢八进一十六进制：0x 逢十六进一银行业务用什么表示？用BigDecimal类 数学工具类不能使用浮点数。- float： 浮点数是有限的 舍入误差，大约，接近但不等于- double： 最好完全使用浮点数进行比较 最好完全使用浮点数进行比较 最好完全使用浮点数进行比较```javapublic static void main(String[] args) &#123; int i1 = 10; int i2 = 010; int i3 = 0x10; System.out.println(i1);//10 System.out.println(i2);//8 System.out.println(i3);//16 float f = 0.1f;//0.1 double d = 1.0/10;//0.1 System.out.println(f == d);//false&#125;1234567891011121314 字符扩展？ 1234567char c1 = &#x27;a&#x27;;char c2 = &#x27;中&#x27;;System.out.println(c1);System.out.println((int)c1);//97 强制转换System.out.println(c2);System.out.println((int)c2);//20013123456 所有的字符本质还是数字编码问题 Unicode 表：（97 &#x3D; a，65 &#x3D; A） 编码 占了两个字节 转义字符\\t 制表符\\n 换行… 6.类型转换 通过查看byte包装类型得到：byte 最大值信息 1234public static final byte MIN_VALUE = -128;public static final byte MAX_VALUE = 127;123 由于java是强类型语言，所以要进行有些运算的时候，需要用到类型转换。 低 ———————————————-&gt;高 byte，short，char—&gt;，int—&gt;，float—&gt;，long—&gt;，double 运算中，不同类型的数据先转换为同一类型，然后进行运算。（小数优先级高于整数） 强制类型转换 高到低 12345int i = 128;byte b = (byte) i;//内存溢出System.out.println(i);//128System.out.println(b);//-1281234 自动类型转换 低到高 12345int i = 128;double d = i;System.out.println(i);//128System.out.println(d);//128.01234 总结： 不能对布尔类型进行转换。（不能把人转成猪，可以把男人转女人） 不能把对象类型转换为不相干的类型。 在把高容量转换为低容量的时候，需要强制转换。 转换的时候可能存在内存溢出，或者精度问题。 Java流程控制1.Scanner 类 通过scanner 类的next() 与nextLine() 方法获取输入的字符串，在读取我们一般需要使用hasNext() 与 hasNextLine() 判断是否还有输入的数据。 1234567891011121314151617Scanner sc = new Scanner(System.in)1public static void main(String[] args) &#123; //从键盘接收数据 Scanner sc = new Scanner(System.in); System.out.println(&quot;使用next方式接收：&quot;); //判断是否还有输入 if (sc.hasNext())&#123; //next() 只读取第一个字符串 //String str = sc.next(); //nextLine() 获取一行数据 String str = sc.nextLine(); System.out.println(&quot;用户输入是：&quot;+str); &#125; sc.close();&#125;1234567891011121314 next()： 一定要读取到有效字符后才可以结束输入。 对输入有效字符之前遇到的空白，next（）方法会自动将其去掉。 只有输入有效字符后才将其后面输入的空白作为分隔符或者结束符。 next（）方法不能得到有空格的不能得到有空格的字符串 nextLine(): 以Enter为结束符，也就是说 nextLine() 方法返回的是输入回车之前的所有字符 可以获得空白。 4.switch 多选择语句 switch case 语句判断一个变量和与一系列值中某个值相等，每个值称为一个分支。 switch 语句中的变量类型可以是： byte、short、int、或者是char 从 Java SE 7开始 switch 开始支持字符串 String 类型了 同时case 标签必须为字符串常量或字面量 第7章面向对象基础部分7.1创建对象 先声明再创建 Cat cat ; &#x2F;&#x2F;声明对象 cat cat &#x3D; new Cat(); &#x2F;&#x2F;创建 直接创建 Cat cat &#x3D; new Cat(); 创建对象 在方法区加载 7.2Java 内存的结构分析 栈： 一般存放基本数据类型(局部变量) 堆： 存放对象(Cat cat , 数组等) 方法区：常量池(常量，比如字符串)， 类加载信息 示意图 [Cat (name, age, price)] Java 创建对象的流程简单分析 Person p &#x3D; new Person(); p.name &#x3D; “jack”; p.age &#x3D; 10 先加载 Person 类信息(属性和方法信息, 只会加载一次) 在堆中分配空间, 进行默认初始化(看规则) 把地址赋给 p , p 就指向对象 进行指定初始化， 比如 p.name &#x3D;”jack” 方法的调用机制原理 1.当程序执行到方法时，就会开辟一个独立的空间（栈空间） 2.当方法执行完毕，或者执行到return语句时就会返回 3.返回到调用方法的地方 4.返回后继续执行方法后面的代码 5.当main方法（栈）执行完毕，整个程序退出 方法的访问修饰符 方法的返回数据类型 void可无return，或者return; 7.4成员方法传参机制7.4.1基本数据类型的传参机制基本数据类型，传递的是值 ，形参的任何改变不影响实参 7.4.2引用数据类型的传参机制B 类中编写一个方法 test100，可以接收一个数组，在方法中修改该数组，看看原来的数组是否变化？会变化 B 类中编写一个方法 test200，可以接收一个 Person(age,sal)对象，在方法中修改该对象属性，看看原来的对象是否变化？会变化 引用类型传递的是地址（传递也是值，但是值是地址） 方法栈 如果对方法传入的引入对象 然后对引入对象进行更改，并没有对原指针更改，而是将指针传给另一个值，可以根据这个地址更改原来指向的对象的属性，但不能更改原来的对象的地址 &#x2F;&#x2F;编写一个方法 copyPerson，可以复制一个 Person 对象，返回复制的对象。克隆对象， 123456789101112131415//注意要求得到新对象和原来的对象是两个独立的对象，只是他们的属性相同////编写方法的思路//1. 方法的返回类型 Person//2. 方法的名字 copyPerson//3. 方法的形参 (Person p)//4. 方法体, 创建一个新对象，并复制属性，返回即可public Person copyPerson(Person p) &#123;//创建一个新的对象Person p2 = new Person();p2.name = p.name; //把原来对象的名字赋给 p2.namep2.age = p.age; //把原来对象的年龄赋给 p2.agereturn p2;&#125;&#125; 7.4.3方法的递归调用每次调用方法 都会形成方法栈 占用主栈的空间 7.5方法重载java 中允许同一个类中，多个同名方法的存在，但要求 形参列表不一致！ 比如：System.out.println(); out 是 PrintStream 类 方法名相同 形参列表必须不同 形参类型 或个数 或顺序 7.6可变参数7.6.1基本概念java 允许将同一个类中多个同名同功能但参数个数不同的方法，封装成一个方法。就可以通过可变参数实现 7.6.2基本语法访问修饰符 返回类型 方法名(数据类型… 形参名) {} 7.6.3快速入门案例12345678910111213141516171819202122232425262728293031323334看一个案例 类 HspMethod，方法 sum 【可以计算 2 个数的和，3 个数的和 ， 4. 5， 。。】public class VarParameter01 &#123;//编写一个 main 方法public static void main(String[] args) &#123;HspMethod m = new HspMethod();System.out.println(m.sum(1, 5, 100)); //106System.out.println(m.sum(1,19)); //20&#125;&#125;class HspMethod &#123;//可以计算 2 个数的和，3 个数的和 ， 4. 5， 。。//可以使用方法重载// public int sum(int n1, int n2) &#123;//2 个数的和// return n1 + n2;// &#125;// public int sum(int n1, int n2, int n3) &#123;//3 个数的和// return n1 + n2 + n3;// &#125;// public int sum(int n1, int n2, int n3, int n4) &#123;//4 个数的和// return n1 + n2 + n3 + n4;// &#125;//..... //上面的三个方法名称相同，功能相同, 参数个数不同-&gt; 使用可变参数优化//1. int... 表示接受的是可变参数，类型是 int ,即可以接收多个 int(0-多)//2. 使用可变参数时，可以当做数组来使用 即 nums 可以当做数组//3. 遍历 nums 求和即可public int sum(int... nums) &#123;//System.out.println(&quot;接收的参数个数=&quot; + nums.length);int res = 0;for(int i = 0; i &lt; nums.length; i++) &#123;res += nums[i];&#125;return res;&#125;&#125; 7.6.4注意事项和使用细节可变参数的实参可以为0或任意多个 可变参数的实参可以维数组 可变参数的本质就是数组 可变参数可以和普通参数一起放在形参列表，但必须保证可变参数在最后 一个形参列表中只能出现一个可变参数 &#x2F;&#x2F;细节: 可变参数的实参可以为数组int[] arr &#x3D; {1, 2, 3};T t1 &#x3D; new T();t1.f1(arr);}}class T {public void f1(int… nums) {System.out.println(“长度&#x3D;” + nums.length);} 7.7作用域（对类来说）1.在Java编程中，主要的变量就是属性（成员变量）和局部变量 2.我们说的局部变量一般是指在成员方法中定义的变量 3.Java中作用域的分类 全局变量：也就是属性，作用域为整个类体 局部变量：也就是除了属性之外的其他变量，作用域为定义它的代码块中 4.属性可以不赋值，直接使用，因为有默认值，局部变量必须赋值后，才能使用因为没有默认值 5.注意事项和细节使用 属性和局部变量可以重名，访问时采用就近原则 同作用域不能重名 属性生命周期较长 伴随着对象的创建而创建，伴随着对象的销毁而销毁 局部变量伴随着代码快的执行而创建，伴随着代码的结束而销毁。即在一次方法调用过程中 作用域范围不同 ：属性可以被本类使用，或其他类使用（通过对象调用） 局部变量只能在本类中对应的方法中调用 修饰符不同 属性可以加修饰符，局部变量不可以加修饰符 7.8构造方法&#x2F;构造器第10章面向对象高级部分10.5 final 关键字可以修饰类，属性，方法和局部变量 第13 章 常用类 13.1包装类 有了类的特点，就可以调用类的方法 13.1.1装箱拆箱JDK5前 装箱：基本数据类型-&gt;包装类 拆箱相反 手动 12345678910111213141516171819public class Integer01 &#123;public static void main(String[] args) &#123;//演示 int &lt;--&gt; Integer 的装箱和拆箱//jdk5 前是手动装箱和拆箱//手动装箱 int-&gt;Integerint n1 = 100;Integer integer = new Integer(n1);Integer integer1 = Integer.valueOf(n1);//两种方式都可以 都是手动装箱//手动拆箱//Integer -&gt; intint i = integer.intValue();//jdk5 后，就可以自动装箱和自动拆箱int n2 = 200;//自动装箱 int-&gt;IntegerInteger integer2 = n2; //底层使用的是 Integer.valueOf(n2)//自动拆箱 Integer-&gt;intint n3 = integer2; //底层仍然使用的是 intValue()方法&#125;&#125; 13.1.2包装类之间的转化案例演示, 以 Integer 和 String 转换为例，其它类似: 1234567891011121314151617181920212223package com.hspedu.wrapper;/*** @author 韩顺平* @version 1.0 */ public class WrapperVSString &#123; public static void main(String[] args) &#123; //包装类(Integer)-&gt;String Integer i = 100;//自动装箱 //方式 1 String str1 = i + &quot;&quot;; //方式 2 String str2 = i.toString(); //方式 3 String str3 = String.valueOf(i); //String -&gt; 包装类(Integer) String str4 = &quot;12345&quot;; Integer i2 = Integer.parseInt(str4);//使用到自动装箱 Integer i3 = new Integer(str4);//构造器 System.out.println(&quot;ok~~&quot;); &#125; &#125; 13.1.3Integer 类和 Character类的常用方法public class WrapperMethod {public static void main(String[] args) {System.out.println(Character.isDigit(‘a’));&#x2F;&#x2F;判断是不是数字System.out.println(Character.isLetter(‘a’));&#x2F;&#x2F;判断是不是字母System.out.println(Character.isUpperCase(‘a’));&#x2F;&#x2F;判断是不是大写System.out.println(Character.isLowerCase(‘a’));&#x2F;&#x2F;判断是不是小写System.out.println(Character.isWhitespace(‘a’));&#x2F;&#x2F;判断是不是空格System.out.println(Character.toUpperCase(‘a’));&#x2F;&#x2F;转成大写System.out.println(Character.toLowerCase(‘A’));&#x2F;&#x2F;转成小写 13.1.4面试题1234567891011121314151617181920212223242526public class WrapperExercise02 &#123;public static void main(String[] args) &#123;Integer i = new Integer(1);Integer j = new Integer(1);System.out.println(i == j); //False//所以，这里主要是看范围 -128 ~ 127 就是直接返回/*//1. 如果 i 在 IntegerCache.low(-128)~IntegerCache.high(127),就直接从数组返回//2. 如果不在 -128~127,就直接 new Integer(i)public static Integer valueOf(int i) &#123;if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)return IntegerCache.cache[i + (-IntegerCache.low)];return new Integer(i);&#125;*/Integer m = 1; //底层 Integer.valueOf(1); -&gt; 阅读源码Integer n = 1;//底层 Integer.valueOf(1);System.out.println(m == n); //T//所以，这里主要是看范围 -128 ~ 127 就是直接返回//，否则，就 new Integer(xx);Integer x = 128;//底层 Integer.valueOf(1);Integer y = 128;//底层 Integer.valueOf(1);System.out.println(x == y);//False&#125;&#125; 13.2 String 类（双引号括起来）13.2.1 String 类的理解和创建对象字符串常量用双引号扩起的字符序列 ： “你好”，”12.97”等 使用Unicode编码 一个字符（不区分字母还是汉子)占两个字节 String 类常用构造器（看手册） &#x2F;&#x2F;1.String 对象用于保存字符串，也就是一组字符序列&#x2F;&#x2F;2. “jack” 字符串常量, 双引号括起的字符序列&#x2F;&#x2F;3. 字符串的字符使用 Unicode 字符编码，一个字符(不区分字母还是汉字)占两个字节&#x2F;&#x2F;4. String 类有很多构造器，构造器的重载&#x2F;&#x2F; 常用的有 String s1 &#x3D; new String(); &#x2F;&#x2F;&#x2F;&#x2F;String s2 &#x3D; new String(String original);&#x2F;&#x2F;String s3 &#x3D; new String(char[] a);&#x2F;&#x2F;String s4 &#x3D; new String(char[] a,int startIndex,int count)&#x2F;&#x2F;String s5 &#x3D; new String(byte[] b)&#x2F;&#x2F;5. String 类实现了接口 Serializable【String 可以串行化:可以在网络传输】&#x2F;&#x2F; 接口 Comparable [String 对象可以比较大小]&#x2F;&#x2F;6. String 是 final 类，不能被其他的类继承&#x2F;&#x2F;7. String 有属性 private final char value[]; 用于存放字符串内容&#x2F;&#x2F;8. 一定要注意：value 是一个 final 类型， 不可以修改(需要功力)：即 value 不能指向&#x2F;&#x2F; 新的地址，但是单个字符内容是可以变化 13.2.2创建String对象的两种方式方式一：直接赋值 String s &#x3D; “ashndkjand”; 方式二: 调用构造器 String s &#x3D; new String( “ashndkjand”); 13.2.3两种方式的区别方式一：先从常量池找是否有 “ashndkjand”数据空间，若有则直接指向，若没有则在常量池中创建，然后指向 方式二：先在堆中创建空间，里面维护了value属性，指向常量池的”ashndkjand”空间。如果常量池中没有 “ashndkjand”空间，重新创建，如果有value直接指向常量池， s最终指向的对空间 13.3字符串的特性​ 13.4 String类的常见方法​ String类是保存字符串常量的，每次更新都需要重新开辟空间，效率较低，因此java设计者还提供了StringBuilder和StringBuffer来增强String的功能，并提高效率 1234567891011121314151617181920212223242526272829303132333435public class StringMethod01 &#123;public static void main(String[] args) &#123;**//1. equals 前面已经讲过了. 比较内容是否相同，区分大小写**String str1 = &quot;hello&quot;;String str2 = &quot;Hello&quot;;System.out.println(str1.equals(str2));//**// 2.equalsIgnoreCase 忽略大小写的判断内容是否相等**String username = &quot;johN&quot;;if (&quot;john&quot;.equalsIgnoreCase(username)) &#123;System.out.println(&quot;Success!&quot;);&#125; else &#123;System.out.println(&quot;Failure!&quot;);&#125;**// 3.length 获取字符的个数，字符串的长度**System.out.println(&quot;韩顺平&quot;.length());**// 4.indexOf 获取字符在字符串对象中第一次出现的索引，索引从 0 开始，如果找不到，返回-1**String s1 = &quot;wer@terwe@g&quot;;int index = s1.indexOf(&#x27;@&#x27;);System.out.println(index);// 3System.out.println(&quot;weIndex=&quot; + s1.indexOf(&quot;we&quot;));//0**// 5.lastIndexOf 获取字符在字符串中最后一次出现的索引，索引从 0 开始，如果找不到，返回-1**s1 = &quot;wer@terwe@g@&quot;;index = s1.lastIndexOf(&#x27;@&#x27;);System.out.println(index);//11System.out.println(&quot;ter 的位置=&quot; + s1.lastIndexOf(&quot;ter&quot;));//4**// 6.substring 截取指定范围的子串**String name = &quot;hello,张三&quot;;//下面 name.substring(6) 从索引 6 开始截取后面所有的内容System.out.println(name.substring(6));//截取后面的字符//name.substring(0,5)表示从索引 0 开始截取，截取到索引 5-1=4 位置System.out.println(name.substring(2,5));//llo&#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class StringMethod02 &#123;public static void main(String[] args) &#123;**// 1.toUpperCase 转换成大写**String s = &quot;heLLo&quot;;System.out.println(s.toUpperCase());//HELLO**// 2.toLowerCase**System.out.println(s.toLowerCase());//hello**// 3.concat 拼接字符串**String s1 = &quot;宝玉&quot;;s1 = s1.concat(&quot;林黛玉&quot;).concat(&quot;薛宝钗&quot;).concat(&quot;together&quot;);System.out.println(s1);//宝玉林黛玉薛宝钗 together**// 4.replace 替换字符串中的字符**s1 = &quot;宝玉 and 林黛玉 林黛玉 林黛玉&quot;;//在 s1 中，将 所有的 林黛玉 替换成薛宝钗// 老韩解读: s1.replace() 方法执行后，返回的结果才是替换过的. // 注意对 s1 没有任何影响String s11 = s1.replace(&quot;宝玉&quot;, &quot;jack&quot;);System.out.println(s1);//宝玉 and 林黛玉 林黛玉 林黛玉System.out.println(s11);//jack and 林黛玉 林黛玉 林黛玉**// 5.split 分割字符串, 对于某些分割字符，我们需要 转义比如 | \\\\等**String poem = &quot;锄禾日当午,汗滴禾下土,谁知盘中餐,粒粒皆辛苦&quot;;//老韩解读：// 1. 以 , 为标准对 poem 进行分割 , 返回一个数组// 2. 在对字符串进行分割时，如果有特殊字符，需要加入 转义符 \\String[] split = poem.split(&quot;,&quot;);poem = &quot;E:\\\\aaa\\\\bbb&quot;;split = poem.split(&quot;\\\\\\\\&quot;);System.out.println(&quot;==分割后内容===&quot;);for (int i = 0; i &lt; split.length; i++) &#123;System.out.println(split[i]);&#125;**// 6.toCharArray 转换成字符数组**s = &quot;happy&quot;;char[] chs = s.toCharArray();for (int i = 0; i &lt; chs.length; i++) &#123;System.out.println(chs[i]);&#125;**// 7.compareTo 比较两个字符串的大小，如果前者大，****// 则返回正数，后者大，则返回负数，如果相等，返回 0**// 老韩解读// (1) 如果长度相同，并且每个字符也相同，就返回 0// (2) 如果长度相同或者不相同，但是在进行比较时，可以区分大小// 就返回 if (c1 != c2) &#123;// return c1 - c2;// &#125;// (3) 如果前面的部分都相同，就返回 str1.len - str2.lenString a = &quot;jcck&quot;;// len = 3String b = &quot;jack&quot;;// len = 4System.out.println(a.compareTo(b)); // 返回值是 &#x27;c&#x27; - &#x27;a&#x27; = 2 的值**// 8.format 格式字符串**/* 占位符有:%s 字符串 %c 字符 %d 整型 %.2f 浮点型**/String name = &quot;john&quot;;int age = 10;double score = 56.857;char gender = &#x27;男&#x27;;//将所有的信息都拼接在一个字符串. String info =&quot;我的姓名是&quot; + name + &quot;年龄是&quot; + age + &quot;,成绩是&quot; + score + &quot;性别是&quot; + gender + &quot;。希望大家喜欢我！&quot;;System.out.println(info);//老韩解读//1. %s , %d , %.2f %c 称为占位符//2. 这些占位符由后面变量来替换//3. %s 表示后面由 字符串来替换//4. %d 是整数来替换//5. %.2f 表示使用小数来替换，替换后，只会保留小数点两位, 并且进行四舍五入的处理//6. %c 使用 char 类型来替换String formatStr = &quot;我的姓名是%s 年龄是%d，成绩是%.2f 性别是%c.希望大家喜欢我！&quot;;String info2 = String.format(formatStr, name, age, score, gender);System.out.println(&quot;info2=&quot; + info2); //7 split()（分裂）根据匹配给定的正则表达式来拆分字符串 //注意、.、$、|、等转义字符，必须加\\\\ 注意：多个分隔符可以用|作为连字符 public String[] split(String regex, int limit) //regex 正则表达式分隔符 limit 分割的份数 //return 字符串&#125;&#125; 13.5 StringBuffer类13.5.1基本介绍java.lang.StringBuffer代表可变的字符序列，可以对字符串内容进行增删。 很多方法与String相同 ，但StringBuilder是可变长度的。 1234567891011121314public class StringBuffer01 &#123;public static void main(String[] args) &#123;//老韩解读//1. StringBuffer 的直接父类 是 AbstractStringBuilder//2. StringBuffer 实现了 Serializable, 即 StringBuffer 的对象可以串行化//3. 在父类中 AbstractStringBuilder 有属性 char[] value,不是 final// 该 value 数组存放 字符串内容，引出存放在堆中的//4. StringBuffer 是一个 final 类，不能被继承//5. 因为 StringBuffer 字符内容是存在 char[] value, 所有在变化(增加/删除)// 不用每次都更换地址(即不是每次创建新对象)， 所以效率高于 StringStringBuffer stringBuffer = new StringBuffer(&quot;hello&quot;);&#125;&#125; 13.5.2 String vs StringBufferString保存的是字符串常量，里面的值不能更改，每次String类的更新实际上就是更改地址，效率较低 StringBuffer保存的是字符串变量，里面的值可以更改，每次StringBuffer的更新实际上可以更改内容，不用每次都更新地址效率较高 13.5.3 两者的互相转换123456789101112131415161718public class StringAndStringBuffer &#123;public static void main(String[] args) &#123;//看 String——&gt;StringBufferString str = &quot;hello tom&quot;;//方式 1 使用构造器//注意： 返回的才是 StringBuffer 对象，对 str 本身没有影响StringBuffer stringBuffer = new StringBuffer(str);//方式 2 使用的是 append 方法StringBuffer stringBuffer1 = new StringBuffer();stringBuffer1 = stringBuffer1.append(str);//看看 StringBuffer -&gt;StringStringBuffer stringBuffer3 = new StringBuffer(&quot;韩顺平教育&quot;);//方式 1 使用 StringBuffer 提供的 toString 方法String s = stringBuffer3.toString();//方式 2: 使用构造器来搞定String s1 = new String(stringBuffer3);&#125;&#125; 13.5.4 StringBuffer 类常见方法12345678910111213141516171819202122232425262728293031323334public class StringBufferMethod &#123;public static void main(String[] args) &#123;StringBuffer s = new StringBuffer(&quot;hello&quot;);//增s.append(&#x27;,&#x27;);// &quot;hello,&quot;s.append(&quot;张三丰&quot;);//&quot;hello,张三丰&quot;s.append(&quot;赵敏&quot;).append(100).append(true).append(10.5);//&quot;hello,张三丰赵敏 100true10.5&quot; System.out.println(s);//&quot;hello,张三丰赵敏 100true10.5&quot;//删/** 删除索引为&gt;=start &amp;&amp; &lt;end 处的字符* 解读: 删除 11~14 的字符 [11, 14)*/s.delete(11, 14);System.out.println(s);//&quot;hello,张三丰赵敏 true10.5&quot;//改//老韩解读，使用 周芷若 替换 索引 9-11 的字符 [9,11)s.replace(9, 11, &quot;周芷若&quot;);System.out.println(s);//&quot;hello,张三丰周芷若 true10.5&quot;//查找指定的子串在字符串第一次出现的索引，如果找不到返回-1int indexOf = s.indexOf(&quot;张三丰&quot;);System.out.println(indexOf);//6//插//老韩解读，在索引为 9 的位置插入 &quot;赵敏&quot;,原来索引为 9 的内容自动后移s.insert(9, &quot;赵敏&quot;);System.out.println(s);//&quot;hello,张三丰赵敏周芷若 true10.5&quot;//长度System.out.println(s.length());//22System.out.println(s);&#125;&#125; 13.6 StringBuilder 线程不安全的StringBuffer13.7 Math 类Math类包含用于执行基本数学运算的方法，如初等函数、对数、平方根和三角函数。 均为静态方法 12345678910111213141516171819202122232425262728293031323334353637383940414243public class MathMethod &#123;public static void main(String[] args) &#123;//看看 Math 常用的方法(静态方法)//1.abs 绝对值int abs = Math.abs(-9);System.out.println(abs);//9//2.pow 求幂double pow = Math.pow(2, 4);//2 的 4 次方System.out.println(pow);//16//3.ceil 向上取整,返回&gt;=该参数的最小整数(转成 double);double ceil = Math.ceil(3.9);System.out.println(ceil);//4.0//4.floor 向下取整，返回&lt;=该参数的最大整数(转成 double)double floor = Math.floor(4.001);System.out.println(floor);//4.0//5.round 四舍五入 Math.floor(该参数+0.5)long round = Math.round(5.51);System.out.println(round);//6//6.sqrt 求开方double sqrt = Math.sqrt(9.0);System.out.println(sqrt);//3.0//7.random 求随机数// random 返回的是 0 &lt;= x &lt; 1 之间的一个随机小数// 思考：请写出获取 a-b 之间的一个随机整数,a,b 均为整数 ，比如 a = 2, b=7// 即返回一个数 x 2 &lt;= x &lt;= 7// 解读 Math.random() * (b-a) 返回的就是 0 &lt;= 数 &lt;= b-a// (1) (int)(a) &lt;= x &lt;= (int)(a + Math.random() * (b-a +1) )// (2) 使用具体的数给小伙伴介绍 a = 2 b = 7// (int)(a + Math.random() * (b-a +1) ) = (int)( 2 + Math.random()*6)// Math.random()*6 返回的是 0 &lt;= x &lt; 6 小数// 2 + Math.random()*6 返回的就是 2&lt;= x &lt; 8 小数// (int)(2 + Math.random()*6) = 2 &lt;= x &lt;= 7// (3) 公式就是 (int)(a + Math.random() * (b-a +1) )for(int i = 0; i &lt; 100; i++) &#123;System.out.println((int)(2 + Math.random() * (7 - 2 + 1)));&#125;//max , min 返回最大值和最小值int min = Math.min(1, 9);int max = Math.max(45, 90);System.out.println(&quot;min=&quot; + min);System.out.println(&quot;max=&quot; + max);&#125;&#125; 13.8 Arrays类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166public class ArraysMethod01 &#123;public static void main(String[] args) &#123;Integer[] integers = &#123;1, 20, 90&#125;;//遍历数组// for(int i = 0; i &lt; integers.length; i++) &#123;// System.out.println(integers[i]);// &#125;//直接使用 Arrays.toString 方法，显示数组// System.out.println(Arrays.toString(integers));////演示 sort 方法的使用Integer arr[] = &#123;1, -1, 7, 0, 89&#125;;//进行排序//老韩解读//1. 可以直接使用冒泡排序 , 也可以直接使用 Arrays 提供的 sort 方法排序//2. 因为数组是引用类型，所以通过 sort 排序后，会直接影响到 实参 arr//3. sort 重载的，也可以通过传入一个接口 Comparator 实现定制排序//4. 调用 定制排序 时，传入两个参数 (1) 排序的数组 arr// (2) 实现了 Comparator 接口的匿名内部类 , 要求实现 compare 方法//5. 先演示效果，再解释//6. 这里体现了接口编程的方式 , 看看源码，就明白// 源码分析//(1) Arrays.sort(arr, new Comparator()//(2) 最终到 TimSort 类的 private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, // Comparator&lt;? super T&gt; c)()//(3) 执行到 binarySort 方法的代码, 会根据动态绑定机制 c.compare()执行我们传入的// 匿名内部类的 compare ()// while (left &lt; right) &#123;// int mid = (left + right) &gt;&gt;&gt; 1;// if (c.compare(pivot, a[mid]) &lt; 0)// right = mid;// else// left = mid + 1;// &#125;//(4) new Comparator() &#123;// @Override// public int compare(Object o1, Object o2) &#123;// Integer i1 = (Integer) o1;// Integer i2 = (Integer) o2;// return i2 - i1;// &#125;// &#125;//(5) public int compare(Object o1, Object o2) 返回的值&gt;0 还是 &lt;0// 会影响整个排序结果, 这就充分体现了 接口编程+动态绑定+匿名内部类的综合使用// 将来的底层框架和源码的使用方式，会非常常见//Arrays.sort(arr); // 默认排序方法//定制排序Arrays.sort(arr, new Comparator() &#123;@Overridepublic int compare(Object o1, Object o2) &#123;Integer i1 = (Integer) o1;Integer i2 = (Integer) o2;return i2 - i1;&#125;&#125;);System.out.println(&quot;===排序后===&quot;);System.out.println(Arrays.toString(arr));//&#125;&#125;package com.hspedu.arrays_;import java.util.Arrays;import java.util.Comparator;/*** @author 韩顺平* @version 1.0*/public class ArraysSortCustom &#123;韩顺平循序渐进学 Java 零基础第 575页public static void main(String[] args) &#123;int[] arr = &#123;1, -1, 8, 0, 20&#125;;//bubble01(arr);bubble02(arr, new Comparator() &#123;@Overridepublic int compare(Object o1, Object o2) &#123;int i1 = (Integer) o1;int i2 = (Integer) o2;return i2 - i1;// return i2 - i1;&#125;&#125;);System.out.println(&quot;==定制排序后的情况==&quot;);System.out.println(Arrays.toString(arr));&#125;//使用冒泡完成排序public static void bubble01(int[] arr) &#123;int temp = 0;for (int i = 0; i &lt; arr.length - 1; i++) &#123;for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123;//从小到大if (arr[j] &gt; arr[j + 1]) &#123;韩顺平循序渐进学 Java 零基础第 576页temp = arr[j];arr[j] = arr[j + 1];arr[j + 1] = temp;&#125;&#125;&#125;&#125;//结合冒泡 + 定制public static void bubble02(int[] arr, Comparator c) &#123;int temp = 0;for (int i = 0; i &lt; arr.length - 1; i++) &#123;for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123;//数组排序由 c.compare(arr[j], arr[j + 1])返回的值决定if (c.compare(arr[j], arr[j + 1]) &gt; 0) &#123;temp = arr[j];arr[j] = arr[j + 1];arr[j + 1] = temp;&#125;&#125;&#125;&#125;&#125;package com.hspedu.arrays_;import java.util.Arrays;import java.util.List;/*** @author 韩顺平* @version 1.0*/public class ArraysMethod02 &#123;public static void main(String[] args) &#123;Integer[] arr = &#123;1, 2, 90, 123, 567&#125;;// binarySearch 通过二分搜索法进行查找，要求必须排好// 老韩解读//1. 使用 binarySearch 二叉查找//2. 要求该数组是有序的. 如果该数组是无序的，不能使用 binarySearch//3. 如果数组中不存在该元素，就返回 return -(low + 1); // key not found. int index = Arrays.binarySearch(arr, 567);System.out.println(&quot;index=&quot; + index);//copyOf 数组元素的复制// 老韩解读//1. 从 arr 数组中，拷贝 arr.length 个元素到 newArr 数组中//2. 如果拷贝的长度 &gt; arr.length 就在新数组的后面 增加 null//3. 如果拷贝长度 &lt; 0 就抛出异常 NegativeArraySizeException//4. 该方法的底层使用的是 System.arraycopy()Integer[] newArr = Arrays.copyOf(arr, arr.length);System.out.println(&quot;==拷贝执行完毕后==&quot;);韩顺平循序渐进学 Java 零基础第 578页System.out.println(Arrays.toString(newArr));//ill 数组元素的填充Integer[] num = new Integer[]&#123;9,3,2&#125;;//老韩解读//1. 使用 99 去填充 num 数组，可以理解成是替换原理的元素Arrays.fill(num, 99);System.out.println(&quot;==num 数组填充后==&quot;);System.out.println(Arrays.toString(num));//equals 比较两个数组元素内容是否完全一致Integer[] arr2 = &#123;1, 2, 90, 123&#125;;//老韩解读//1. 如果 arr 和 arr2 数组的元素一样，则方法 true;//2. 如果不是完全一样，就返回 falseboolean equals = Arrays.equals(arr, arr2);System.out.println(&quot;equals=&quot; + equals);//asList 将一组值，转换成 list//老韩解读//1. asList 方法，会将 (2,3,4,5,6,1)数据转成一个 List 集合//2. 返回的 asList 编译类型 List(接口)//3. asList 运行类型 java.util.Arrays#ArrayList, 是 Arrays 类的// 静态内部类 private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;// implements RandomAccess, java.io.SerializableList asList = Arrays.asList(2,3,4,5,6,1);System.out.println(&quot;asList=&quot; + asList);System.out.println(&quot;asList 的运行类型&quot; + asList.getClass());&#125;&#125; 13.9 System类 123456789101112131415161718192021222324252627282930313233343536package com.hspedu.system_;import java.util.Arrays;/*** @author 韩顺平* @version 1.0*/public class System_ &#123;public static void main(String[] args) &#123;//exit 退出当前程序// System.out.println(&quot;ok1&quot;);// //老韩解读// //1. exit(0) 表示程序退出// //2. 0 表示一个状态 , 正常的状态// System.exit(0);//// System.out.println(&quot;ok2&quot;);//arraycopy ：复制数组元素，比较适合底层调用，// 一般使用 Arrays.copyOf 完成复制数组int[] src=&#123;1,2,3&#125;;int[] dest = new int[3];// dest 当前是 &#123;0,0,0&#125;//老韩解读//1. 主要是搞清楚这五个参数的含义//2. // 源数组韩顺平循序渐进学 Java 零基础第 586页// * @param src the source array. // srcPos： 从源数组的哪个索引位置开始拷贝// * @param srcPos starting position in the source array. // dest : 目标数组，即把源数组的数据拷贝到哪个数组// * @param dest the destination array. // destPos: 把源数组的数据拷贝到 目标数组的哪个索引// * @param destPos starting position in the destination data. // length: 从源数组拷贝多少个数据到目标数组// * @param length the number of array elements to be copied. System.arraycopy(src, 0, dest, 0, src.length);// int[] src=&#123;1,2,3&#125;;System.out.println(&quot;dest=&quot; + Arrays.toString(dest));//[1, 2, 3]//currentTimeMillens:返回当前时间距离 1970-1-1 的毫秒数// 老韩解读:System.out.println(System.currentTimeMillis());&#125;&#125; 13.10 BigInteger和BigDecimal类应用场景： BigInteger适合保存较大的整形 BigDecimal适合保存精度更高的浮点型 两者的常见方法 1234567891011121314151617181920212223public class BigInteger_ &#123;public static void main(String[] args) &#123;//当我们编程中，需要处理很大的整数，long 不够用//可以使用 BigInteger 的类来搞定// long l = 23788888899999999999999999999l;// System.out.println(&quot;l=&quot; + l);BigInteger bigInteger = new BigInteger(&quot;23788888899999999999999999999&quot;);BigInteger bigInteger2 = newBigInteger(&quot;10099999999999999999999999999999999999999999999999999999999999999999999999999999999&quot;);System.out.println(bigInteger);//解读//1. 在对 BigInteger 进行加减乘除的时候，需要使用对应的方法，不能直接进行 + - * ///2. 可以创建一个 要操作的 BigInteger 然后进行相应操作BigInteger add = bigInteger.add(bigInteger2);System.out.println(add);//BigInteger subtract = bigInteger.subtract(bigInteger2);System.out.println(subtract);//减BigInteger multiply = bigInteger.multiply(bigInteger2);System.out.println(multiply);//乘BigInteger divide = bigInteger.divide(bigInteger2);System.out.println(divide);//除&#125;&#125; 123456789101112131415161718192021public class BigDecimal_ &#123;public static void main(String[] args) &#123;//当我们需要保存一个精度很高的数时，double 不够用//可以是 BigDecimal// double d = 1999.11111111111999999999999977788d;// System.out.println(d);BigDecimal bigDecimal = new BigDecimal(&quot;1999.11&quot;);BigDecimal bigDecimal2 = new BigDecimal(&quot;3&quot;);System.out.println(bigDecimal);//老韩解读//1. 如果对 BigDecimal 进行运算，比如加减乘除，需要使用对应的方法//2. 创建一个需要操作的 BigDecimal 然后调用相应的方法即可System.out.println(bigDecimal.add(bigDecimal2));System.out.println(bigDecimal.subtract(bigDecimal2));System.out.println(bigDecimal.multiply(bigDecimal2));//System.out.println(bigDecimal.divide(bigDecimal2));//可能抛出异常 ArithmeticException//在调用 divide 方法时，指定精度即可. BigDecimal.ROUND_CEILING//如果有无限循环小数，就会保留 分子 的精度System.out.println(bigDecimal.divide(bigDecimal2, BigDecimal.ROUND_CEILING));&#125;&#125; 第14章 集合Deque是一个双端队列接口，继承自Queue接口，Deque的实现类是LinkedList、ArrayDeque、LinkedBlockingDeque，其中LinkedList是最常用的。 关于Queue的介绍可以看上一篇文章：Java队列Queue使用详解 Deque有三种用途：普通队列(一端进另一端出):Queue queue &#x3D; new LinkedList()或Deque deque &#x3D; new LinkedList()双端队列(两端都可进出)Deque deque &#x3D; new LinkedList()堆栈Deque deque &#x3D; new LinkedList()注意：Java堆栈Stack类已经过时，Java官方推荐使用Deque替代Stack使用。Deque堆栈操作方法：push()、pop()、peek()。 Deque是一个线性collection，支持在两端插入和移除元素。名称 deque 是“double ended queue（双端队列）”的缩写，通常读为“deck”。大多数 Deque 实现对于它们能够包含的元素数没有固定限制，但此接口既支持有容量限制的双端队列，也支持没有固定大小限制的双端队列。 此接口定义在双端队列两端访问元素的方法。提供插入、移除和检查元素的方法。每种方法都存在两种形式：一种形式在操作失败时抛出异常，另一种形式返回一个特殊值（null 或 false，具体取决于操作）。插入操作的后一种形式是专为使用有容量限制的 Deque 实现设计的；在大多数实现中，插入操作不能失败。 下表总结了上述 12 种方法： 第一个元素 (头部) 最后一个元素 (尾部)抛出异常 特殊值 抛出异常 特殊值插入 addFirst(e) offerFirst(e) addLast(e) offerLast(e)删除 removeFirst() pollFirst() removeLast() pollLast()检查 getFirst() peekFirst() getLast() peekLast()Deque接口扩展(继承)了 Queue 接口。在将双端队列用作队列时，将得到 FIFO（先进先出）行为。将元素添加到双端队列的末尾，从双端队列的开头移除元素。从 Queue 接口继承的方法完全等效于 Deque 方法，如下表所示： Queue方法 等效Deque方法add(e) addLast(e)offer(e) offerLast(e)remove() removeFirst()poll() pollFirst()element() getFirst()peek() peekFirst() 增加一个方法，可以返回当前栈顶的值, 但是不是真正的 pop 双端队列也可用作 LIFO（后进先出）堆栈。应优先使用此接口而不是遗留 Stack 类。在将双端队列用作堆栈时，元素被推入双端队列的开头并从双端队列开头弹出。堆栈方法完全等效于 Deque 方法，如下表所示： 堆栈方法 等效Deque方法push(e) addFirst(e)pop() removeFirst()peek() peekFirst(————————————————版权声明：本文为CSDN博主「devnn」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/devnn/article/details/82716447 14.1集合的理解与好处数组长度固定不能更改 CRUD（增加 (Create)、读取(Retrieve) (重新得到数据)、更新 (Update)和删除 (Delete)增删改查）不方便 集合可以动态保存任意多个对象（底层源码运用扩容机制），提供了一系列方便的方法，add、remove、set、get等 14.2集合的框架体系单列集合 add（“tom”） 接口定义方法类会自己具体实现各种方法 双列集合 put（“NO1”,“北京”） 14.3 Collection接口和常用方法Collection的实现类 有可以存放重复的元素 有些不可以 ​ 有些是有序的（list）有些是无序的（set） Collection接口没有直接的实现子类，是通过子接口set和list来实现的 123456789101112131415161718192021222324252627282930313233343536373839404142Collection 接口常用方法,以实现子类 ArrayList 来演示. CollectionMethod.javapackage com.hspedu.collection_;import java.util.ArrayList;import java.util.List;public class CollectionMethod &#123;@SuppressWarnings(&#123;&quot;all&quot;&#125;)public static void main(String[] args) &#123;List list = new ArrayList();// add:添加单个元素list.add(&quot;jack&quot;);list.add(10);//list.add(new Integer(10))list.add(true);System.out.println(&quot;list=&quot; + list);// remove:删除指定元素//list.remove(0);//删除第一个元素list.remove(true);//指定删除某个元素System.out.println(&quot;list=&quot; + list);// contains:查找元素是否存在System.out.println(list.contains(&quot;jack&quot;));//T// size:获取元素个数System.out.println(list.size());//2// isEmpty:判断是否为空System.out.println(list.isEmpty());//F// clear:清空list.clear();System.out.println(&quot;list=&quot; + list);// addAll:添加多个元素ArrayList list2 = new ArrayList();list2.add(&quot;红楼梦&quot;);list2.add(&quot;三国演义&quot;);list.addAll(list2);System.out.println(&quot;list=&quot; + list);// containsAll:查找多个元素是否都存在System.out.println(list.containsAll(list2));//T// removeAll：删除多个元素list.add(&quot;聊斋&quot;);list.removeAll(list2);System.out.println(&quot;list=&quot; + list);//[聊斋]// 说明：以 ArrayList 实现类来演示. &#125;&#125; 第21章 网络编程查询 API 的一般流程是：找包→找类或接口→查看类或接口→找方法或变量 21.1网络的相关概念计算机网络 21.2InetAddress类21.2.1相关方法1.获取本机InetAddress对象 InetAddress.getLocalHost 静态方法 ，return LAPTOP-PH64GORS&#x2F;192.168.137.1 2.根据指定主机名&#x2F;域名获取ip地址对象InetAddress.getByName（主机名） 3.获取InetAddress对象的主机名 getHostName 4.获取InetAddress对象的地址 getHostAddress 12345678910111213141516171819//1. 获取本机的InetAddress 对象InetAddress localHost = InetAddress.getLocalHost();System.out.println(localHost);//DESKTOP-S4MP84S/192.168.12.1//2. 根据指定主机名 获取 InetAddress对象InetAddress host1 = InetAddress.getByName(&quot;LAPTOP-PH64GORS&quot;);System.out.println(&quot;host1=&quot; + host1);//DESKTOP-S4MP84S/192.168.12.1//3. 根据域名返回 InetAddress对象, 比如 www.baidu.com 对应InetAddress host2 = InetAddress.getByName(&quot;www.baidu.com&quot;);System.out.println(&quot;host2=&quot; + host2);//www.baidu.com / 110.242.68.4//4. 通过 InetAddress 对象，获取对应的地址String hostAddress = host2.getHostAddress();//IP 110.242.68.4System.out.println(&quot;host2 对应的ip = &quot; + hostAddress);//110.242.68.4//5. 通过 InetAddress 对象，获取对应的主机名/或者的域名String hostName = host2.getHostName();System.out.println(&quot;host2对应的主机名/域名=&quot; + hostName); // www.baidu.com 21.3 Socket21.3.1基本介绍1.套接字（Socket）开发网络应用程序被广泛采用，以至成为事实上的标准 2.通信两端都要是Socket，是两台机器间通信的端点 3.网络通信其实就是Socket的通信 4.Socket允许程序把网络连接当成一个流，数据在两个Socket间通过IO传输。 5.一般主动发起通信的应用程序属于客户端，等待的为服务端 21.4 TCP网络通信编程 21.4.1使用字节流123456789101112131415161718public class SocketTCP01Client &#123; public static void main(String[] args) throws IOException &#123; //思路 //1. 连接服务端 (ip , 端口） //解读: 连接本机的 9999端口, 如果连接成功，返回Socket对象 Socket socket = new Socket(InetAddress.getLocalHost(), 9999); System.out.println(&quot;客户端 socket返回=&quot; + socket.getClass()); //2. 连接上后，生成Socket, 通过socket.getOutputStream() // 得到 和 socket对象关联的输出流对象 OutputStream outputStream = socket.getOutputStream(); //3. 通过输出流，写入数据到 数据通道 outputStream.write(&quot;hello, server&quot;.getBytes()); //4. 关闭流对象和socket, 必须关闭 outputStream.close(); socket.close(); System.out.println(&quot;客户端退出.....&quot;); &#125;&#125; 123456789101112131415161718192021222324252627282930public class SocketTCP01Server &#123; public static void main(String[] args) throws IOException &#123; //思路 //1. 在本机 的9999端口监听, 等待连接 // 细节: 要求在本机没有其它服务在监听9999 // 细节：这个 ServerSocket 可以通过 accept() 返回多个Socket[多个客户端连接服务器的并发] ServerSocket serverSocket = new ServerSocket(9999); System.out.println(&quot;服务端，在9999端口监听，等待连接..&quot;); //2. 当没有客户端连接9999端口时，程序会 阻塞, 等待连接 // 如果有客户端连接，则会返回Socket对象，程序继续 Socket socket = serverSocket.accept(); System.out.println(&quot;服务端 socket =&quot; + socket.getClass()); // //3. 通过socket.getInputStream() 读取客户端写入到数据通道的数据, 显示 InputStream inputStream = socket.getInputStream(); //4. IO读取 byte[] buf = new byte[1024]; int readLen = 0; while ((readLen = inputStream.read(buf)) != -1) &#123; System.out.println(new String(buf, 0, readLen));//根据读取到的实际长度，显示内容. &#125; //5.关闭流和socket inputStream.close(); socket.close(); serverSocket.close();//关闭 &#125;&#125; 21.4.2使用字符流1234567891011121314151617181920212223242526272829public static void main(String[] args) throws IOException &#123; //思路 //1. 连接服务端 (ip , 端口） //解读: 连接本机的 9999端口, 如果连接成功，返回Socket对象 Socket socket = new Socket(InetAddress.getLocalHost(), 9999); System.out.println(&quot;客户端 socket返回=&quot; + socket.getClass()); //2. 连接上后，生成Socket, 通过socket.getOutputStream() // 得到 和 socket对象关联的输出流对象 OutputStream outputStream = socket.getOutputStream(); //3. 通过输出流，写入数据到 数据通道, 使用字符流 BufferedWriter bufferedWriter = new BufferedWriter(new OutputStreamWriter(outputStream)); bufferedWriter.write(&quot;hello, server 字符流&quot;); bufferedWriter.newLine();//插入一个换行符，表示写入的内容结束, 注意，要求对方使用readLine()!!!! bufferedWriter.flush();// 如果使用的字符流，需要手动刷新，否则数据不会写入数据通道 //4. 获取和socket关联的输入流. 读取数据(字符)，并显示 InputStream inputStream = socket.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); String s = bufferedReader.readLine(); System.out.println(s); //5. 关闭流对象和socket, 必须关闭 bufferedReader.close();//关闭外层流 bufferedWriter.close(); socket.close(); System.out.println(&quot;客户端退出.....&quot;); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839public class SocketTCP03Server &#123; public static void main(String[] args) throws IOException &#123; //思路 //1. 在本机 的9999端口监听, 等待连接 // 细节: 要求在本机没有其它服务在监听9999 // 细节：这个 ServerSocket 可以通过 accept() 返回多个Socket[多个客户端连接服务器的并发] ServerSocket serverSocket = new ServerSocket(9999); System.out.println(&quot;服务端，在9999端口监听，等待连接..&quot;); //2. 当没有客户端连接9999端口时，程序会 阻塞, 等待连接 // 如果有客户端连接，则会返回Socket对象，程序继续 Socket socket = serverSocket.accept(); System.out.println(&quot;服务端 socket =&quot; + socket.getClass()); // //3. 通过socket.getInputStream() 读取客户端写入到数据通道的数据, 显示 InputStream inputStream = socket.getInputStream(); //4. IO读取, 使用字符流, 老师使用 InputStreamReader 将 inputStream 转成字符流 BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); String s = bufferedReader.readLine(); System.out.println(s);//输出 //5. 获取socket相关联的输出流 OutputStream outputStream = socket.getOutputStream(); // 使用字符输出流的方式回复信息 BufferedWriter bufferedWriter = new BufferedWriter(new OutputStreamWriter(outputStream)); bufferedWriter.write(&quot;hello client 字符流&quot;); bufferedWriter.newLine();// 插入一个换行符，表示回复内容的结束 bufferedWriter.flush();//注意需要手动的flush //6.关闭流和socket bufferedWriter.close(); bufferedReader.close(); socket.close(); serverSocket.close();//关闭 &#125;&#125; 21.4.3文件发送21.4.4 netstat 指令 telnet ip 端口号 连接服务器 crtl+】 显示字符 用Java连接服务器 12345678try (var s = new Socket(&quot;time-a.nist.gov&quot;, 13); //打开一个关键字，负责启动该程序内部和外部的通信 若连接失败 它将抛出 // 一个UnknownHostException, // 如果存在其他问题将抛出一个IOException 因为UnknownException是IOException的一个子类 这仅是示例程序仅捕获超类的异常 var in = new Scanner(s.getInputStream(), StandardCharsets.UTF_8))//一旦套接字打开 Socket 类中的getInputStream 类就会返回一个InputSteam对象，该对象可以像任何其他流对象使用，该程序一旦获得了 //这个流 该程序会将直接把每一行打印到标准输出 该程序只适用非常简单的服务器 //在比较复杂的网络程序中 客户端发送请求而服务器可能在响应结束是并不立刻断开连接 //java库隐藏了建立网络连接和通过连接发送数据的复杂过程 12345678910111213141516171819202122232425262728import java.io.*;import java.net.*;/** * This program demonstrates the InetAddress class. Supply a host name as command-line * argument, or run without command-line arguments to see the address of the local host. * @version 1.02 2012-06-05 * @author Cay Horstmann */public class InetAddressTest&#123; public static void main(String[] args) throws IOException &#123; if (args.length &gt; 0) &#123; String host = args[0]; InetAddress[] addresses = InetAddress.getAllByName(host);//为给定的主机名创建一个InetAddress对象 // for (InetAddress a : addresses) System.out.println(a); &#125; else &#123; InetAddress localHostAddress = InetAddress.getLocalHost(); //为本机主机创建一个InetAddress对象 System.out.println(localHostAddress); &#125; &#125;&#125; InetAddress Socket 基础知识基础类型byte是字节类型 char 是unicode 是万国码 16位 兼容assic 类型转换自动向上类型转换 强制向下转换(对表达式强转) 比较器&amp;gt 则返回 1 &amp;lt 则返回 -1 sort 默认从小到大,比较器不关注sort,只关注传递大小信息 lamda随便写写 基本类型不支持比较器 Date File类 创建文件对象,对对象进行操作 文件夹或文件皆可抽象为file,但文件夹不能被输入输出 IO流字节与字符的区别 字节(Byte)是计量单位，表示数据量多少，是计算机信息技术用于计量存储容量的一种计量单位，通常情况下一字节等于八位。 字符(Character)计算机中使用的字母、数字、字和符号，比如’A’、’B’、’$’、’&amp;’等。 一般在英文状态下一个字母或字符占用一个字节，一个汉字用两个字节表示。 字节与字符： ASCII 码中，一个英文字母（不分大小写）为一个字节，一个中文汉字为两个字节。 UTF-8 编码中，一个英文字为一个字节，一个中文为三个字节。 Unicode 编码中，一个英文为一个字节，一个中文为两个字节。 符号：英文标点为一个字节，中文标点为两个字节。例如：英文句号 . 占1个字节的大小，中文句号 。占2个字节的大小。 UTF-16 编码中，一个英文字母字符或一个汉字字符存储都需要 2 个字节（Unicode 扩展区的一些汉字存储需要 4 个字节）。 UTF-32 编码中，世界上任何字符的存储都需要 4 个字节。 输出流默认覆盖写,文件不存在则创建文件 权限修饰符类1、外部类前可以修饰：public、default、abstract、final 对于顶级类(外部类)来说，只有两种修饰符：public和默认(default)。因为外部类的上一单元是包，所以外部类只有两个作用域：同包，任何位置。因此，只需要两种控制权限：包控制权限和公开访问权限，也就对应两种控制修饰符：public和默认(default)。可以满足所有的情况了。 如果类使用了private修饰符，说明是个内部类。内部类的上一级是外部类，那么对应的有四种访问控制修饰符：本类(private)，同包(default)，父子类(protected)，任何位置(public)。当一个内部类使用了private修饰后，只能在该类的外部类内部使用。 上面这些都是平时使用司空见惯的，但是为什么是这种情况呢？ 可以想一下，一个java项目是不可能在一个class里面完成的。mvc模式中，是把类分为三层，一层层调用类。如果定义为私有的和受保护的就无法调用。换句话说，对于一个java文件，要么就是自己单独运行，要么就是被其他程序作为库调用，如果一个java文件的类被private修饰，那么是不是其他的程序或是类是无法使用它的，那么他作为一个单独的文件就没啥用了。如果它作为单个文件运行，类加载怎么找到它呢，因为它对外不可见。同时，也失去了类的存在意义。 2、内部类前可以修饰：public、protected、default、private、abstract、final、static 3、局部(指方法 代码块等)内部类前可以修饰：abstract、final 成员变量1、 public ：对 所有用户 开放，所有用户都可直接调用2、 private ：私有。 除了class自己之外，任何人都不可直接使用 ，私有财产神圣不可侵犯嘛，即便是子女，朋友，都不可使用。 default 类内部 与 同包 ,即对于外包的类和子类朋友类相当于为私有不能访问 3、 protected ：对于子女、朋友来说，就是public的，可自由使用，无任何限制；而对于其他的外部class，protected就变成private。（ 同一个包中的类，若不在同一个包中，必须为其子孙类才可使用 ） 接口抽象类接口里的静态方法，即static修饰的有方法体的方法不会被继承或者实现，但是静态变量会被继承 接口中的static方法不能被继承，也不能被实现类调用，只能被自身调用 Guava入门guava就是类库，是java api的增强与扩展，里面有大量的方法供我们使用，使用之前需要引入包 &lt;!--guava依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;27.0.1&lt;/version&gt; &lt;/dependency&gt; guava有哪些方法呢？我们先从以下几方面开始学习： 字符串处理：分割，连接，填充新增的集合类型原生类型1.原生类型 定义list，map public void test() { &#x2F;&#x2F;JDK List list &#x3D; new ArrayList(); list.add(“a”); list.add(“b”); list.add(“c”); list.add(“d”); &#x2F;&#x2F;guava List lists &#x3D; Lists.newArrayList(“a”, “b”, “g”, null, “8”, “9”); List lists1 &#x3D; Lists.newArrayList(); Map&lt;Integer, String&gt; maps &#x3D; Maps.newHashMap();}guava就是类库，是java api的增强与扩展，里面有大量的方法供我们使用，使用之前需要引入包 &lt;!--guava依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;27.0.1&lt;/version&gt; &lt;/dependency&gt; guava有哪些方法呢？我们先从以下几方面开始学习： 字符串处理：分割，连接，填充新增的集合类型原生类型1.原生类型 定义list，map public void test() { &#x2F;&#x2F;JDK List list &#x3D; new ArrayList(); list.add(“a”); list.add(“b”); list.add(“c”); list.add(“d”); &#x2F;&#x2F;guava List lists &#x3D; Lists.newArrayList(“a”, “b”, “g”, null, “8”, “9”); List lists1 &#x3D; Lists.newArrayList(); Map&lt;Integer, String&gt; maps &#x3D; Maps.newHashMap();}2.新增集合（这里我只讲一下Mulitmap,平时用这个会使代码很方便，这里我就多讲一下） a Multimap的使用 Multimap就是将相同key的value值放在一个list里面，这样子取相同key下面的所有value值就非常简单了，不然还得for循环去匹配，把相同key值的value值找出来，在进行处理。map&lt;key,value&gt;键值key不能重复，所以当遇到这样子场景的时候map就非常不适合了，guava提供了Multimap适用于该场景。 当我们需要一个map中包含key为String类型，value为List类型的时候，以前我们是这样写的 &#x2F;&#x2F; jdk方式Map&lt;String,List&gt; map &#x3D; new HashMap&lt;String,List&gt;();List list &#x3D; new ArrayList();list.add(1);list.add(2);map.put(“aa”, list);System.out.println(map.get(“aa”));&#x2F;&#x2F;[1, 2] &#x2F;&#x2F; guava方式Multimap&lt;String,Integer&gt; map &#x3D; ArrayListMultimap.create();map.put(“aa”, 1);map.put(“aa”, 2);System.out.println(map.get(“aa”)); &#x2F;&#x2F;[1, 2] Multimap.get(key)即使没有key值，会返回空的list。 Multimap.keySet()返回的用set表示的不重复key; Multimap.keys()返回的是用Multiset表示的key,key数量跟value值数量一致； Multimap.containKeys()是表示是否包含这个key; Multimap.size()返回所有值的个数，而非不同键的个数。要得到不同键的个数，要用Multimap.keySet().size() 想要更多了解Multimap可以参考 https://www.jianshu.com/p/e0537d878b6c 3.字符串的处理：分割，连接，填充 a. joiner 连接器 joiner on就是将list用，连接转成字符串 @Test public void joinerListTest() { List lists &#x3D; Lists.newArrayList(“a”,”b”,”g”,”8”,”9”); String result &#x3D; Joiner.on(“,”).join(lists); System.out.println(result); } 结果：a,b,g,8,9joiner skipNulls()连接跳过null元素(第一个test为了跟第二个进行比对一下) @Test public void joinerListTest1() { List lists &#x3D; Lists.newArrayList(“a”,”b”,”g”,null,”8”,”9”); String result &#x3D; Joiner.on(“,”).join(lists); System.out.println(result); } 结果：a,b,g,null,8,9 @Testpublic void joinerListTest2() { List lists &#x3D; Lists.newArrayList(“a”,”b,”g”,null,”8”,”9”); String result &#x3D; Joiner.on(“,”).skipNulls().join(lists); System.out.println(result);}结果：a,b,g,8,9 如果连接的时候list里面含有null值，会报空指针，因为join实现如下： public final String join(Iterable&lt;?&gt; parts) { return this.join(parts.iterator()); } public final String join(Iterator&lt;?&gt; parts) { return this.appendTo(new StringBuilder(), parts).toString(); } @CanIgnoreReturnValue public final StringBuilder appendTo(StringBuilder builder, Iterator&lt;?&gt; parts) { try { this.appendTo((Appendable)builder, (Iterator)parts); return builder; } catch (IOException var4) { throw new AssertionError(var4); } } @CanIgnoreReturnValue public A appendTo(A appendable, Iterator&lt;?&gt; parts) throws IOException { Preconditions.checkNotNull(appendable); if (parts.hasNext()) { appendable.append(this.toString(parts.next())); while(parts.hasNext()) { appendable.append(this.separator); appendable.append(this.toString(parts.next())); } } return appendable; } @CanIgnoreReturnValue public static T checkNotNull(T reference) { if (reference &#x3D;&#x3D; null) { throw new NullPointerException(); } else { return reference; } } joiner useForNull(final String value)用value替换null元素值 @Test public void useNullListTest() { List lists &#x3D; Lists.newArrayList(“a”, “b”, “g”, null, “8”, “9”); String result &#x3D; Joiner.on(“,”).useForNull(“哈哈”).join(lists); System.out.println(result); } 结果：a,b,g,哈哈,8,9 joiner withKeyValueSeparator(String value) map连接器，keyValueSeparator为key和value之间的分隔符 @Test public void withMapTest() { Map&lt;Integer, String&gt; maps &#x3D; Maps.newHashMap(); maps.put(1, “哈哈”); maps.put(2, “压压”); String result &#x3D; Joiner.on(“,”).withKeyValueSeparator(“:”).join(maps); System.out.println(result); System.out.println(maps); } 结果：1:哈哈,2:压压{1&#x3D;哈哈, 2&#x3D;压压} b. splitter 拆分器 splitter on 拆分 @Test public void splitterListTest() { String test &#x3D; “34344,34,34,哈哈”; List lists &#x3D; Splitter.on(“,”).splitToList(test); System.out.println(lists); } 结果：[34344, 34, 34, 哈哈] splitter trimResults 拆分去除前后空格 @Test public void trimResultListTest() { String test &#x3D; “ 34344,34,34,哈哈 “; List lists &#x3D; Splitter.on(“,”).trimResults().splitToList(test); System.out.println(lists); } 结果：[34344, 34, 34, 哈哈]splitter omitEmptyStrings 去除拆分出来空的字符串 @Test public void omitEmptyStringsTest() { String test &#x3D; “ 3434,434,34,,哈哈 “; List lists &#x3D; Splitter.on(“,”).omitEmptyStrings().splitToList(test); System.out.println(lists); } 结果：[ 3434, 434, 34, 哈哈 ]splitter fixedLength(int lenght) 把字符串按固定长度分割 @Test public void fixedLengthTest() { String test &#x3D; “343443434哈哈”; List lists &#x3D; Splitter.fixedLength(3).splitToList(test); System.out.println(lists); } 结果：[343, 443, 434, 哈哈] b. charMatcher 匹配器 charMatcher is(Char char) 给单一字符匹配 @Test public void isTest() { String str &#x3D; “12312,agg”; CharMatcher charMatcher1 &#x3D; CharMatcher.is(‘g’); System.out.println(charMatcher1.retainFrom(str)); } 结果：ggcharMatcher retainFrom(String s) 在字符序列中保留匹配字符，移除其他字符 @Test public void charMatcherTest() { String str &#x3D; “12312,agg “; &#x2F;&#x2F;两个匹配符,先匹配再操作 CharMatcher charMatcher1 &#x3D; CharMatcher.is(‘1’); CharMatcher charMatcher2 &#x3D; CharMatcher.is(‘2’); &#x2F;&#x2F;两个CharMatcher或操作 CharMatcher charMatcher3 &#x3D; charMatcher1.or(charMatcher2); System.out.println(charMatcher3.retainFrom(str)); } 结果：1212charMatcher matchersAllOf(Char char) 测试是否字符序列所有字符都匹配 @Test public void matchesAllOfTest() { String str &#x3D; “12312,agg”; CharMatcher charMatcher1 &#x3D; CharMatcher.is(‘g’); System.out.println(charMatcher1.matchesAllOf(str)); } 结果：false@Test public void matchesAllOfTest() { String str &#x3D; “ggggg”; CharMatcher charMatcher1 &#x3D; CharMatcher.is(‘g’); System.out.println(charMatcher1.matchesAllOf(str)); } 结果：true arr与list转换前言123456int[] ints = &#123;2, 34, 55, 22, 11&#125;; long[] longs = &#123;1, 2, 3&#125;; double[] doubles = &#123;1, 2, 3&#125;; Arrays.stream(ints).boxed().collect(Collectors.toList()); Arrays.stream(longs).boxed().collect(Collectors.toList()); Arrays.stream(doubles).boxed().collect(Collectors.toList()); 直接for,add就完事了反之同理 java数组转list误区一、不能把基本数据类型转化为列表仔细观察可以发现asList接受的参数是一个泛型的变长参数，而基本数据类型是无法泛型化的，如下所示： 123456789101112public class App &#123; public static void main(String[] args) &#123; int [] intarray = &#123; 1 , 2 , 3 , 4 , 5 &#125;; //List&lt;Integer&gt; list = Arrays.asList(intarray); 编译通不过 List&lt; int []&gt; list = Arrays.asList(intarray); System.out.println(list); &#125;&#125;output：[[I @66d3c617 ]1234567891011 这是因为把int类型的数组当参数了，所以转换后的列表就只包含一个int[]元素。解决方案：要想把基本数据类型的数组转化为其包装类型的list，可以使用guava类库的工具方法，示例如下： 12int [] intArray = &#123; 1 , 2 , 3 , 4 &#125;;List&lt;Integer&gt; list = Ints.asList(intArray); 第一种方式(未必最佳):使用ArrayList.asList(strArray)使用Arrays工具类Arrays.asList(strArray)方式,转换完成后,只能对List数组进行查改,不能增删,增删就会抛出UnsupportedOperationException 异常 12345678910import java.util.Arrays;import java.util.List; public static void Demo1() &#123; String[] str = &#123;&quot;fgx&quot;, &quot;lzy&quot;&#125;; //注意这个List不是Collections包内的List,而是util包里面的List接口 List&lt;String&gt; ints = Arrays.asList(str); //这里会报错 ints.add(&quot;laopo&quot;); &#125;123456789 添加数据报错: 1234567891011Exception in thread &quot;main&quot; java.lang.UnsupportedOperationExceptionat java.util.AbstractList.add(AbstractList.java:148)at java.util.AbstractList.add(AbstractList.java:108)at JAVA基础.JDK8新特性.Java数组转List.Demo1(Java数组转List.java:20)at JAVA基础.JDK8新特性.Java数组转List.main(Java数组转List.java:13)报错原因:Arrays.asList(str)返回值是java.util.Arrays类中一个私有静态内部类 java.utiil.Arrays.Arraylist,并不是我们平时用的java.util.ArrayList();使用场景:Arrays.asList(strArray)方式仅能用在将数组转换为List后，不需要增删其中的值，仅作为数据源读取使用。12345678910 第二种方法(支持增删查改):通过ArrayList的构造器,将Arrays.asList(strArray)的返回值由java.utilArrays.ArrayList转为java.util.ArrayList.关键代码：ArrayList list &#x3D; new ArrayList(Arrays.asList(strArray)) ; 1234567 String[] str = &#123;&quot;fgx&quot;, &quot;lzy&quot;&#125;; //注意这个List不是Collections包内的List,而是util包里面的List接口 java.util.ArrayList&lt;String&gt; strings = new ArrayList&lt;&gt;(Arrays.asList(str)); strings.add(&quot;aop&quot;); strings.stream().forEach(System.out::println);123456 使用场景:需要在将数组转换为List后，对List进行增删改查操作，在List的数据量不大的情况下，可以使用。 第三种方式(通过集合工具类Collections.addAll()方法(最高效))通过Collections.addAll(arrayList, strArray)方式转换，根据数组的长度创建一个长度相同的List，然后通过Collections.addAll()方法，将数组中的元素转为二进制，然后添加到List中，这是最高效的方法。 123456public static void Demo3() &#123; //注意这个List不是Collections包内的List,而是util包里面的List接口 String[] str = &#123;&quot;fgx&quot;, &quot;lzy&quot;&#125;; java.util.ArrayList&lt;String&gt; stringList = new ArrayList&lt;&gt;(str.length); Collections.addAll(stringList,str); &#125; 第四种方式通过JDK8的Stream流将3总基本类型数组转为List如果JDK版本在1.8以上,使用流stream来将下列3种数组快速转为List,分别是int[],long[],double[],不支持short[ ],byte[ ],char[]在JDK1.8中暂不支持. 1234567 int[] ints = &#123;2, 34, 55, 22, 11&#125;; long[] longs = &#123;1, 2, 3&#125;; double[] doubles = &#123;1, 2, 3&#125;; Arrays.stream(ints).boxed().collect(Collectors.toList()); Arrays.stream(longs).boxed().collect(Collectors.toList()); Arrays.stream(doubles).boxed().collect(Collectors.toList());123456 TIPs:为什么int[]不能直接转为List,而Integer[]可以转为List,而Integer[]就可以转为List了,因为List中的泛型必须是引用类型。 java数组转list误区一、不能把基本数据类型转化为列表仔细观察可以发现asList接受的参数是一个泛型的变长参数，而基本数据类型是无法泛型化的，如下所示： 123456789101112public class App &#123; public static void main(String[] args) &#123; int [] intarray = &#123; 1 , 2 , 3 , 4 , 5 &#125;; //List&lt;Integer&gt; list = Arrays.asList(intarray); 编译通不过 List&lt; int []&gt; list = Arrays.asList(intarray); System.out.println(list); &#125;&#125;output：[[I @66d3c617 ]1234567891011 这是因为把int类型的数组当参数了，所以转换后的列表就只包含一个int[]元素。解决方案：要想把基本数据类型的数组转化为其包装类型的list，可以使用guava类库的工具方法，示例如下： 123int [] intArray = &#123; 1 , 2 , 3 , 4 &#125;;List&lt;Integer&gt; list = Ints.asList(intArray);12 二、asList方法返回的是数组的一个视图视图意味着，对这个list的操作都会反映在原数组上，而且这个list是定长的，不支持add、remove等改变长度的方法。 12345678910111213141516public class App &#123; public static void main(String[] args) &#123; int [] intArray = &#123; 1 , 2 , 3 , 4 &#125;; List&lt;Integer&gt; list = Ints.asList(intArray); list.set( 0 , 100 ); System.out.println(Arrays.toString(intArray)); list.add( 5 ); list.remove( 0 ); &#125;&#125;output：[ 100 , 2 , 3 , 4 ]UnsupportedOperationExceptionUnsupportedOperationException 类与对象 依赖 use-a 聚合 has-a 继承 is-a 1.域变量与局部变量域变量会初始化为自动默认值,如果不明确初始化会影响代码的可读性 局部变量不会自动初始化为null 123456789101112131415class Employee &#123; public String name; ...&#125;Emplpyee[] staff = new Employee[3];// 省略不同的名字初始化// 如果需要返回一个可变数据域的拷贝,应该使用cloneEmployee boss = new Employee();System.out.println(boss.name); // nullpublic boolean equals(Employee other) &#123; //访问 int a; System.out.println(a);//报错 在使用时a未被初始化 当然如果不使用a就不会报错 &#125; 首先方法可以访问所调用对象的私有数据(平常使用显而易见). 然后让人奇怪的是一个方法可以访问所属类的所有对象的私有数据 1234567891011121314151617181920212223class Employee &#123; private String name;// ... Employee (String name) &#123; this.name = name; &#125; public boolean equals(Employee other) &#123; //访问 return name.equals(other.name); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Employee boss = new Employee(&quot;boss&quot;); Employee harry = new Employee(&quot;harry&quot;);// System.out.println(boss.name); // 编译器报错 if (boss.equals(harry)) &#123; System.out.println(&quot;Employee的方法可以访问Employee类任何一个对象的私有域&quot;); &#125; &#125;&#125; private 方法内部使用,想删就删(不会被外部使用) final实例域 必须确保在每个构造器执行后这个域的值被设置 123456789101112class Employee &#123; public final String name;//编译器报错 //如果去掉无参构造器则不报错 Employee () &#123; &#125; Employee (String name) &#123; this.name = name; this.name = &quot;不能改&quot;;// 报错: name&#x27; might already have been assigned(分配) to,因为涉及更改引用 &#125;&#125; final关键字只是表示不会在指向别的地方,对象本身可以更改 静态方法不需要构建对象就可以调用 静态代码(只有在装载类的时候被执行) 12345678910111213141516171819202122232425class A &#123; static &#123; System.out.println(&quot;1&quot;); &#125; A() &#123; System.out.println(&quot;a&quot;); &#125;&#125;class B extends A &#123; static &#123; System.out.println(&quot;2&quot;); &#125; B() &#123; System.out.println(&quot;b&quot;); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; B b = new B(); A a = new A(); // 12aba &#125;&#125; 每一个类都可以有一个main方法 方法可以改变一个对象参数的状态,但不能整体改变(用x指向别的)因为是局部变量只是改变局部变量的值 真正的引用未被改变 12345678910//伪代码A a(a),b(b)swap(a,b);swap(x,y) &#123; A temp = x; x = y; y = x; &#125;// 如果是传应用sout(a,b) 输出 b,a但是并没有奏效输出还是a,b 重载方法同名不同参数 继承覆盖方法子类覆盖父类:方法签名覆盖 方法名与参数列表完全一致 区分重载: super不是一个对象的引用,不能将super赋给另一个对象变量,它只是一个指示编译器调用超类方法的特殊关键字 方法调用方法名+参数列表称为方法签名 动态绑定 C x &#x3D; new B(); x.f(args) 获取父类public且对应名称的方法和声明类的对应名称方法 找一个参数类型完全匹配的方法(这个过程称为重载解析) 有可能类型转换 没找到就会报错 实际调用会调用x的真正类型的方法,虚拟机预先为每个类有一个方法表 作用: 无需对现存代码修改,就可以对程序扩展 静态绑定: private,static,final或者构造器等编译器可以准确的知道应该调用哪个方法,所以称为静态绑定 修饰类final类 为不允许扩展的的类,所有方法自动成为final,不包括域,确保它们不会在子类改变语义 如果一个方法没有被覆盖并且很短就可被优化为内联 例如: e.getNname 将被替换为访问e.name域 详见:Java核心卷10 强制类型转换允许子类引用赋值给父类反之必须类型转换才能通过运行时检查 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Employee &#123; public String name; // ... Employee () &#123; &#125; Employee (String name) &#123; this.name = name; &#125; public boolean equals(Employee other) &#123; //访问 return name.equals(other.name); &#125; public void work() &#123; System.out.println(&quot;员工共有之work&quot;+name); &#125;&#125;class Manager extends Employee&#123; Manager (String name) &#123; super(name); &#125; public void manage() &#123; System.out.println(&quot;经理独有之manage&quot;+name); &#125; //每个经理是一个员工&#125;public class Main &#123; public static void main(String[] args) &#123; double x = 3.405; int nx = (int) x; Manager a = new Manager(&quot;a&quot;); Employee[] staff = new Employee[3];// Employee b = new Employee(&quot;b&quot;);// Manager c = (Manager)b;// c.manage(); 这三行会报 ClassCastException //改进: Employee b = new Employee(&quot;b&quot;); Manager c; // 局部变量未使用不会报错 if (b instanceof Manager) &#123; c = (Manager) b; &#125; staff[0] = a;// 转化为E 实际为M// staff[0].manage();//报错 a = (Manager)staff[0];// 将父类强转为子类 唯一原因是:暂时忽视对象的?后,使用对象的全部功能 a.manage(); // 正常调用 &#125;&#125; 总结:父类转换为子类之前要使用instanceof,并且只能在继承层次内进行类型转换 抽象类 含有抽象方法(不需要实现的方法)的必须是抽象类 不含有抽象方法也可以声明为抽象类,只是不能被实例化 可以包含具体数据与方法 Object**hashCode()**每个对象都有,其值为对象的存储地址 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; String s = &quot;ok&quot;; StringBuilder sb = new StringBuilder(s); System.out.println(s.hashCode() + &quot; &quot;+sb.hashCode()); String t = new String(&quot;ok&quot;); StringBuilder tb = new StringBuilder(t); System.out.println(t.hashCode() + &quot; &quot;+tb.hashCode()); &#125;&#125; 3548 4601419583548 1163157884 String 的hashcode()是内容导向的 如果equals为true那么hashcode也要一致 为什么重写equals方法就必须重写hashCode方法？ 在散列表中，1、如果两个对象相等，那么它们的hashCode()值一定要相同； 这里的相等是指，通过equals()比较两个对象 时返回true 2、如果两个对象hashCode()相等，它们并不一定相等。(不相等时就是哈希冲突) 注意：这是在散列表中的情况。在非散列表中一定如此！ 考虑只重写equals而不重写 hashcode 时，虽然两个属性值完全相同的对象通过equals方法判断为true，但是当把这两个对象加入到 HashSet 时。会发现HashSet中有重复元素，这就是因为HashSet 使用 hashcode 判断对象是否已存在时造成了歧义，结果会导 致HashSet 的不正常运行。所以重写 equals 方法必须重写 hashcode 方法。 map的put 拿到hashcode()进行散列定槽 如果槽为空直接加入 如果槽不为空(判断key是否相等(key不能重复),)如果key相同直接覆盖 value ,否则解决哈希冲突 还是从set角度说重写hashCode enum关键字接口、lambda表达式与内部类 接口,lambda 内部类机制,内部类中的方法可以访问外部的域 代理 1234567891011121314151617181920public class Main &#123; A a; public static void main(String[] args) &#123; Main main = new Main(); &#125; public interface Iinterface &#123; // 内部接口默认为static的 void print(); &#125; protected class A implements Iinterface &#123; @Override public void print() &#123; System.out.println(&quot;内部接口可被private,protectd static(默认static) public, 修饰&quot;); System.out.println(&quot;外部类(接口)权限修饰符只能是public 或者不写&quot;); System.out.println(&quot;外部类可被final修饰(接口不行),不能被继承,不能static修饰&quot;); &#125; &#125;&#125; 接口1234public interface Comparable&lt;T&gt; &#123; int compareTo(T other);&#125;// 接口方法自动的是public,实现类必须写好 类泛型 写在类名之后&lt;&gt; 可以用在类内部域,方法参数,方法返回值,方法参数,局部变量等所有能声明的: 从结果来说可以理解为限定了一个限定符 等指定之后在进行替换不指定则为null,当第一次被确定时就被确定了比如set,在使用时都进行泛型指定在实现Comparable接口的类中必须提供下列方法int compareTo(Employee other )可用instanceof 检查对象是否实现了某个特定的接口,instancof限定上限 默认方法可以为接口提供默认实现 123456789101112131415161718192021222324interface Comparable&lt;T&gt; &#123; default int compareTo(Tother) &#123;return 0&#125;;// 可以不用实现但既然 //用处并不大,每一个实际实现都要覆盖这个方法(逻辑覆盖并不是一定要实现),不过有些情况默认方法可能很有用 // 重要用法: 接口演化&#125;interface DeInterface &#123; int size(); default boolean isEmpty() &#123; return size() == 0; &#125;&#125;public class Main implements DeInterface&#123; //不用实现默认方法 public static void main(String[] args) &#123; &#125; @Override public int size() &#123; return 0; &#125;&#125; 异常、断言和日志简述: 程序运行过程发生错误就会”抛出异常”,抛出异常比终止程序灵活,因为可以提供一个”捕获”异常的处理器(handler)对异常情况进行处理,如果没有提供处理器程序就会终止,并在控制台打印信息 异常有两种类型,未检查异常和已检查异常 对于已检查异常,编译器会检查是否提供处理器,(提示要添加异常处理的都是已检查异常) 常见的如空指针都属于未检查异常,编译器不会查看,因为应该精心编写代码来避免这些错误 1234try&#123;&#125; catch &#123; handler action&#125; 异常层次 Error（错误）Error 类及其子类：程序中无法处理的错误，表示运行应用程序中出现了严重的错误。 此类错误一般表示代码运行时 JVM 出现问题。通常有 Virtual MachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如 OutOfMemoryError：内存不足错误；StackOverflowError：栈溢出错误。此类错误发生时，JVM 将终止线程。 这些错误是不受检异常，非代码性错误。因此，当此类错误发生时，应用程序不应该去处理此类错误。按照Java惯例，我们是不应该实现任何新的Error子类的！ Exception（异常）程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。 运行时异常 未检查异常 都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。 运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。 非运行时异常 （编译异常必须从语法角度进行处理） 已检查异常 是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。 应用 应该寻找更加适当的子类或创建自己的异常类","categories":[{"name":"java","slug":"java","permalink":"https://gouguoqiang.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gouguoqiang.github.io/tags/java/"}]},{"title":"mysql","slug":"mysql/mysql","date":"2022-10-08T10:49:25.000Z","updated":"2022-10-09T13:54:28.467Z","comments":true,"path":"2022/10/08/mysql/mysql/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/08/mysql/mysql/","excerpt":"","text":"创建数据库语法12345678910CREATE DATABASE [IF NOT EXISTS] &lt;数据库名&gt;[[DEFAULT] CHARACTER SET &lt;字符集名&gt;] [[DEFAULT] COLLATE &lt;校对规则名&gt;];说明：（1）[]中的内容是可选的。（2）&lt;数据库名&gt;：要创建数据库的名称。（3）IF NOT EXISTS：只有该数据库不存在时才能执行创建操作，可以避免因为数据库已经存在而引起错误。（4）[DEFAULT] CHARACTER SET：指定数据库的默认字符集。字符集是用来定义 MySQL 存储字符串的方式。该选项可以省略，如果省略就采用配置文件中指定的字符集。MySQL 不允许在同一个系统中创建两个相同名称的数据库。（5）[DEFAULT] COLLATE：指定字符集的默认校对规则。校对规则用来定义比较字符串的方式，以解决排序和字符分组的问题。该选项可以省略，如果省略就采用配置文件中指定的校对规则。 1、查看MySQL默认的字符集和校对规则12345678910111213141516171819202122232425mysql&gt; show variables like &#x27;%char%&#x27;; --查看系统默认的字符集+--------------------------+--------------------------------------+| Variable_name | Value |+--------------------------+--------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8mb4 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8mb4 || character_set_system | utf8 || character_sets_dir | /usr/local/mysql-5.7/share/charsets/ |+--------------------------+--------------------------------------+8 rows in set (0.26 sec)mysql&gt; show variables like &#x27;%COLL%&#x27;; --查看系统默认的校对规则+----------------------+--------------------+| Variable_name | Value |+----------------------+--------------------+| collation_connection | utf8_general_ci || collation_database | utf8mb4_general_ci || collation_server | utf8mb4_general_ci |+----------------------+--------------------+3 rows in set (0.03 sec) 修改数据库主要是修改字符集和校对规则 1alter database mydb character set gbk collate gbk_chinese_ci; 删除数据库1drop database 数据库名; 创建数据表(table)语法12345678910111213141516171819202122232425262728293031create [temporary] table [if not exists] &lt;表名&gt; ([列定义选项])[表选项][分区选项];[列定义选项]的格式为： &lt;列名1&gt; &lt;类型&gt; &lt;数据完整性约束&gt; [, &lt;列名2&gt; &lt;类型&gt; &lt;数据完整性约束&gt; [, ... [&lt;列名n&gt; &lt;类型n&gt;]]]&lt;数据完整性约束&gt;的格式： [NOT NULL | NULL] --非空约束 [DEFAULT default_value] --默认值 [AUTO_INCREMENT] --定义为自增列（类型必须是整型） [PRIMARY KEY] --主键 [[unique] index] --索引，唯一索引 [foreign KEY(column_name) REFERENCES table_name(column_name))] --定义外键 [COMMENT &#x27;string&#x27;] --为字段添加注释 [表选项]的格式为： ENGINE = engine_name（存储引擎的名称） --指定存储引擎 --常用的存储引擎有 InnoDB 和 MyISAM AUTO_INCREMENT = value --设置自增字段的起始值 [DEFAULT] CHARACTER SET charset_name（字符集名称） --设置字符集 [COLLATE collation_name（校对集名称）] --设置校对集 COMMENT = &#x27;string&#x27; --表注释--参数说明：（1）temporary：表示创建连时表。只有在当前连接情况下，TEMPORARY表才是可见的。当连接关闭时，TEMPORARY表被自动取消。这意味着两个不同的连接可以使用相同的临时表名称，同时两个临时表不会互相冲突，也不与原有的同名的非临时表冲突。（2）IF NOT EXISTS：如果加了该选项，只有在要创建的表不存在的情况下，才创建该表。如果要创建的表已经存在，则不执行 create table 命令。（3）表名：如果只指定表名，则把表创建到当前数据库中，可以使用【db_name.table_name】格式指定表名，则把表创建到指定的数据库中。 举例(1) 创建t01 1create table hist.t01(id int,name char(20)); (2) 包含主键 1234567create table if not exists hist.dept ( dept_id int primary key comment &#x27;部门编号&#x27;, dept_name char(20) not null comment &#x27;部门名称&#x27; ) comment &#x27;部门表&#x27;; （3）创建 emp 表，包含自增字段（从1001开始），通过外键和 dept 表关联 1234567891011121314151617181920212223242526272829mysql&gt; create table if not exists emp ( emp_id int auto_increment primary key comment &#x27;员工编号&#x27;, emp_name char(20) not null comment &#x27;员工姓名&#x27;, birth datetime comment &#x27;出生日期&#x27;, phone char(20) comment &#x27;员工表&#x27;, dept_id int, foreign key(dept_id) references dept(dept_id) ) comment &#x27;员工表&#x27; auto_increment=1001 default character set utf8 collate utf8_general_ci engine=InnoDB;Query OK, 0 rows affected (0.04 sec)mysql&gt; show create table emp\\G*************************** 1. row *************************** Table: empCreate Table: CREATE TABLE `emp` ( `emp_id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;员工编号&#x27;, `emp_name` char(20) NOT NULL COMMENT &#x27;员工姓名&#x27;, `birth` datetime DEFAULT NULL COMMENT &#x27;出生日期&#x27;, `phone` char(20) DEFAULT NULL COMMENT &#x27;员工表&#x27;, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`emp_id`), KEY `dept_id` (`dept_id`), CONSTRAINT `emp_ibfk_1` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`dept_id`)) ENGINE=InnoDB AUTO_INCREMENT=1001 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工表&#x27;1 row in set (0.00 sec) （4）创建 stu 表，包含默认值，索引 12345678910111213141516171819202122232425262728293031323334353637383940mysql&gt; create table if not exists stu( s_no int auto_increment primary key, s_name char(20) not null, birth datetime, phone char(11), addr char(100), index(s_name), unique index(phone), index(birth,s_name) );Query OK, 0 rows affected (0.04 sec)mysql&gt; desc stu;+--------+-----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+-----------+------+-----+---------+----------------+| s_no | int(11) | NO | PRI | NULL | auto_increment || s_name | char(20) | NO | MUL | NULL | || birth | datetime | YES | MUL | NULL | || phone | char(11) | YES | UNI | NULL | || addr | char(100) | YES | | NULL | |+--------+-----------+------+-----+---------+----------------+5 rows in set (0.00 sec)mysql&gt; show create table stu\\G*************************** 1. row *************************** Table: stuCreate Table: CREATE TABLE `stu` ( `s_no` int(11) NOT NULL AUTO_INCREMENT, `s_name` char(20) NOT NULL, `birth` datetime DEFAULT NULL, `phone` char(11) DEFAULT NULL, `addr` char(100) DEFAULT NULL, PRIMARY KEY (`s_no`), UNIQUE KEY `phone` (`phone`), KEY `s_name` (`s_name`), KEY `birth` (`birth`,`s_name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 通过已有的表建新表12345create [temporary] table [if not exists] table_namelike old_tbale_name;--说明：使用该命令可以创建一个和原数据表结构完全相同的新表，但不会复制原数据表中的数据。 举例 12345678910111213141516171819202122232425262728293031mysql&gt; create table if not exists student like stu;Query OK, 0 rows affected (0.04 sec)mysql&gt; desc student;+--------+-----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+-----------+------+-----+---------+----------------+| s_no | int(11) | NO | PRI | NULL | auto_increment || s_name | char(20) | NO | MUL | NULL | || birth | datetime | YES | MUL | NULL | || phone | char(11) | YES | UNI | NULL | || addr | char(100) | YES | | NULL | |+--------+-----------+------+-----+---------+----------------+5 rows in set (0.01 sec)mysql&gt; show create table student\\G*************************** 1. row *************************** Table: studentCreate Table: CREATE TABLE `student` ( `s_no` int(11) NOT NULL AUTO_INCREMENT, `s_name` char(20) NOT NULL, `birth` datetime DEFAULT NULL, `phone` char(11) DEFAULT NULL, `addr` char(100) DEFAULT NULL, PRIMARY KEY (`s_no`), UNIQUE KEY `phone` (`phone`), KEY `s_name` (`s_name`), KEY `birth` (`birth`,`s_name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 使用 select 查询的结果集来创建表123456789create [temporary] table [if not exists] table_name [(create_definition,...)] [table_options] [partition_options] [ignore | replace] [as] query_expression --说明：使用此命令可以根据查询结果创建一张新表，并且把查询到的数据插入到新建的表中。 举例： （1）创建新表 stu1，表结构来源于对 stu 表的查询结果 123456789101112131415161718192021222324252627282930mysql&gt; create table if not exists stu1 as select * from stu;Query OK, 3 rows affected (0.04 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from stu;+------+--------+---------------------+-------------+----------+| s_no | s_name | birth | phone | addr |+------+--------+---------------------+-------------+----------+| 1 | Jack | 1999-01-23 00:00:00 | 13703735566 | Beijing || 2 | Mark | 1999-10-03 00:00:00 | 13783735566 | Beijing || 3 | Rose | 2000-11-21 00:00:00 | 13783735522 | Shanghai |+------+--------+---------------------+-------------+----------+3 rows in set (0.01 sec)mysql&gt; show create table stu1\\G*************************** 1. row *************************** Table: stu1Create Table: CREATE TABLE `stu1` ( `s_no` int(11) NOT NULL DEFAULT &#x27;0&#x27;, `s_name` char(20) NOT NULL, `birth` datetime DEFAULT NULL, `phone` char(11) DEFAULT NULL, `addr` char(100) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec)--新建的表包含了查询结果中的数据，但新建表的结构和原数据表的结构并不完全相同。 （2）创建新表 stu2，并且重新定义表结构 12345678910111213141516171819202122232425mysql&gt; create table if not exists stu2( s_no int auto_increment primary key, s_name char(30), phone char(11) ) engine=InnoDB character set utf8 collate utf8_general_ci as select s_no,s_name,phone from stu;Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; show create table stu2\\G*************************** 1. row *************************** Table: stu2Create Table: CREATE TABLE `stu2` ( `s_no` int(11) NOT NULL AUTO_INCREMENT, `s_name` char(30) DEFAULT NULL, `phone` char(11) DEFAULT NULL, PRIMARY KEY (`s_no`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf81 row in set (0.00 sec) 删除数据表123drop table 表名; 修改表结构12345678910mysql&gt; desc employee;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(10) | YES | | NULL | || addr | varchar(100) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+3 rows in set (0.00 sec)-- 以这个表为例 在 MySQL 中可以使用 ALTER TABLE 语句来改变原有数据表的结构。修改表结构涉及到的操作主要有：（1）增加和删除字段；（2）修改字段的数据类型；（3）修改字段名；（4）修改字段的排列位置；（5）添加和删除完整性约束；（6）修改表名；（7）更改表的存储引擎等。 12345678910ALTER TABLE &lt;表名&gt; [修改选项];[修改选项]的格式为：ADD COLUMN &lt;列名&gt; &lt;类型&gt;| CHANGE COLUMN &lt;旧列名&gt; &lt;新列名&gt; &lt;新列类型&gt;| ALTER COLUMN &lt;列名&gt; [ SET DEFAULT &lt;默认值&gt; | DROP DEFAULT ]| MODIFY COLUMN &lt;列名&gt; &lt;类型&gt;| DROP COLUMN &lt;列名&gt;| RENAME TO &lt;新表名&gt; 一、增加和删除字段1、增加字段1234ALTER TABLE &lt;表名&gt; ADD COLUMN &lt;列名&gt; &lt;类型&gt; &lt;完整性约束&gt; [FIRST | AFTER 列名];说明：使用 [FIRST | AFTER 列名] 选项可以设置新增字段的位置。 举例： （1）添加一个列 phone123456789101112131415mysql&gt; alter table employee add phone char(20);Query OK, 0 rows affected (0.17 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+-------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(10) | YES | | NULL | || addr | varchar(100) | YES | | NULL | || phone | char(20) | YES | | NULL | |+-------+--------------+------+-----+---------+-------+4 rows in set (0.00 sec) （2）添加一个列 salary，默认值为0，不能取空值12345678910111213141516 mysql&gt; alter table employee add salary decimal(10,2) default 0 not null;Query OK, 0 rows affected (0.11 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+--------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(10) | YES | | NULL | || addr | varchar(100) | YES | | NULL | || phone | char(20) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+--------+---------------+------+-----+---------+-------+5 rows in set (0.00 sec) （3）新增一个字段 birth，并放在 name 字段之后1234567891011121314151617mysql&gt; ALTER TABLE employee ADD COLUMN birth datetime after name;Query OK, 0 rows affected (0.08 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+--------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(10) | YES | | NULL | || birth | datetime | YES | | NULL | || addr | varchar(100) | YES | | NULL | || phone | char(20) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+--------+---------------+------+-----+---------+-------+6 rows in set (0.00 sec) 2、删除字段1ALTER TABLE &lt;表名&gt; DROP COLUMN &lt;列名&gt;; 12345678910111213141516mysql&gt; alter table employee drop column salary;Query OK, 0 rows affected (0.17 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+--------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(10) | YES | | NULL | || birth | datetime | YES | | NULL | || addr | varchar(100) | YES | | NULL | || phone | char(20) | YES | | NULL | |+--------+---------------+------+-----+---------+-------+6 rows in set (0.00 sec) 二、修改字段的数据类型、名称和字段的位置1、修改字段的数据类型修改字段的数据类型使用 MODIFY 选项。语法格式如下： 1234ALTER TABLE &lt;表名&gt; MODIFY COLUMN &lt;列名&gt; &lt;类型&gt;;说明：使用 MODIFY 选项不能更改字段的名称。 举例：把字段 name 的类型更为 varchar，长度为20 12345678910111213141516mysql&gt; alter table employee modify name varchar(20);Query OK, 2 rows affected (0.05 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+--------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | YES | | NULL | || birth | datetime | YES | | NULL | || addr | varchar(100) | YES | | NULL | || phone | char(20) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+--------+---------------+------+-----+---------+-------+6 rows in set (0.01 sec) 2、修改字段的名称修改字段的名称使用 CHANGE 选项。语法格式如下： 1234ALTER TABLE &lt;表名&gt; CHANGE COLUMN &lt;旧列名&gt; &lt;新列名&gt; &lt;新列类型&gt;;说明：使用 CHANGE 选项时，如果新列名和旧列名相同，则作用和 MODIFY 相同。 举例：把 addr 列的名称修改为 address，类型修改为 varchar(200)，放到字段 phone 之后 1234567891011121314151617mysql&gt; alter table employee change addr address varchar(200) after phone;Query OK, 0 rows affected (0.13 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+---------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | YES | | NULL | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || address | varchar(200) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+---------+---------------+------+-----+---------+-------+6 rows in set (0.00 sec) 3、更改字段的位置在使用 ADD 选项添加字段、使用 MODIFY 选项修改字段的类型和长度、使用 CHANGE 选项修改字段名称和类型时，可以使用 [FIRST | AFTER 列名] 选项 指定字段的位置。语法格式如下： 1234567--添加字段同时指定新增字段的位置ALTER TABLE &lt;表名&gt; ADD COLUMN &lt;列名&gt; &lt;类型&gt; &lt;完整性约束&gt; [FIRST | AFTER 列名]; --修改字段的类型和长度同时指定字段的位置ALTER TABLE &lt;表名&gt; MODIFY COLUMN &lt;列名&gt; &lt;类型&gt; [FIRST | AFTER 列名];--修改字段的名称、类型和长度同时指定字段的位置ALTER TABLE &lt;表名&gt; CHANGE COLUMN &lt;旧列名&gt; &lt;新列名&gt; &lt;新列类型&gt; [FIRST | AFTER 列名]; 举例： （1）添加一个字段 comm，类型为 varchar(500)，位置放在第一位 123456789101112131415161718mysql&gt; alter table employee add comm varchar(500) first;Query OK, 0 rows affected (0.09 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+---------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+---------------+------+-----+---------+-------+| comm | varchar(500) | YES | | NULL | || id | int(11) | NO | PRI | NULL | || name | varchar(20) | YES | | NULL | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || address | varchar(200) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+---------+---------------+------+-----+---------+-------+7 rows in set (0.01 sec) 2）把字段 comm 的长度修改为 1000，并放在字段 salary 之前 123456789101112131415161718mysql&gt; alter table employee modify comm varchar(1000) after address;Query OK, 0 rows affected (0.08 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+---------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | YES | | NULL | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || address | varchar(200) | YES | | NULL | || comm | varchar(1000) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | |+---------+---------------+------+-----+---------+-------+7 rows in set (0.01 sec) （3）把字段 comm 的名称修改为 comme，并放在表的结尾 123456789101112131415161718mysql&gt; alter table employee change comm comme varchar(1000) after salary;Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc employee;+---------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+---------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(20) | YES | | NULL | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || address | varchar(200) | YES | | NULL | || salary | decimal(10,2) | NO | | 0.00 | || comme | varchar(1000) | YES | | NULL | |+---------+---------------+------+-----+---------+-------+7 rows in set (0.00 sec) 三、修改表名语法格式如下： 12ALTER TABLE &lt;表名&gt; RENAME [TO] &lt;新表名&gt;; 举例：把数据表 employee 名称修改为 emp 123456789101112131415mysql&gt; alter table employee rename emp;Query OK, 0 rows affected (0.10 sec)mysql&gt; show tables;+-----------------+| Tables_in_hist |+-----------------+| dept || emp || stu || student || user_permission |+-----------------+5 rows in set (0.00 sec) 数据更新之INSERTMySQL 数据库和其它的关系型数据库一样，支持数据的增（插入：insert）、删（删除：delete）、改（更新：update）、查（查询：select）操作。 一、数据准备创建两张表：部门（dept）和员工（emp），表结构如下： 12345678910111213141516171819202122mysql&gt; desc dept;+-----------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------+----------+------+-----+---------+-------+| dept_id | int(11) | NO | PRI | NULL | || dept_name | char(20) | NO | | NULL | |+-----------+----------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; desc emp;+----------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+----------+------+-----+---------+----------------+| emp_id | int(11) | NO | PRI | NULL | auto_increment || emp_name | char(20) | NO | | NULL | || gender | char(2) | YES | | 男 | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || dept_id | int(11) | YES | MUL | NULL | |+----------+----------+------+-----+---------+----------------+6 rows in set (0.01 sec) 二、数据的插入操作插入数据使用 Insert 命令，Insert 命令有三种用法： 1、插入一条或多条数据记录语法如下： 123456789-- 下面的命令一次可以插入一条或多条数据记录INSERT [INTO] 表名 [(列名,...)] VALUES (&#123;表达式 | DEFAULT&#125;, ...), (...),...说明：（1）每条数据记录包含在一对括号中。（2）如果省略表名后面的列名，则 values 后面的数据必须和表中字段的数量与顺序对应。（3）使用 DEFAULT 可以把字段的默认值插入表中。（4）使用一条 INSERT 命令插入多条数据记录时，多条记录之间用逗号分开。 （1）用 insert 命令一次插入一条记录1234567891011121314151617181920212223242526272829303132333435363738394041mysql&gt; insert into dept values(11,&#x27;人事部&#x27;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into dept(dept_id,dept_name) values(12,&#x27;财务部&#x27;);Query OK, 1 row affected (0.02 sec)mysql&gt; select * from dept;+---------+-----------+| dept_id | dept_name |+---------+-----------+| 11 | 人事部 || 12 | 财务部 |+---------+-----------+2 rows in set (0.00 sec)mysql&gt; insert into emp(emp_name,gender,birth,phone,dept_id) values(&#x27;Jack&#x27;,default,&#x27;1995-2-3&#x27;,&#x27;15937321555&#x27;,11);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into emp values(1101,&#x27;Mark&#x27;,&#x27;男&#x27;,&#x27;1997-12-15&#x27;,&#x27;15903732155&#x27;,11);Query OK, 1 row affected (0.02 sec)mysql&gt; insert into emp(emp_name,gender,birth,phone,dept_id) values(&#x27;Jack&#x27;,&#x27;女&#x27;,null,&#x27;15937321666&#x27;,12);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into emp(emp_name,gender,dept_id) values(&#x27;Jack&#x27;,default,12);Query OK, 1 row affected (0.00 sec)mysql&gt; mysql&gt; select * from emp;+--------+----------+--------+---------------------+-------------+---------+| emp_id | emp_name | gender | birth | phone | dept_id |+--------+----------+--------+---------------------+-------------+---------+| 1 | Jack | 男 | 1995-02-03 00:00:00 | 15937321555 | 11 || 1101 | Mark | 男 | 1997-12-15 00:00:00 | 15903732155 | 11 || 1102 | Jack | 女 | NULL | 15937321666 | 12 || 1103 | Jack | 男 | NULL | NULL | 12 |+--------+----------+--------+---------------------+-------------+---------+4 rows in set (0.00 sec) （2）用 insert 命令一次插入多条记录12345678910111213141516mysql&gt; insert into dept values(13,&#x27;生产制造部&#x27;),(14,&#x27;销售部&#x27;),(15,&#x27;公关部&#x27;);Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from dept;+---------+-----------------+| dept_id | dept_name |+---------+-----------------+| 11 | 人事部 || 12 | 财务部 || 13 | 生产制造部 || 14 | 销售部 || 15 | 公关部 |+---------+-----------------+5 rows in set (0.00 sec) 2、使用 set 参数插入数据12345INSERT [INTO] 表名 SET col_name=&#123;表达式 | DEFAULT&#125;, ... 说明：使用这种形式的 INSERT 语句不能插入多行。 举例 : 12345678910111213141516mysql&gt; insert into dept set dept_id=16,dept_name=&#x27;信息部&#x27;;Query OK, 1 row affected (0.01 sec)mysql&gt; select * from dept;+---------+-----------------+| dept_id | dept_name |+---------+-----------------+| 11 | 人事部 || 12 | 财务部 || 13 | 生产制造部 || 14 | 销售部 || 15 | 公关部 || 16 | 信息部 |+---------+-----------------+6 rows in set (0.00 sec) 3、把一个查询的结果插入到数据表中格式如下： 12345INSERT [INTO] 表名 [(列名,...)] SELECT ... 说明：查询命令不能包含 ORDER BY子句，而且INSERT语句的目的表不能出现在查询命令的 FROM 子句中。 举例： （1）创建一张数据表表结构如下： 1234567891011121314151617mysql&gt; create table emp001 select emp_id,emp_name,phone from emp where 2=3;Query OK, 0 rows affected (0.04 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc emp001;+----------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+----------+------+-----+---------+-------+| emp_id | int(11) | NO | | 0 | || emp_name | char(20) | NO | | NULL | || phone | char(20) | YES | | NULL | |+----------+----------+------+-----+---------+-------+3 rows in set (0.00 sec)mysql&gt; select * from emp001;Empty set (0.00 sec) （2）从 emp 表中查询中男性员工的信息插入 emp001 表中1234567891011121314mysql&gt; insert into emp001 select emp_id,emp_name,phone from emp where gender=&#x27;男&#x27;;Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from emp001;+--------+----------+-------------+| emp_id | emp_name | phone |+--------+----------+-------------+| 1 | Jack | 15937321555 || 1101 | Mark | 15903732155 || 1103 | Jack | NULL |+--------+----------+-------------+3 rows in set (0.00 sec) 4、replace into 命令replace into 命令的格式与 insert into 命令基本相同。使用 insert into 命令插入数据时，如果主键重复，则插入失败，使用replace into 命令插入数据时，如果主键重复，则替换该行的所有数据，相当于将主键这条记录彻底删除，再插入新的记录。也就是说，将所有的字段都更新了。 语法如下： 123456REPLACE [INTO] 表名 [(列名, ...)] VALUES (expr, ...),(...),...REPLACE [INTO] 表名 [(列名, ...)] SELECT ... 举例：在 dept 表中插入一个新部门：技术部 12345678910111213141516171819202122232425262728293031mysql&gt; select * from dept;+---------+-----------------+| dept_id | dept_name |+---------+-----------------+| 11 | 人事部 || 12 | 财务部 || 13 | 生产制造部 || 14 | 销售部 || 15 | 公关部 || 16 | 信息部 |+---------+-----------------+6 rows in set (0.00 sec)mysql&gt; replace into dept values(16,&#x27;技术部&#x27;);Query OK, 2 rows affected (0.01 sec)mysql&gt; select * from dept;+---------+-----------------+| dept_id | dept_name |+---------+-----------------+| 11 | 人事部 || 12 | 财务部 || 13 | 生产制造部 || 14 | 销售部 || 15 | 公关部 || 16 | 技术部 |+---------+-----------------+6 rows in set (0.00 sec)-- 可以看到，当命令执行成功后，“信息部”被替换为了“技术部”。 数据更新之UPDATEMySQL 数据库和其它的关系型数据库一样，支持数据的增（插入：insert）、删（删除：delete）、改（更新：update）、查（查询：select）操作。 一、数据准备创建两张表：部门（dept）和员工（emp），表结构如下： 12345678910111213141516171819202122mysql&gt; desc dept;+-----------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------+----------+------+-----+---------+-------+| dept_id | int(11) | NO | PRI | NULL | || dept_name | char(20) | NO | | NULL | |+-----------+----------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; desc emp;+----------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+----------+------+-----+---------+----------------+| emp_id | int(11) | NO | PRI | NULL | auto_increment || emp_name | char(20) | NO | | NULL | || gender | char(2) | YES | | 男 | || birth | datetime | YES | | NULL | || phone | char(20) | YES | | NULL | || dept_id | int(11) | YES | MUL | NULL | |+----------+----------+------+-----+---------+----------------+6 rows in set (0.01 sec) 二、数据更新操作使用 UPDATE 命令可以对表中的数据进行更新，该命令有两种用法： 1、为表中的字段指定一个常量或表达式格式如下： 123456789UPDATE 表名 SET 列名 = 表达式 [, 列名 = 表达式 ...] [WHERE 条件] [ORDER BY ...] [LIMIT row_count]说明：（1） ORDER BY：按照指定的顺序对行进行更新。（2） LIMIT：限制可更新的行数。 举例： 12345678910111213141516171819202122232425262728293031mysql&gt; select * from emp;+--------+----------+--------+---------+-------------+---------+| emp_id | emp_name | gender | salary | phone | dept_id |+--------+----------+--------+---------+-------------+---------+| 1 | Jack | 男 | 4500.00 | 15937321555 | 11 || 1101 | Mark | 男 | 7100.00 | 15903732155 | 11 || 1102 | Rose | 女 | 6200.00 | 15937321666 | 12 || 1103 | Jerry | 男 | 3700.00 | NULL | 12 |+--------+----------+--------+---------+-------------+---------+4 rows in set (0.00 sec)mysql&gt; update emp set phone=&#x27;15537312999&#x27; where emp_id=1103;--更新1103员工的电话Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; update emp set salary=salary*1.05; --所有人工资增加 5%Query OK, 4 rows affected (0.04 sec)Rows matched: 4 Changed: 4 Warnings: 0mysql&gt; select * from emp;+--------+----------+--------+---------+-------------+---------+| emp_id | emp_name | gender | salary | phone | dept_id |+--------+----------+--------+---------+-------------+---------+| 1 | Jack | 男 | 4725.00 | 15937321555 | 11 || 1101 | Mark | 男 | 7455.00 | 15903732155 | 11 || 1102 | Rose | 女 | 6510.00 | 15937321666 | 12 || 1103 | Jerry | 男 | 3885.00 | 15537312999 | 12 |+--------+----------+--------+---------+-------------+---------+4 rows in set (0.00 sec) 2、利用另一个表中的数据更新当前表格式如下： 1234567UPDATE 表1 join 表2 on 表1.列名 = 表2.列名 SET 列名 = 表达式 [, 列名 = 表达式 ...] [WHERE 条件]说明：（1）利用 表2 中的数据更新 表1，要求两个表必须存在关联字段。（2）表1 和 表2 关联的条件为 表1.列名 = 表2.列名。 举例： （1）为 emp 表添加一个列 dept_name，并使用 dept 表的相关数据进行填充 1234567891011121314151617181920212223242526272829303132mysql&gt; alter table emp add dept_name char(20);Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from emp;+--------+----------+--------+---------+-------------+---------+-----------+| emp_id | emp_name | gender | salary | phone | dept_id | dept_name |+--------+----------+--------+---------+-------------+---------+-----------+| 1 | Jack | 男 | 4725.00 | 15937321555 | 11 | NULL || 1101 | Mark | 男 | 7455.00 | 15903732155 | 11 | NULL || 1102 | Rose | 女 | 6510.00 | 15937321666 | 12 | NULL || 1103 | Jerry | 男 | 3885.00 | 15537312999 | 12 | NULL |+--------+----------+--------+---------+-------------+---------+-----------+4 rows in set (0.00 sec)mysql&gt; update emp join dept on emp.dept_id = dept.dept_id -&gt; set emp.dept_name = dept.dept_name -&gt; where emp.dept_id = 11;Query OK, 2 rows affected (0.01 sec)Rows matched: 2 Changed: 2 Warnings: 0mysql&gt; mysql&gt; select * from emp;+--------+----------+--------+---------+-------------+---------+-----------+| emp_id | emp_name | gender | salary | phone | dept_id | dept_name |+--------+----------+--------+---------+-------------+---------+-----------+| 1 | Jack | 男 | 4725.00 | 15937321555 | 11 | 人事部 || 1101 | Mark | 男 | 7455.00 | 15903732155 | 11 | 人事部 || 1102 | Rose | 女 | 6510.00 | 15937321666 | 12 | NULL || 1103 | Jerry | 男 | 3885.00 | 15537312999 | 12 | NULL |+--------+----------+--------+---------+-------------+---------+-----------+ （2）有两个表 stu 和 certificate，使用 stu 表的 s_name 和 phone 列的数据更新 certificate 表。 1234567891011121314151617181920212223242526272829303132333435363738394041mysql&gt; select * from stu;+------+--------+---------------------+-------------+----------+| s_no | s_name | birth | phone | addr |+------+--------+---------------------+-------------+----------+| 1 | Jack | 1999-01-23 00:00:00 | 13703735566 | Beijing || 2 | Mark | 1999-10-03 00:00:00 | 13783735566 | Beijing || 3 | Rose | 2000-11-21 00:00:00 | 13783735522 | Shanghai || 4 | John | 2000-03-04 00:00:00 | 18503735214 | Xinxiang || 5 | Jerry | 2001-04-25 00:00:00 | 13303735266 | Xinxiang |+------+--------+---------------------+-------------+----------+5 rows in set (0.00 sec)mysql&gt; select * from certificate;+------+--------+-------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------+-----------------+| 1 | NULL | NULL | 英语四级 || 2 | NULL | NULL | 英语四级 || 3 | NULL | NULL | 英语六级 || 4 | NULL | NULL | 计算机二级 || 5 | NULL | NULL | 英语四级 |+------+--------+-------+-----------------+5 rows in set (0.00 sec)mysql&gt; update certificate c join stu s on c.s_no = s.s_no -&gt; set c.s_name = s.s_name, c.phone = s.phone;Query OK, 5 rows affected (0.01 sec)Rows matched: 5 Changed: 5 Warnings: 0mysql&gt; select * from certificate;+------+--------+-------------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------------+-----------------+| 1 | Jack | 13703735566 | 英语四级 || 2 | Mark | 13783735566 | 英语四级 || 3 | Rose | 13783735522 | 英语六级 || 4 | John | 18503735214 | 计算机二级 || 5 | Jerry | 13303735266 | 英语四级 |+------+--------+-------------+-----------------+5 rows in set (0.00 sec) 数据更新之DELETE一、使用 delete 命令删除表中的数据格式如下： 123456789DELETE FROM 表名 [WHERE 条件] [ORDER BY ...] [LIMIT row_count] 说明：（1） ORDER BY：按照指定的顺序对行删除操作。（2） LIMIT：限制可删除的行数。 举例： （1）从 certificate 表删除 phone 为 133 开头的记录 1234567891011121314151617181920212223242526mysql&gt; select * from certificate;+------+--------+-------------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------------+-----------------+| 1 | Jack | 13703735566 | 英语四级 || 2 | Mark | 13783735566 | 英语四级 || 3 | Rose | 13783735522 | 英语六级 || 4 | John | 18503735214 | 计算机二级 || 5 | Jerry | 13303735266 | 英语四级 |+------+--------+-------------+-----------------+5 rows in set (0.00 sec)mysql&gt; delete from certificate where phone like &#x27;133%&#x27;;Query OK, 1 row affected (0.02 sec)mysql&gt; select * from certificate;+------+--------+-------------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------------+-----------------+| 1 | Jack | 13703735566 | 英语四级 || 2 | Mark | 13783735566 | 英语四级 || 3 | Rose | 13783735522 | 英语六级 || 4 | John | 18503735214 | 计算机二级 |+------+--------+-------------+-----------------+4 rows in set (0.00 sec) （2）删除时限制删除的行数：从 certificate 表删除 phone 为 137 开头的记录，但一次最多删除两行。并且按学号降序的顺序删除。 12345678910111213141516171819202122232425mysql&gt; select * from certificate;+------+--------+-------------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------------+-----------------+| 1 | Jack | 13703735566 | 英语四级 || 2 | Mark | 13783735566 | 英语四级 || 3 | Rose | 13783735522 | 英语六级 || 4 | John | 18503735214 | 计算机二级 |+------+--------+-------------+-----------------+4 rows in set (0.00 sec)mysql&gt; delete from certificate where phone like &#x27;137%&#x27; -&gt; order by s_no desc -&gt; limit 2;Query OK, 2 rows affected (0.07 sec)mysql&gt; select * from certificate;+------+--------+-------------+-----------------+| s_no | s_name | phone | certificate |+------+--------+-------------+-----------------+| 1 | Jack | 13703735566 | 英语四级 || 4 | John | 18503735214 | 计算机二级 |+------+--------+-------------+-----------------+2 rows in set (0.01 sec) 二、使用 truncate 命令删除表中的数据使用 truncate 命令可以删除表中的所有数据，和不带条件的 delete 命令结果相同。两个命令的区别有两点：（1）delete 命令在删除时逐行判断和删除，效率较低；truncate 命令是直接删除表，然后重建表，因此删除的效率很高。（2）当表中有自增字段时，如果使用 delete 命令删除全部记录，当重新插入记录时，自增字段的值从删除之前的编号的最大值开始增加。如果使用 truncate 命令删除全部记录，重新插入记录时，自增字段的值将重新开始编号。 truncate 命令的语法如下： truncate [TABLE] 表名;1举例： （1）创建表 t1，id 为自增字段，初始值为 1，然后插入数据。根据 t1 表生成 t2，t2 表的结构和数据与 t1 表完全相同。 结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849mysql&gt; desc t1;+-------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | |+-------+----------+------+-----+---------+----------------+2 rows in set (0.00 sec)mysql&gt; select * from t1;+----+-------+| id | name |+----+-------+| 1 | zhang || 2 | wang || 3 | li || 4 | zhao || 5 | liu |+----+-------+5 rows in set (0.00 sec)mysql&gt; create table t2 like t1;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t2 select * from t1;Query OK, 5 rows affected (0.08 sec)Records: 5 Duplicates: 0 Warnings: 0mysql&gt; desc t2;+-------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | |+-------+----------+------+-----+---------+----------------+2 rows in set (0.00 sec)mysql&gt; select * from t2;+----+-------+| id | name |+----+-------+| 1 | zhang || 2 | wang || 3 | li || 4 | zhao || 5 | liu |+----+-------+5 rows in set (0.00 sec) （2）使用 delete 命令删除 t1 表中的所有数据，然后插入新记录 可以看到，新插入的记录 id 从 6 开始编号。 1234567891011121314151617mysql&gt; delete from t1;Query OK, 5 rows affected (0.02 sec)mysql&gt; insert into t1(name) values(&#x27;Tom&#x27;),(&#x27;Jack&#x27;),(&#x27;Jerry&#x27;);Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from t1;+----+-------+| id | name |+----+-------+| 6 | Tom || 7 | Jack || 8 | Jerry |+----+-------+3 rows in set (0.00 sec) （3）使用 truncate 命令删除 t2 表中的所有数据，然后插入新记录 可以看到，新插入的记录 id 从 1 重新开始编号。 1234567891011121314151617mysql&gt; truncate table t2;Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into t2(name) values(&#x27;Tom&#x27;),(&#x27;Jack&#x27;),(&#x27;Jerry&#x27;);Query OK, 3 rows affected (0.03 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from t2;+----+-------+| id | name |+----+-------+| 1 | Tom || 2 | Jack || 3 | Jerry |+----+-------+3 rows in set (0.00 sec) 完整性约束概述数据完整性是指数据的正确性和相容性，是为了防止数据库中存在不符合语义的数据，即防止数据库中存在不正确的数据。在MySQL中提供了多种完整性约束。完整性约束根据约束的规则不同可分为三类： （1）实体完整性：可以保证数据的唯一性。可以使用主键约束与唯一性约束来定义。（2）参照完整性：一个表中某个字段的取值要参照另一个表的主键。使用外键约束来定义。（3）域完整性：又称为用户自定义完整性。可以针对某个列的取值由用户定义约束的规则。 MySQL中的完整性约束如下表所示： 完整性约束 说明PRIMARY KEY 主键约束（实体完整性）UNIQUE 唯一性约束（实体完整性）FOREIGN KEY 外键约束（参照完整性）NOT NULL 非空约束（域完整性）AUTO_INCREMENT 自增字段DEFAULT 默认值 一、主键约束主键是表中的某一个或多个列，由多个列组合而成的主键也称为复合主键。主键的取值能够唯一标识表中的记录。主键的定义必须遵守以下规则： （1）一个表只能定义一个主键。（2）主键的值必须能够唯一标识表中的每一条记录，且不能为空（NULL）。 创建表时定义1、定义列时同时定义主键12345create table 表名 ( &lt;字段名&gt; &lt;数据类型&gt; PRIMARY KEY [AUTO_INCREMENT], ....); 12345678910111213141516171819202122232425262728mysql&gt; create table emp001( -&gt; id int primary key auto_increment, -&gt; name char(20), -&gt; salary decimal(8,1) -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; desc emp001;+--------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | || salary | decimal(8,1) | YES | | NULL | |+--------+--------------+------+-----+---------+----------------+3 rows in set (0.00 sec)mysql&gt; show create table emp001\\G*************************** 1. row *************************** Table: emp001Create Table: CREATE TABLE `emp001` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, `salary` decimal(8,1) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 2、在定义完所有列之后定义主键12345create table 表名 ( &lt;字段定义&gt;... , PRIMARY KEY (字段名)); 1234567891011121314151617181920212223242526272829mysql&gt; create table stu001( -&gt; s_no char(11), -&gt; s_name char(20), -&gt; birth datetime, -&gt; primary key(s_no) -&gt; );Query OK, 0 rows affected (0.04 sec)mysql&gt; desc stu001;+--------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+----------+------+-----+---------+-------+| s_no | char(11) | NO | PRI | NULL | || s_name | char(20) | YES | | NULL | || birth | datetime | YES | | NULL | |+--------+----------+------+-----+---------+-------+3 rows in set (0.01 sec)mysql&gt; show create table stu001\\G*************************** 1. row *************************** Table: stu001Create Table: CREATE TABLE `stu001` ( `s_no` char(11) NOT NULL, `s_name` char(20) DEFAULT NULL, `birth` datetime DEFAULT NULL, PRIMARY KEY (`s_no`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 定义多列主键1234567891011121314151617181920212223242526272829mysql&gt; create table score( -&gt; stu_no char(11), -&gt; course_no char(10), -&gt; socre int, -&gt; primary key(stu_no,course_no) -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; desc score;+-----------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------+----------+------+-----+---------+-------+| stu_no | char(11) | NO | PRI | NULL | || course_no | char(10) | NO | PRI | NULL | || socre | int(11) | YES | | NULL | |+-----------+----------+------+-----+---------+-------+3 rows in set (0.00 sec)mysql&gt; show create table score\\G*************************** 1. row *************************** Table: scoreCreate Table: CREATE TABLE `score` ( `stu_no` char(11) NOT NULL, `course_no` char(10) NOT NULL, `socre` int(11) DEFAULT NULL, PRIMARY KEY (`stu_no`,`course_no`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 创建表之后添加主键1alter table 表名 add 列名 类型 primary key [auto_increment]; 1234567891011121314151617181920212223242526mysql&gt; create table t11(name char(11));Query OK, 0 rows affected (0.02 sec)mysql&gt; alter table t11 add id int primary key auto_increment first;Query OK, 0 rows affected (0.05 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc t11;+-------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(11) | YES | | NULL | |+-------+----------+------+-----+---------+----------------+2 rows in set (0.00 sec)mysql&gt; show create table t11\\G*************************** 1. row *************************** Table: t11Create Table: CREATE TABLE `t11` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 把一个已经存在的列定义为主键1alter table 表名 add primary key(列名); 1234567891011121314151617181920212223242526272829mysql&gt; create table t22( -&gt; id int not null, -&gt; name char(20) -&gt; );Query OK, 0 rows affected (0.01 sec)mysql&gt; alter table t22 add primary key(id);Query OK, 0 rows affected (0.06 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc t22;+-------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | char(20) | YES | | NULL | |+-------+----------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; show create table t22\\G*************************** 1. row *************************** Table: t22Create Table: CREATE TABLE `t22` ( `id` int(11) NOT NULL, `name` char(20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 删除主键12345678910111213141516171819202122mysql&gt; alter table t22 drop primary key;Query OK, 0 rows affected (0.04 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc t22;+-------+----------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+-------+| id | int(11) | NO | | NULL | || name | char(20) | YES | | NULL | |+-------+----------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; show create table t22\\G*************************** 1. row *************************** Table: t22Create Table: CREATE TABLE `t22` ( `id` int(11) NOT NULL, `name` char(20) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 二、唯一约束唯一约束使用 UNIQUE 关键字来定义。唯一约束的要求某一列的取值必须是唯一的，不能取重复值。主键约束同时也是唯一约束，唯一约束与主键之间存在以下区别：（1）一个表只能创建一个主键，但可以定义多个唯一约束。（2）定义主键约束时，系统会自动创建 PRIMARY KEY 索引，定义 UNIQUE 约束时，系统会自动创建 UNIQUE 索引。 一、UNIQUE 约束与 PRIMARY KEY 约束的区别和联系（1）唯一性约束所在的列允许空值，但是主键约束所在的列不允许空值。（2）可以把唯一性约束放在一个或者多个列上，这些列或列的组合必须有唯一的。但是，唯一性约束所在的列并不是表的主键列。（3）唯一性约束强制在指定的列上创建一个唯一性索引。（4）一个表最多只有一个主键，但可以有多个唯一键。（5）UNIQUE 约束 &#x3D; PRIMARY KEY 约束 + NOT NULL 。 二、创建表时，同时创建 UNIQUE 约束1、定义列的同时定义 UNIQUE 约束语法如下： 1234567create table 表名 ( 列名 类型 ... , 列名 类型 unique, ....);说明：该方法不能指定约束名。可以使用【show index from 表名; 】命令查看索引名。 12345678910111213141516171819202122232425262728293031mysql&gt; create table t12 ( -&gt; id int primary key auto_increment, -&gt; name char(20), -&gt; phone char(11) unique, -&gt; ID_number char(18) unique -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; desc t12;+-----------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-----------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | || phone | char(11) | YES | UNI | NULL | || ID_number | char(18) | YES | UNI | NULL | |+-----------+----------+------+-----+---------+----------------+4 rows in set (0.00 sec)mysql&gt; show index from t12;+-------+------------+-----------+--------------+-------------+-----------+-------------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality +-------+------------+-----------+--------------+-------------+-----------+-------------| t12 | 0 | PRIMARY | 1 | id | A | 0 | t12 | 0 | phone | 1 | phone | A | 0 | t12 | 0 | ID_number | 1 | ID_number | A | 0 +-------+------------+-----------+--------------+-------------+-----------+-------------3 rows in set (0.00 sec)-- unique 约束的名称默认和字段名相同。 2、在所有的列定义之后定义 UNIQUE 约束123456create table 表名 ( 列名 类型 ... , [constraint 约束名] unique(列名));说明：该方法可以指定约束名。可以使用【show index from 表名; 】命令查看索引名。 1234567891011121314151617181920212223242526272829303132mysql&gt; create table t13 ( -&gt; id int primary key auto_increment, -&gt; name char(20), -&gt; phone char(11), -&gt; ID_number char(18), -&gt; constraint uq_phone unique(phone), -&gt; constraint uq_ID_number unique(ID_number) -&gt;);Query OK, 0 rows affected (0.04 sec)mysql&gt; desc t13;+-----------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-----------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | || phone | char(11) | YES | UNI | NULL | || ID_number | char(18) | YES | UNI | NULL | |+-----------+----------+------+-----+---------+----------------+4 rows in set (0.00 sec)mysql&gt; show index from t13;+-------+------------+--------------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+--------------+--------------+-------------+-----------| t13 | 0 | PRIMARY | 1 | id | A | t13 | 0 | uq_phone | 1 | phone | A | t13 | 0 | uq_ID_number | 1 | ID_number | A +-------+------------+--------------+--------------+-------------+-----------3 rows in set (0.00 sec) 三、创建表之后添加 UNIQUE 约束创建表之后可以添加 UNIQUE 约束，语法格式如下： 1alter table 表名 add [constraint 约束名] unique(列名); 123456789101112131415161718192021222324252627282930mysql&gt; create table t14( -&gt; id int primary key auto_increment, -&gt; name char(20), -&gt; phone char(11) -&gt; );Query OK, 0 rows affected (0.04 sec)mysql&gt; alter table t14 add constraint uq_phone unique(phone);Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc t14;+-------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(20) | YES | | NULL | || phone | char(11) | YES | UNI | NULL | |+-------+----------+------+-----+---------+----------------+3 rows in set (0.00 sec)mysql&gt; show index from t14;+-------+------------+----------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+----------+--------------+-------------+-----------| t14 | 0 | PRIMARY | 1 | id | A | t14 | 0 | uq_phone | 1 | phone | A +-------+------------+----------+--------------+-------------+-----------2 rows in set (0.00 sec) 四、删除 UNIQUE 约束删除 UNIQUE 约束之前可以使用 【show index from 表名; 】查看 UNIQUE 约束的名称。删除 UNIQUE 约束的命令格式如下： 1alter table 表名 drop index 约束名; 1234567891011121314151617181920212223mysql&gt; show index from t13;+-------+------------+--------------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+--------------+--------------+-------------+-----------| t13 | 0 | PRIMARY | 1 | id | A | t13 | 0 | uq_phone | 1 | phone | A | t13 | 0 | uq_ID_number | 1 | ID_number | A +-------+------------+--------------+--------------+-------------+-----------3 rows in set (0.00 sec)mysql&gt; alter table t13 drop index uq_ID_number;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show index from t13;+-------+------------+----------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+----------+--------------+-------------+-----------| t13 | 0 | PRIMARY | 1 | id | A | t13 | 0 | uq_phone | 1 | phone | A +-------+------------+----------+--------------+-------------+-----------2 rows in set (0.00 sec) 三、外键约束两个表必须是 InnoDB 存储引擎 一个表外键所包含的列的类型和与之发生关联的另一个表的主键列的数据类型必须相似，也就是可以相互转换类型的列，数据类型最好相同。 外键用于定义多个表之间的参照完整性。参照完整性指多个表之间的对应关系，在一张表中执行数据的插入、更新、删除等操作时，会和另一张表进行对照，以确保数据存储的完整性。 外键约束必须遵守以下规则： （1）某一个表中的某个字段的取值依赖于另一张表中某个字段的值。（2）主键所在的表为主表，外键所在的表为从表，每一个外键值必须与另一个表中的主键值相对应。 一、创建表的同时定义外键在创建表时可以同时创建外键，语法如下： 123456789101112131415create table 表名 ( 列名 类型 ... , [CONSTRAINT 约束名] FOREIGN KEY (列名) REFERENCES 表名 (列名) [ON DELETE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;] [ON UPDATE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;]);说明：定义了外键约束之后，在删除父表记录和更新父表的主键时可以设置以下操作方式。（1）cascade 方式：在父表上更新和删除记录时，子表匹配的记录也同步进行更新（级联更新）和删除（级联删除）；（2）set null 方式：在父表上更新和删除记录时，子表匹配的记录的外键设为null；（3）No action 方式：如果子表中有匹配的记录，则不允许对父表对应的主键进行更新和删除操作；（4）Restrict 方式：同 no action, 都是立即检查外键约束；（5）Set default 方式：父表上更新和删除记录时，子表将外键列设置成一个默认的值；（6）系统默认为No action 方式。 例子： 1、创建部门（dept）和员工（emp）表，并创建外键。（1）创建表 12345678910111213create table dept ( id int primary key auto_increment, name char(20));create table emp ( id int primary key auto_increment, name char(20), salary decimal(8,2), dept_id int, foreign key(dept_id) references dept(id)); (2) 插入数据 123456789101112131415161718192021222324mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 1 | 人事部 || 2 | 销售部 || 3 | 技术部 || 4 | 财务部 |+----+-----------+4 rows in set (0.00 sec)mysql&gt; select * from emp;+----+-----------+---------+---------+| id | name | salary | dept_id |+----+-----------+---------+---------+| 1 | 张鹏 | 4500.00 | 1 || 2 | 王晶 | 5700.00 | 1 || 3 | 刘云 | 4900.00 | 2 || 4 | 王晓刚 | 5200.00 | 2 || 5 | 刘大鹏 | 4200.00 | 2 || 6 | 王军军 | 5600.00 | 3 |+----+-----------+---------+---------+6 rows in set (0.00 sec) （3）验证外键约束 在删除父表记录和更新父表的主键时，子表的操作方式默认为No action 方式。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152-- 1、删除 dept 表（父表）：删除失败mysql&gt; drop table dept;ERROR 1217 (23000): Cannot delete or update a parent row: a foreign key constraint fails-- 2、删除 dept 表（父表）中的 1号部门（人事部）：子表中有相关记录，删除失败mysql&gt; delete from dept where id=1;ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`wgx`.`emp`, CONSTRAINT `emp_ibfk_1` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`))-- 3、删除 dept 表（父表）中的 4号部门（财务部）：由于子表中没有相关记录，成功删除mysql&gt; delete from dept where id=4;Query OK, 1 row affected (0.01 sec)mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 1 | 人事部 || 2 | 销售部 || 3 | 技术部 |+----+-----------+3 rows in set (0.00 sec)-- 4、重新插入财务部的信息mysql&gt; insert into dept(id,name) values(4,&#x27;财务部&#x27;);Query OK, 1 row affected (0.02 sec)mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 1 | 人事部 || 2 | 销售部 || 3 | 技术部 || 4 | 财务部 |+----+-----------+4 rows in set (0.00 sec)-- 5、更新父表的字段 id，更新人事部的 id 失败，因为子表中存在相关记录mysql&gt; update dept set id=11 where id=1;ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`wgx`.`emp`, CONSTRAINT `emp_ibfk_1` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`))-- 6、更新父表的字段 id，更新财务部的 id 成功，因为子表中不存在相关记录mysql&gt; update dept set id=44 where id=4;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 1 | 人事部 || 2 | 销售部 || 3 | 技术部 || 44 | 财务部 |+----+-----------+4 rows in set (0.00 sec) 2、把 emp 表的外键设置为级联更新和级联删除不提供对外键的直接修改，可以先删除外键，然后再重新创建。 （1）查看外键约束的名称 12345678910111213141516mysql&gt; show create table emp\\G*************************** 1. row *************************** Table: empCreate Table: CREATE TABLE `emp` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, `salary` decimal(8,2) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `dept_id` (`dept_id`), CONSTRAINT `emp_ibfk_1` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec)-- 外键约束的名称为：emp_ibfk_1 （2）删除外键约束 1234mysql&gt; alter table emp drop foreign key emp_ibfk_1;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0 （3）重新添加外键约束 12345678910111213141516171819202122mysql&gt; alter table emp -&gt; add constraint fk_emp_dept_id foreign key(dept_id) -&gt; references dept(id) -&gt; on update cascade -&gt; on delete cascade;Query OK, 6 rows affected (0.06 sec)Records: 6 Duplicates: 0 Warnings: 0mysql&gt; show create table emp\\G*************************** 1. row *************************** Table: empCreate Table: CREATE TABLE `emp` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, `salary` decimal(8,2) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `fk_emp_dept_id` (`dept_id`), CONSTRAINT `fk_emp_dept_id` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) （4）测试外键约束 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566-- 1、在dept表中把人事部的编号修改为11，销售部的编号修改22，技术部的编号修改为33-- 可以看到，子表中对应的部门编号自动被修改mysql&gt; update dept set id=11 where id=1;Query OK, 1 row affected (0.03 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; update dept set id=22 where id=2;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; update dept set id=33 where id=3;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 11 | 人事部 || 22 | 销售部 || 33 | 技术部 || 44 | 财务部 |+----+-----------+4 rows in set (0.00 sec)mysql&gt; select * from emp;+----+-----------+---------+---------+| id | name | salary | dept_id |+----+-----------+---------+---------+| 1 | 张鹏 | 4500.00 | 11 || 2 | 王晶 | 5700.00 | 11 || 3 | 刘云 | 4900.00 | 22 || 4 | 王晓刚 | 5200.00 | 22 || 5 | 刘大鹏 | 4200.00 | 22 || 6 | 王军军 | 5600.00 | 33 |+----+-----------+---------+---------+6 rows in set (0.01 sec)-- 2、在dept表中删除技术部的信息-- 可以看到，技术部的员工自动被删除mysql&gt; delete from dept where id=33;Query OK, 1 row affected (0.01 sec)mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 11 | 人事部 || 22 | 销售部 || 44 | 财务部 |+----+-----------+3 rows in set (0.00 sec)mysql&gt; select * from emp;+----+-----------+---------+---------+| id | name | salary | dept_id |+----+-----------+---------+---------+| 1 | 张鹏 | 4500.00 | 11 || 2 | 王晶 | 5700.00 | 11 || 3 | 刘云 | 4900.00 | 22 || 4 | 王晓刚 | 5200.00 | 22 || 5 | 刘大鹏 | 4200.00 | 22 |+----+-----------+---------+---------+5 rows in set (0.00 sec) 二、删除外键约束删除外键约束的语法格式如下： 1alter table 表名 drop foreign key 约束名; 删除外键约束之前需要先查询外键约束名，可以使用 show create table 表名： 1234567891011121314151617181920212223242526-- 查看外键约束名mysql&gt; show create table emp\\G*************************** 1. row *************************** Table: empCreate Table: CREATE TABLE `emp` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, `salary` decimal(8,2) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `fk_emp_dept_id` (`dept_id`), CONSTRAINT `fk_emp_dept_id` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec)-- 创建外键约束会自动创建一个索引-- 查看外键约束对应的索引mysql&gt; show index from emp;+-------+------------+----------------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+----------------+--------------+-------------+-----------| emp | 0 | PRIMARY | 1 | id | A | emp | 1 | fk_emp_dept_id | 1 | dept_id | A +-------+------------+----------------+--------------+-------------+-----------2 rows in set (0.00 sec) 举例：删除 emp 表的外键约束 123456789101112131415161718192021222324252627282930mysql&gt; alter table emp drop foreign key fk_emp_dept_id;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table emp\\G*************************** 1. row *************************** Table: empCreate Table: CREATE TABLE `emp` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, `salary` decimal(8,2) DEFAULT NULL, `dept_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `fk_emp_dept_id` (`dept_id`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec)-- 删除约束不会自动删除约束对应的索引mysql&gt; show index from emp;+-------+------------+----------------+--------------+-------------+-----------| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation +-------+------------+----------------+--------------+-------------+-----------| emp | 0 | PRIMARY | 1 | id | A | emp | 1 | fk_emp_dept_id | 1 | dept_id | A +-------+------------+----------------+--------------+-------------+-----------2 rows in set (0.00 sec)-- 手工删除外键约束对应的索引mysql&gt; alter table emp drop index fk_emp_dept_id;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0 三、为已有的表添加外键约束命令格式如下： 1234567alter table 表名add constraint 约束名foreign key(列名) references 父表名(列名)[ON DELETE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;][ON UPDATE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;]; 举例：为 emp 表添加外键约束，名称为 fk_emp_dept_id，on delete 设置为 set null，on update 设置为 cascade。 12345678mysql&gt; alter table emp add constraint fk_emp_dept_id foreign key(dept_id) references dept(id) on delete set null on update cascade;Query OK, 5 rows affected (0.03 sec)Records: 5 Duplicates: 0 Warnings: 0 四、非空约束非空约束就是限制必须为某个列提供值。空值（NULL）既不是数字0，也不是空字符串。空值用 NULL 表示，使用空值参与的运算结果仍然为空值。 12345create table 表名( 列名 类型 not null, ....); 五、默认值可通过关键字 DEFAULT 为某个字段设置默认值。如果为某个字段设置了默认值，当在数据表中插入一条新记录时，如果没有为某个字段赋值，则自动为这个字段插入默认值。 12345create table 表名 ( &lt;字段名&gt; &lt;数据类型&gt; DEFAULT &lt;默认值&gt;, ....); 六、自增列可以使用关键字 AUTO_INCREMENT 把某个字段设置为自增列，当向数据表中插入新记录时，该字段上的值会自动生成唯一的ID。一个表只能把一个字段设置为自增字段，并且字段的数据类型必须是整型。由于设置 AUTO_INCREMENT 约束后的字段会生成唯一的 ID，因此该字段也经常会同时设置成主键 插入数据：插入数据时如果手工指定自增列的数据，则自增列的起始值变为新插入的数据，下次插入数据时从当前插入的数据值递增。 修改表结构重新定义字段类型，并且去掉 auto_increment 关键词即可 alter table t2 modify id int auto_increment; 3、修改自增列的起始值1234567891011121314mysql&gt; alter table t2 auto_increment=1001;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t2\\G*************************** 1. row *************************** Table: t2Create Table: CREATE TABLE `t2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` char(20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1001 DEFAULT CHARSET=utf8mb41 row in set (0.00 sec) 索引索引包含了对表中所有记录的引用指针，通俗地说，索引好比是一本书前面的目录，能加快数据库的查询速度，索引用于快速找出在某个列中有一特定值的行。当执行查询操作时，如果不使用索引，MySQL 必须从第一条记录开始读完整个表，直到找出相关的行，表越大，查询数据所花费的时间就越多。如果表中查询的列有一个索引，MySQL 能够快速到达一个位置去搜索数据文件，而不必查看所有数据。MySQL 索引的存储类型有两种：BTREE 和 HASH，也就是用树或者Hash值来存储索引字段。 一、使用索引的优点使用索引可以加快数据的查询速度。 例如：有一张 person 表，其中有 2W 条记录，记录着 2W 个人的信息。有一个 Phone 字段记录每个人的电话号码，现在想要查询出电话号码为 xxxx 的人的信息。如果没有索引，将从表中第一条记录一条条往下遍历，直到找到该条信息为止。如果根据 Phone 字段创建了索引，会将该字段通过一定的方法进行存储，当查询该字段上的信息时，能够快速找到对应的数据，而不必再去遍历 2W 条数据了。 二、使用索引的缺点虽然通过创建索引可以提供查询数据的速度，但过多的创建索引也存在一些问题。 1、创建索引和维护索引需要耗费时间，并且随着数据量的增加所耗费的时间也会增加。因此，不要创建非必要的索引。2、索引需要占用存储空间。3、当对表中的数据进行增删改操作时，索引也需要动态的维护，降低了数据维护的速度。 三、索引的使用原则通过对索引优缺点的分析，应该知道：索引并不是越多越好，而是根据自己的需要创建索引，创建索引的原则如下：（1）经常进行数据更新的表要避免创建过多的索引，而经常用于查询的字段应该创建索引。（2）数据量小的表最好不要使用索引。如果数据较少，可能查询全部数据花费的时间比遍历索引的时间还要短。（3）如果一个字段的值大量重复，则不要创建索引，比如学生表的性别字段上只有男，女两个不同值。 四、索引的分类1、根据索引的存储结构划分按索引的存储结构分为 BTREE 索引和 HASH 索引。MyISAM 和 InnoDB 存储引擎，只支持 BTREE 索引；MEMORY 和 HEAP 存储引擎，支持 BTREE 索引和 HASH 索引。 2、根据索引所包含的列数划分根据索引所包含的列数分为单列索引和组合索引。（1）单列索引：一个索引只包含一个列。（2）组合索引：根据表中多个字段的组合创建索引。只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时遵循最左前缀原则。 3、根据索引对数据的要求划分根据索引对数据的要求分为普通索引、唯一索引和主键索引。（1）普通索引：MySQL 中基本的索引类型，对数据没有什么限制，允许在定义索引的列中插入重复值和空值。（2）唯一索引：要求索引列中的值必须唯一，但是允许为空值。（3）主键索引：是一种特殊的唯一索引，除了要求索引列中的值必须唯一之外，还不允许有空值。 DDL(Data Definition Language)数据定义语言一、操作库– 创建库create database db1;– 创建库是否存在，不存在则创建create database if not exists db1;– 查看所有数据库show databases;– 查看某个数据库的定义信息show create database db1;– 修改数据库字符信息alter database db1 character set utf8;– 删除数据库drop database db1;二、操作表–创建表create table student( id int, name varchar(32), age int , score double(4,1), birthday date, insert_time timestamp); 一、基础关键字 BETWEEN…AND （在什么之间）和 IN( 集合) – 查询年龄大于等于20 小于等于30 SELECT * FROM student WHERE age &gt;&#x3D; 20 &amp;&amp; age &lt;&#x3D;30;SELECT * FROM student WHERE age &gt;&#x3D; 20 AND age &lt;&#x3D;30;SELECT * FROM student WHERE age BETWEEN 20 AND 30; – 查询年龄22岁，18岁，25岁的信息SELECT * FROM student WHERE age &#x3D; 22 OR age &#x3D; 18 OR age &#x3D; 25SELECT * FROM student WHERE age IN (22,18,25); is null(不为null值) 与 like（模糊查询）、distinct（去除重复值） – 查询英语成绩不为nullSELECT * FROM student WHERE english IS NOT NULL; :单个任意字符 %：多个任意字符– 查询姓马的有哪些？ likeSELECT * FROM student WHERE NAME LIKE ‘马%’;– 查询姓名第二个字是化的人 SELECT * FROM student WHERE NAME LIKE “化%”; – 查询姓名是3个字的人SELECT * FROM student WHERE NAME LIKE ‘_’; – 查询姓名中包含德的人SELECT * FROM student WHERE NAME LIKE ‘%德%’; – 关键词 DISTINCT 用于返回唯一不同的值。– 语法：SELECT DISTINCT 列名称 FROM 表名称SELECT DISTINCT NAME FROM student ;二、排序查询 order by语法：order by 子句 order by 排序字段1 排序方式1 ， 排序字段2 排序方式2... 注意： 如果有多个排序条件，则当前边的条件值一样时，才会判断第二条件。 – 例子SELECT * FROM person ORDER BY math; –默认升序SELECT * FROM person ORDER BY math desc; –降序三、 聚合函数：将一列数据作为一个整体，进行纵向的计算。1.count：计算个数 2.max：计算最大值 3.min：计算最小值 4.sum：计算和 5.avg：计算平均数 四、 分组查询 grout by 语法：group by 分组字段; 注意：分组之后查询的字段：分组字段、聚合函数 – 按照性别分组。分别查询男、女同学的平均分SELECT sex , AVG(math) FROM student GROUP BY sex; – 按照性别分组。分别查询男、女同学的平均分,人数 SELECT sex , AVG(math),COUNT(id) FROM student GROUP BY sex; – 按照性别分组。分别查询男、女同学的平均分,人数 要求：分数低于70分的人，不参与分组SELECT sex , AVG(math),COUNT(id) FROM student WHERE math &gt; 70 GROUP BY sex; – 按照性别分组。分别查询男、女同学的平均分,人数 要求：分数低于70分的人，不参与分组,分组之后。人数要大于2个人SELECT sex , AVG(math),COUNT(id) FROM student WHERE math &gt; 70 GROUP BY sex HAVING COUNT(id) &gt; 2;SELECT sex , AVG(math),COUNT(id) 人数 FROM student WHERE math &gt; 70 GROUP BY sex HAVING 人数 &gt; 2;五、 分页查询 1. 语法：limit 开始的索引,每页查询的条数; 2. 公式：开始的索引 &#x3D; （当前的页码 - 1） * 每页显示的条数 3. limit 是一个MySQL”方言” – 每页显示3条记录 SELECT * FROM student LIMIT 0,3; – 第1页 SELECT * FROM student LIMIT 3,3; – 第2页 SELECT * FROM student LIMIT 6,3; – 第3页六、内连接查询： 1. 从哪些表中查询数据 2.条件是什么 3. 查询哪些字段 1.隐式内连接：使用where条件消除无用数据– 查询员工表的名称，性别。部门表的名称SELECT emp.name,emp.gender,dept.name FROM emp,dept WHERE emp.dept_id &#x3D; dept.id; SELECT t1.name, – 员工表的姓名 t1.gender,– 员工表的性别 t2.name – 部门表的名称FROM emp t1, dept t2WHERE t1.dept_id &#x3D; t2.id; 2.显式内连接– 语法：select 字段列表 from 表名1 [inner] join 表名2 on 条件– 例如：SELECT * FROM emp INNER JOIN dept ON emp.dept_id &#x3D; dept.id;SELECT * FROM emp JOIN dept ON emp.dept_id &#x3D; dept.id; 七、外连接查询1.左外连接 – 查询的是左表所有数据以及其交集部分。– 语法：select 字段列表 from 表1 left [outer] join 表2 on 条件；– 例子：– 查询所有员工信息，如果员工有部门，则查询部门名称，没有部门，则不显示部门名称SELECT t1.*,t2.name FROM emp t1 LEFT JOIN dept t2 ON t1.dept_id &#x3D; t2.id; 2.右外连接 – 查询的是右表所有数据以及其交集部分。– 语法：select 字段列表 from 表1 right [outer] join 表2 on 条件；– 例子：SELECT * FROM dept t2 RIGHT JOIN emp t1 ON t1.dept_id &#x3D; t2.id; 八、子查询：查询中嵌套查询– 查询工资最高的员工信息– 1 查询最高的工资是多少 9000SELECT MAX(salary) FROM emp; – 2 查询员工信息，并且工资等于9000的SELECT * FROM emp WHERE emp.salary &#x3D; 9000; – 一条sql就完成这个操作。这就是子查询SELECT * FROM emp WHERE emp.salary &#x3D; (SELECT MAX(salary) FROM emp); 1.子查询的结果是单行单列的 子查询可以作为条件，使用运算符去判断。 运算符： &gt; &gt;&#x3D; &lt; &lt;&#x3D; &#x3D; – 查询员工工资小于平均工资的人SELECT * FROM emp WHERE emp.salary &lt; (SELECT AVG(salary) FROM emp); 2. 子查询的结果是多行单列的： 子查询可以作为条件，使用运算符in来判断 – 查询’财务部’和’市场部’所有的员工信息SELECT id FROM dept WHERE NAME &#x3D; ‘财务部’ OR NAME &#x3D; ‘市场部’;SELECT * FROM emp WHERE dept_id &#x3D; 3 OR dept_id &#x3D; 2; – 子查询SELECT * FROM emp WHERE dept_id IN (SELECT id FROM dept WHERE NAME &#x3D; ‘财务部’ OR NAME &#x3D; ‘市场部’); 3. 子查询的结果是多行多列的： 子查询可以作为一张虚拟表参与查询 – 查询员工入职日期是2011-11-11日之后的员工信息和部门信息– 子查询SELECT * FROM dept t1 ,(SELECT * FROM emp WHERE emp.join_date &gt; ‘2011-11-11’) t2 WHERE t1.id &#x3D; t2.dept_id; – 普通内连接SELECT * FROM emp t1,dept t2 WHERE t1.dept_id &#x3D; t2.id AND t1.join_date &gt; ‘2011-11-11’ DCL(Data Control Language)数据控制语言管理用户添加用户语法：CREATE USER ‘用户名‘@’主机名’ IDENTIFIED BY ‘密码’;删除用户语法：DROP USER ‘用户名‘@’主机名’;权限管理查询权限– 查询权限SHOW GRANTS FOR ‘用户名‘@’主机名’;SHOW GRANTS FOR ‘lisi‘@’%’;授予权限– 授予权限grant 权限列表 on 数据库名.表名 to ‘用户名‘@’主机名’; – 给张三用户授予所有权限，在任意数据库任意表上GRANT ALL ON . TO ‘zhangsan‘@’localhost’;撤销权限– 撤销权限：revoke 权限列表 on 数据库名.表名 from ‘用户名‘@’主机名’;REVOKE UPDATE ON db3.account FROM ‘lisi‘@’%’; 作者：刘金玉数据库中对数据进行查询必须使用Select关键词。本期教程跟老刘一起对数据库查询的几种情况进行学习。 第一种:单表查询语法结构: select 字段名称 from 表名称或者如果我们要查询表的所以字段，就直接使用select * from 表名 这个语法即可，这里的星号*表示所有字段名称。案例：查询用户表user的所有信息Select * from user 第二种:带有条件筛选的单表查询 where这个语法只是在select查询语句的最好加上一条where语句进行数据的进一步过滤。语法结构：where 字段1 表达式符号 相应条件值举例：查询姓名为刘金玉的用户信息Select * from user where trueName&#x3D;’刘金玉’这里要注意的是“刘金玉”为一个字符串，因此要加上单引号，在数据库查询语句中，我们之前强调过，如果字段类型为字符串类型(例如char、varchar、nchar、nvarchar、text等)就要在查询和录入的时候加上相应的单引号‘’ 第三种:多表查询 join我们很多时候往往要多个表的数据举行查询，因为根据关系型数据库设计的特点，我们需要的各个字段的数据往往分布于各个不同的数据表内。虽然在数据库中我们也可以采用where语句进行关键表的字段，但是这样做有很多弊端：一是条件语句不清晰，二是查询效率降低。因此，我们引出了join这个关键词。Join有三种类型：left join 左连接 （默认的join就是left join）right join 右连接inner join 内连接语法结构：Select * from 表1 left&#x2F;right&#x2F;inner join 表2 on 表1.字段&#x3D;表2.字段举例：关联用户表和新闻表，关联字段为useridSelect * from user left join news on user.userid&#x3D; news. userid根据这样说表关联，就可以显示文章的作者信息啦！当然，我们也可以采用给表取别名的方式关联。Select * from user a left join news b on a.userid&#x3D; b. userid在使用join关键词进行关联的时候，一定要注意的是主表是哪个，这个跟现实结果记录数有关系。最好结合老刘的《零基础数据库教程》视频学习，注意观察一下不同的使用，得到的不同表关联结果。以下简单说明一下：A left join B 就是A为主表A right join B 就是B为主表A inner join B 就是取两张表的公共部分副表在这里只是根据关键词对主表进行匹配，可能会被多次匹配，这要看数据表设计时候的表关系。 第四种:过滤相同列数据 distinct如果我们得到的查询结果中有相同的数据行，我们可以通过distinct关键词进行过滤。语法结构：select distinct 字段 from 表没错，只需要在查询select关键词后加上distinct关键词即可。举例：查询用户表一共有哪些用户昵称。Select distinct nickname from user 第五种:数据排序order by我们很多时候都是要将查询后的数据进行排序的，按照我们查询的指定字段为主关键词和次要关键词进行排序，这个时候，我们需要使用order by这个重要关键词。这个关键词往往用在查询语句的最后。Order by 往往结合asc和desc这两个关键词，其中asc表示升序，desc表示降序。语法结构：Select 字段 from 表 『where语句』 order by 字段1 asc&#x2F;desc, 字段2 asc&#x2F;desc…使用案例：查询用户表所有信息，并按照用户编号进行升序排序。Select * from user order by userid asc其实在这个语句中，我们也可以省略asc关键词，因为order by 默认是以升序作为排序规则的。所以这个语句，我们也可以写成：Select * from user order by userid 第六种:数据记录显示limit我们很多使用数据库的人员中，很多人都是做软件来发的，因此limit这个关键词就非常实用了，因为我们可以结合这个关键词，为我们的软件查询出来的数据记录结果做一个分页功能。limit这个关键词往往用在查询语句的最后。语法结构：Select 字段 from 表 [where语句] [order by语句] [limit语句]举例：获取用户表的前十条记录Select * from user limit 10获取用户表的第11～20条记录Select * from user limit 10，20 第七种:聚合函数 sum count等sum函数用来求和、count函数用来统计数据记录数。但要注意，聚合函数会自动忽略类型值为null的记录。下面分别对两个函数进行讲解:1.求和函数sum。使用注意，该函数用于统计数值类字段。使用时配合select语句。函数参数传入字段名，格式sum（字段名称）。举例:统计某学生各科总成绩。select stuname，sum（score） from student_score这里的stuname是学生姓名，score是指各科目对应的成绩字段，student_score是学生各科成绩表 第八种:数据分组group by group by的意思就是根据哪些字段进行分组，这里注意，后面接的第一个字段是主要关键词，其它的依次都是次要关键词。 分组的数据一般都是where语句筛选后的最终数据，再进行依次筛选，这样的好处是可以减少分组的数据，以进一步提高数据库性能。 语法结构： group by 字段1，字段2，字段3 语句所在sql中的位置： select 字段 from 表 [where语句][group by语句] 一般来说，group by后面接几个字段，在select中就会列出几个字段。分组最终的目的是为了统计数据，比如对每一个学生的各科成绩求和。 案例：统计每个城市有多少人，我们可以从人口信息表中查询出要统计的数据结果。 select city,count(*) from persons group by city 这里的persons是人口信息表，city是城市名称，count（*）表示统计记录数 第九种:分组后筛选数据 having我们有时候常常还会将分组后的数据进行进一步过滤，那么，此时就要使用到having了。 语句所在sql中的位置： select 字段 from 表 [where语句][group by语句][having语句] 至于having之后的字段表达式的用法类似于where语句，唯一不同的就是having之后的筛选条件的字段是group by之后的字段。 案例：筛选出总成绩大于300分的学生 思路：先用group by分组求出每个学生的总成绩，然后将分组后的总成绩中筛选出成绩大于300的结果记录。 select stuname,sum(score) from student_score group by stuname having sum(score)&gt;300 因为，这里筛选的是总成绩这个字段，而这个字段的名称就是sum(score)，因此在having中使用sum(score)作为字段名称。 其中：DISTINCT|UNIQUE|ALL：指定查询结果集中的重复记录 处理方式，默认值为ALL。select_list：指定从数据库中返回的目标列或表达式。query_table_expression：指定数据来源的表、视图或实体化视图等。·join_clause：进行连接查询。where_clause：限制从数据源中返回的记录需要满足的条件。hierarchical_query_clause：层次查询。group_by_clause：分组查询。order_by_clause：查询结果排序。row_limiting_clause：返回查询结果中指定的若干记录。 SELECT语句执行的基本步骤为： 1、当执行一条SELECT语句时，系统会根据WHERE子句 的条件表达式condition，从FROM子句指定的数据源（基本 表、视图、实体化视图、连接查询等）中找出满足条件的记 录，再按SELECT子句中指定的目标列或表达式形成结果集。2、如果数据源是多表连接，则先进行多表连接操作，形 成一个大的结果集，作为外部查询的数据源。3、如果包含层次查询，则返回的记录在满足WHERE过滤 条件的同时，还要符合层次查询条件。4、如果包含分组查询，则将返回的结果集按特定的分组 列进行分组。如果需要对分组进行过滤，最后返回的结果集还 要满足分组的过滤条件。5、如果需要对查询结果进行排序，则返回的结果集需要 进行二次处理，返回有序数据。6、如果只返回排序后的部分记录，则从排序后的结果集 中返回指定的记录","categories":[{"name":"mysql","slug":"mysql","permalink":"https://gouguoqiang.github.io/categories/mysql/"}],"tags":[{"name":"mysql实践","slug":"mysql实践","permalink":"https://gouguoqiang.github.io/tags/mysql%E5%AE%9E%E8%B7%B5/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-10-08T05:18:09.474Z","updated":"2022-10-08T05:18:09.474Z","comments":true,"path":"2022/10/08/hello-world/","link":"","permalink":"https://gouguoqiang.github.io/2022/10/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://gouguoqiang.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"微服务","slug":"微服务","permalink":"https://gouguoqiang.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"多线程","slug":"多线程","permalink":"https://gouguoqiang.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JVM","slug":"JVM","permalink":"https://gouguoqiang.github.io/categories/JVM/"},{"name":"java","slug":"java","permalink":"https://gouguoqiang.github.io/categories/java/"},{"name":"mysql","slug":"mysql","permalink":"https://gouguoqiang.github.io/categories/mysql/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://gouguoqiang.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"redis","slug":"redis","permalink":"https://gouguoqiang.github.io/tags/redis/"},{"name":"框架","slug":"框架","permalink":"https://gouguoqiang.github.io/tags/%E6%A1%86%E6%9E%B6/"},{"name":"多线程","slug":"多线程","permalink":"https://gouguoqiang.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JVM","slug":"JVM","permalink":"https://gouguoqiang.github.io/tags/JVM/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://gouguoqiang.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"java","slug":"java","permalink":"https://gouguoqiang.github.io/tags/java/"},{"name":"mysql实践","slug":"mysql实践","permalink":"https://gouguoqiang.github.io/tags/mysql%E5%AE%9E%E8%B7%B5/"}]}